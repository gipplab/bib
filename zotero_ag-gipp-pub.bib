
@inproceedings{AizawaKOS14,
  ids = {AizawaKOS14a},
  title = {{{NTCIR}}-11 {{Math}}-2 {{Task Overview}}},
  booktitle = {Proceedings of the 11th {{NTCIR Conference}} on {{Evaluation}} of {{Information Access Technologies}}, {{NTCIR}}-11, {{National Center}} of {{Sciences}}, {{Tokyo}}, {{Japan}}, {{December}} 9-12, 2014},
  author = {Aizawa, Akiko and Kohlhase, Michael and Ounis, Iadh and Schubotz, Moritz},
  date = {2014},
  pages = {88--98},
  publisher = {{National Institute of Informatics (NII)}},
  url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings11/pdf/NTCIR/OVERVIEW/01-NTCIR11-OV-MATH-AizawaA.pdf},
  abstract = {This paper presents an overview of the NTCIR-11 Math-2 Task, which is specifically dedicated to information access to mathematical content. In particular, the paper summarizes the task design, analysis of the submitted runs, and the main approaches deployed by the participating groups. It also contains an introduction to the optional free Wikipediasubtask, a newly introduced mathematical retrieval task using Wikipedia articles.},
  biburl = {https://dblp.org/rec/bib/conf/ntcir/AizawaKOS14},
  jabref-groups = {GuidiReview, phd-m},
  oldkey = {Aizawa2014},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,conference,content,information access to mathematical,jabref_imp2,mathml,NTCIR,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\UZY4V3L8\\AizawaKOS14--ntcir-11_math-2_task_overview.pdf}
}

@inproceedings{AlcalaBFG03,
  title = {Ortung von mobilen {{Geraeten}} fuer die {{Realisierung}} lokationsbasierter {{Dienste}}},
  booktitle = {Mobilitaet und {{Informationssysteme}} - {{Workshop}} des {{GI}}-{{Arbeitskreises}} "{{Mobile Datenbanken}} und {{Informationssysteme}}"},
  author = {Alcala, Felix and Beel, Joeran and Frenkel, Arne and Gipp, Bela and Luelf, Johannes and Hoepfner, Hagen},
  editor = {Tuerker, Can},
  date = {2003-10},
  publisher = {{ETH Zuerich}},
  location = {{Zurich}},
  oldkey = {Alcala03},
  preprint = {https://ag-gipp.github.io/bib/preprints/alcala03.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\WM9E7FB4\\AlcalaBFG03--ortung_von_mobilen_geraeten_fuer_die_realisierung_lokationsbasierter_dienste.pdf}
}

@inproceedings{AlcalaBFG04,
  title = {{{UbiLoc}}: {{A System}} for {{Locating Mobile Devices}} using {{Mobile Devices}}},
  booktitle = {Proceedings of 1st {{Workshop}} on {{Positioning}}, {{Navigation}} and {{Communication}} 2004 ({{WPNC}} 04)},
  author = {Alcala, Felix and Beel, Joeran and Frenkel, Arne and Gipp, Bela and Luelf, Johannes and Hoepfner, Hagen},
  editor = {Kyamakya, K.},
  date = {2004},
  publisher = {{University of Hannover}},
  doi = {10.1.1.143.3208},
  oldkey = {Alcala04},
  preprint = {https://ag-gipp.github.io/bib/preprints/alcala04.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\MD6XU6UQ\\AlcalaBFG04--ubiloc_a_system_for_locating_mobile_devices_using_mobile_devices.pdf}
}

@book{Beel07,
  title = {Project {{Team Rewards}} - {{Rewarding}} and {{Motivating}} your {{Project Team}}},
  author = {Beel, Joeran},
  date = {2007},
  publisher = {{Createspace}},
  location = {{Scotts Valley (USA)}},
  oldkey = {Beel07},
  owner = {Joeran},
  keywords = {!jb,!jb_author,\#nosource,jabref_imp2}
}

@book{Beel09CS,
  title = {Computer {{Science}}: {{New Generations}}},
  editor = {Beel, Joeran},
  date = {2009},
  publisher = {{Grin Verlag}},
  location = {{Munich (Germany)}},
  oldkey = {Beel09g},
  owner = {Joeran},
  keywords = {!jb,!jb_author,\#nosource,jabref_imp2}
}

@inproceedings{Beel09VLBA,
  title = {Information {{Retrieval}} in {{Mind Maps}} zum {{Verbessern}} von {{Suchapplikationen}}},
  booktitle = {Very {{Large Business Applications}} ({{VLBA}}): {{Systemlandschaften}} der {{Zukunft}}},
  author = {Beel, Joeran},
  editor = {Arndt, H.-K. and Krcmar, H.},
  date = {2009},
  series = {Workshop des {{Centers}} for {{Very Large Business Applications}} ({{CVLBA}})},
  volume = {3},
  pages = {139--152},
  publisher = {{Shaker Verlag}},
  location = {{Magdeburg}},
  oldkey = {Beel09d},
  owner = {Joeran},
  keywords = {!jb,!jb_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ZZZATVY2\\Beel09VLBA--information_retrieval_in_mind_maps_zum_verbessern_von_suchapplikationen.pdf}
}

@inproceedings{Beel10ECDL,
  ids = {Beel10a},
  title = {Retrieving {{Data}} from {{Mind Maps}} to {{Enhance Search Applications}}},
  booktitle = {Research and {{Advanced Technology}} for {{Digital Libraries}}, {{Proceedings}} of the 14th {{European Conference}} on {{Digital Libraries}} ({{ECDL}}'10)},
  author = {Beel, Joeran},
  editor = {Lalmas, M and Jose, J and Rauber, A and Sebastiani, R and Frommholz, I},
  date = {2010},
  series = {Lecture {{Notes}} of {{Computer Science}} ({{LNCS}})},
  volume = {6273},
  publisher = {{Springer}},
  location = {{Glasgow (UK)}},
  doi = {10/dfpfpr},
  oldkey = {Beel10f},
  owner = {Joeran},
  keywords = {!jb,!jb_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\FTIR47JB\\Beel10ECDL--retrieving_data_from_mind_maps_to_enhance_search_applications.pdf}
}

@inproceedings{Beel10Sem,
  title = {Mind {{Maps}}, {{Information Retrieval}}, and {{SciPlore MindMapping}}},
  booktitle = {Seminar on {{Information Access}}},
  author = {Beel, Joeran},
  date = {2010},
  location = {{Berkeley (USA)}},
  oldkey = {Beel10b},
  organization = {{School of Information, University of California Berkeley}},
  owner = {Joeran},
  keywords = {!jb,!jb_author,\#nosource,⛔ No DOI found,jabref_imp2}
}

@incollection{Beel11,
  title = {Research {{Paper Recommendations Based}} on {{Mind Maps}}},
  booktitle = {Very {{Large Business Applications}} ({{VLBA}}): {{System Landscapes}} of the {{Future}}},
  author = {Beel, Joeran},
  editor = {Arndt, Hans-Knud and Krcmar, Helmut},
  date = {2011},
  series = {Berichte aus der {{Wirtschaftsinformatik}}},
  pages = {66--75},
  publisher = {{Shaker Verlag}},
  oldkey = {Beel11},
  owner = {joeran},
  keywords = {!jb,!jb_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\AY7Q9TTJ\\Beel11--research_paper_recommendations_based_on_mind_maps.pdf}
}

@online{Beel12Blog,
  title = {Evaluations in {{Information Retrieval}}: {{Click Through Rate}} ({{CTR}}) vs. {{Mean Absolute Error}} ({{MAE}}) vs. ({{Root}}) {{Mean Squared Error}} ({{MSE}} / {{RMSE}}) vs. {{Precision}}},
  author = {Beel, Joeran},
  date = {2012},
  url = {http://www.docear.org/2012/09/21/evaluations-in-information-retrieval-click-through-rate-ctr-vs-mean-absolute-error-mae-vs-root-mean-squared-error-mse-rmse-vs-precision/},
  oldkey = {Beel12a},
  organization = {{Docear}},
  owner = {admin},
  keywords = {!jb,!jb_author,\#nosource,jabref_imp2}
}

@article{Beel12LitRev,
  title = {A {{Thorough Literature Review}} on {{User Modeling}}},
  author = {Beel, Joeran},
  date = {2012},
  journaltitle = {under review},
  oldkey = {Beel12b},
  owner = {admin},
  keywords = {!jb,!jb_author,\#nosource,⛔ No DOI found,jabref_imp2}
}

@inproceedings{BeelABG17,
  title = {Mr. {{DLib}}: {{Recommendations}}-as-a-{{Service}} ({{RaaS}}) for {{Academia}}},
  booktitle = {Proceedings of the {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Beel, Joeran and Aizawa, Akiko and Breitinger, Corinna and Gipp, Bela},
  date = {2017},
  doi = {10/ggv8d9},
  oldkey = {Beel2017g},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2017g.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RG662VCR\\BeelABG17--mr_dlib_recommendations-as-a-service_raas_for_academia.pdf}
}

@article{BeelBLL16,
  title = {Towards {{Reproducibility}} in {{Recommender}}-{{Systems Research}}},
  author = {Beel, Joeran and Breitinger, Corinna and Langer, Stefan and Lommatzsch, Andreas and Gipp, Bela},
  date = {2016},
  journaltitle = {User Modeling and User-Adapted Interaction (UMUAI)},
  volume = {26},
  pages = {69--101},
  issn = {1573-1391},
  doi = {10/f3r385},
  abstract = {Numerous recommendation approaches are in use today. However, comparing their effectiveness is a challenging task because evaluation results are rarely reproducible. In this article, we examine the challenge of reproducibility in recommender-system research. We conduct experiments using Plista's news recommender system, and Docear's research-paper recommender system. The experiments show that there are large discrepancies in the effectiveness of identical recommendation approaches in only slightly different scenarios, as well as large discrepancies for slightly different approaches in identical scenarios. For example, in one news-recommendation scenario, the performance of a content-based filtering approach was twice as high as the second-best approach, while in another scenario the same content-based filtering approach was the worst performing approach. We found several determinants that may contribute to the large discrepancies observed in recommendation effectiveness. Determinants we examined include user characteristics (gender and age), datasets, weighting schemes, the time at which recommendations were shown, and user-model size. Some of the determinants have interdependencies. For instance, the optimal size of an algorithms' user model depended on users' age. Since minor variations in approaches and scenarios can lead to significant changes in a recommendation approach's performance, ensuring reproducibility of experimental results is difficult. We discuss these findings and conclude that to ensure reproducibility, the recommender-system community needs to (1) survey other research fields and learn from them, (2) find a common understanding of reproducibility, (3) identify and understand the determinants that affect reproducibility, (4) conduct more comprehensive experiments, (5) modernize publication practices, (6) foster the development and use of recommendation frameworks, and (7) establish best-practice guidelines for recommender-systems research.},
  oldkey = {JoeranBeelEtAl2016a},
  preprint = {https://ag-gipp.github.io/bib/preprints/joeranbeeletal2016a.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\6GGLFBRF\\BeelBLL16--towards_reproducibility_in_recommender-systems_research.pdf}
}

@book{BeelG05,
  title = {{{ePass}} - der neue biometrische {{Reisepass}}},
  author = {Beel, Joeran and Gipp, Bela},
  date = {2005-10},
  publisher = {{Shaker Verlag}},
  location = {{Aachen, Germany}},
  url = {http://www.epass-buch.de},
  oldkey = {Beel05},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel05.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\7LMXSW42\\BeelG05--epass_-_der_neue_biometrische_reisepass.pdf}
}

@inproceedings{BeelG08ICADLPeer,
  title = {Collaborative {{Document Evaluation}}: {{An Alternative Approach}} to {{Classic Peer Review}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Digital Libraries}} ({{ICADL}}'08)},
  author = {Beel, Joeran and Gipp, Bela},
  date = {2008-08},
  volume = {31},
  location = {{Vienna, Austria}},
  doi = {10.1007/978-3-540-89533-6_48},
  oldkey = {Beel08a},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel08a.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\8A39672A\\BeelG08ICADLPeer--collaborative_document_evaluation_an_alternative_approach_to_classic_peer_review.pdf}
}

@inproceedings{BeelG08ICADLScience,
  title = {The {{Potential}} of {{Collaborative Document Evaluation}} for {{Science}}},
  booktitle = {Proceedings of the 11th {{International Conference}} on {{Asia}}-{{Pacific Digital Libraries}} ({{ICADL}}'08)},
  author = {Beel, Joeran and Gipp, Bela},
  editor = {Buchanan, George and Masoodian, Masood and Cunningham, Sally Jo},
  date = {2008-12},
  series = {Lecture notes in computer science ({{LNCS}})},
  volume = {5362},
  publisher = {{Springer}},
  location = {{Heidelberg (Germany)}},
  doi = {10/cr5696},
  isbn = {978-3-540-89532-9},
  oldkey = {Beel08},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel08.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\3VJCQVJ2\\BeelG08ICADLScience--the_potential_of_collaborative_document_evaluation_for_science.pdf}
}

@inproceedings{BeelG09ISSI,
  title = {Google {{Scholar}}'s {{Ranking Algorithm}}: {{An Introductory Overview}}},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Scientometrics}} and {{Informetrics}} ({{ISSI}}'09)},
  author = {Beel, Joeran and Gipp, Bela},
  editor = {Larsen, Birger and Leta, Jacqueline},
  date = {2009-07},
  volume = {1},
  publisher = {{International Society for Scientometrics and Informetrics}},
  location = {{Rio de Janeiro, Brazil}},
  doi = {10/ctnht3},
  oldkey = {Beel09},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel09.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\VCSKF5F3\\BeelG09ISSI--google_scholars_ranking_algorithm_an_introductory_overview.pdf}
}

@inproceedings{BeelG09ITNG,
  title = {Google {{Scholar}}'s {{Ranking Algorithm}}: {{The Impact}} of {{Articles}}' {{Age}} ({{An Empirical Study}})},
  booktitle = {Proceedings of the 6th {{International Conference}} on {{Information Technology}}: {{New Generations}} ({{ITNG}}'09)},
  author = {Beel, Joeran and Gipp, Bela},
  editor = {Latifi, Shahram},
  date = {2009-04},
  publisher = {{IEEE}},
  location = {{Las Vegas, USA}},
  doi = {10/ctnht3},
  url = {https://dx.doi.org/10.1109/ITNG.2009.317},
  oldkey = {Beel09b},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\PKUBW98X\\BeelG09ITNG--google_scholars_ranking_algorithm_the_impact_of_articles_age_an_empirical_study.pdf}
}

@inproceedings{BeelG09RCIS,
  title = {Google {{Scholar}}'s {{Ranking Algorithm}}: {{The Impact}} of {{Citation Counts}} ({{An Empirical Study}})},
  booktitle = {Proceedings of the 3rd {{IEEE International Conference}} on {{Research Challenges}} in {{Information Science}} ({{RCIS}}'09)},
  author = {Beel, Joeran and Gipp, Bela},
  editor = {Flory, Andra and Collard, Martine},
  date = {2009-04},
  publisher = {{IEEE}},
  location = {{Fez, Morocco}},
  doi = {10/cgdtdm},
  oldkey = {Beel09a},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel09a.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\8YYUP34D\\BeelG09RCIS--google_scholars_ranking_algorithm_the_impact_of_citation_counts_an_empirical_study.pdf}
}

@inproceedings{BeelG10HTEnh,
  title = {Enhancing {{Information Search}} by {{Utilizing Mind Maps}}},
  booktitle = {Proceedings of the 21st {{ACM Conference}} on {{Hypertext}} and {{Hypermedia}} ({{HT}}'10)},
  author = {Beel, Joeran and Gipp, Bela},
  date = {2010-06},
  publisher = {{ACM}},
  location = {{Toronto, Canada}},
  doi = {10/cvtkz2},
  oldkey = {Beel10d},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel10d.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\PDD4GWXD\\BeelG10HTEnh--enhancing_information_search_by_utilizing_mind_maps.pdf}
}

@inproceedings{BeelG10HTRobust,
  title = {On the {{Robustness}} of {{Google Scholar Against Spam}}},
  booktitle = {Proceedings of the 21st {{ACM Conference}} on {{Hypertext}} and {{Hypermedia}} ({{HT}}'10)},
  author = {Beel, Joeran and Gipp, Bela},
  date = {2010-06},
  publisher = {{ACM}},
  location = {{Toronto, Canada}},
  doi = {10/dnbz6f},
  oldkey = {Beel10c},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel10c.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\LBIEBRN8\\BeelG10HTRobust--on_the_robustness_of_google_scholar_against_spam.pdf}
}

@inproceedings{BeelG10ICUIMC,
  title = {Link {{Analysis}} in {{Mind Maps}}: {{A New Approach To Determine Document Relatedness}}},
  booktitle = {Proceedings of the 4th {{ACM International Conference}} on {{Ubiquitous Information Management}} and {{Communication}} ({{ICUIMC}}'10)},
  author = {Beel, Joeran and Gipp, Bela},
  date = {2010-01},
  location = {{Seoul, Korea}},
  doi = {10/fznhkc},
  oldkey = {Beel10a},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel10a.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\USDQ2YKJ\\BeelG10ICUIMC--link_analysis_in_mind_maps_a_new_approach_to_determine_document_relatedness.pdf}
}

@article{BeelG10JEP,
  title = {Academic {{Search Engine Spam}} and {{Google Scholar}}'s {{Resilience Against}} it},
  author = {Beel, Joeran and Gipp, Bela},
  date = {2010-12},
  journaltitle = {Journal of Electronic Publishing},
  volume = {13},
  number = {3},
  doi = {10/bpzqdq},
  oldkey = {Beel2010},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2010.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\BU83PHFJ\\BeelG10JEP--academic_search_engine_spam_and_google_scholars_resilience_against_it.pdf}
}

@article{BeelGLB15,
  title = {Research-{{Paper Recommender Systems}}: {{A Literature Survey}}},
  author = {Beel, Joeran and Gipp, Bela and Langer, Stefan and Breitinger, Corinna},
  date = {2015},
  journaltitle = {International Journal on Digital Libraries},
  pages = {1--34},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {1432-5012},
  doi = {10/gddp66},
  oldkey = {Beel2014a},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2014a.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\IKVE5DZI\\BeelGLB15--research-paper_recommender_systems_a_literature_survey.pdf}
}

@inproceedings{BeelGLG11JCDLDocear,
  title = {Docear: {{An Academic Literature Suite}} for {{Searching}}, {{Organizing}} and {{Creating Academic Literature}}},
  booktitle = {Proceedings of the 11th {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}}`11)},
  author = {Beel, Joeran and Gipp, Bela and Langer, Stefan and Genzmehr, Marcel},
  date = {2011},
  publisher = {{ACM}},
  doi = {10/fcwdgc},
  oldkey = {Beel2011c},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2011c.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ISR4RYDF\\BeelGLG11JCDLDocear--docear_an_academic_literature_suite_for_searching_organizing_and_creating_academic.pdf}
}

@inproceedings{BeelGLG11JCDLMrDLib,
  title = {Introducing {{Mr}}. {{DLib}}, a {{Machine}}-readable {{Digital Library}}},
  booktitle = {Proceedings of the 11th {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}}`11)},
  author = {Beel, Joeran and Gipp, Bela and Langer, Stefan and Genzmehr, Marcel and Wilde, Erik and Nuernberger, Andreas and Pitman, Jim},
  date = {2011-06},
  location = {{Ottawa, Canada}},
  doi = {10/fft9wc},
  oldkey = {Beel2011b},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2011b.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\MHZK6WK7\\BeelGLG11JCDLMrDLib--introducing_mr_dlib_a_machine-readable_digital_library.pdf}
}

@article{BeelGM09,
  title = {'{{SciPlore MindMapping}}' - {{A Tool}} for {{Creating Mind Maps Combined}} with {{PDF}} and {{Reference Management}}},
  author = {Beel, Joeran and Gipp, Bela and Mueller, Christoph},
  date = {2009-11},
  journaltitle = {D-Lib Magazine},
  volume = {15},
  number = {11},
  doi = {10/c3nhc9},
  url = {https://www.dlib.org/dlib/november09/11inbrief.html},
  oldkey = {Beel09c},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel09c.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\IEBAQWPA\\BeelGM09--sciplore_mindmapping_-_a_tool_for_creating_mind_maps_combined_with_pdf_and_reference.pdf}
}

@inproceedings{BeelGS09,
  title = {Information {{Retrieval}} on {{Mind Maps}} - {{What Could}} it be {{Good For}}?},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Collaborative Computing}}: {{Networking}}, {{Applications}} and {{Worksharing}} ({{CollaborateCom}}'09)},
  author = {Beel, Joeran and Gipp, Bela and Stiller, Jan-Olaf},
  date = {2009-11},
  publisher = {{IEEE}},
  location = {{Washington, USA}},
  doi = {10/gf26g4},
  oldkey = {Beel09f},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel09f.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  annotation = {BeelGS09Collab},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\J3ISCB3L\\BeelGS09--information_retrieval_on_mind_maps_-_what_could_it_be_good_for.pdf}
}

@inproceedings{BeelGS09ICMLDA,
  title = {Could {{Mind Maps Be Used To Improve Academic Search Engines}}?},
  booktitle = {Proceedings of the {{International Conference}} on {{Machine Learning}} and {{Data Analysis}} ({{ICMLDA}}'09)},
  author = {Beel, Joeran and Gipp, Bela and Stiller, Jan-Olaf},
  editor = {Ao, S. I. and Douglas, C. and Grundfest, W. S. and Burgstone, J.},
  date = {2009-10},
  series = {Lecture notes in engineering and computer science},
  volume = {2},
  publisher = {{Newswood Limited}},
  location = {{Berkeley, USA}},
  oldkey = {Beel09e},
  organization = {{International Association of Engineers (IAENG)}},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel09e.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{BeelGSF10,
  title = {{{SciPlore Xtract}}: {{Extracting Titles}} from {{Scientific PDF Documents}} by {{Analyzing Style Information}} ({{Font Size}})},
  booktitle = {Research and {{Advanced Technology}} for {{Digital Libraries}}: {{Proceedings}} of the 14th {{European Conference}} on {{Digital Libraries}} ({{ECDL}}'10)},
  author = {Beel, Joeran and Gipp, Bela and Shaker, Ammar and Friedrich, Nick},
  editor = {Lalmas, M. and Jose, J. and Rauber, A. and Sebastiani, F. and Frommholz, I.},
  date = {2010-09},
  series = {Lecture notes of computer science ({{LNCS}})},
  volume = {6273},
  publisher = {{Springer}},
  location = {{Glasgow, UK}},
  doi = {10/crhzk5},
  oldkey = {Beel10e},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel10e.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\LHRUHU3X\\BeelGSF10--sciplore_xtract_extracting_titles_from_scientific_pdf_documents_by_analyzing_style.pdf}
}

@article{BeelGW10,
  title = {Academic {{Search Engine Optimization}} ({{ASEO}}): {{Optimizing Scholarly Literature}} for {{Google Scholar}} and {{Co}}},
  author = {Beel, Joeran and Gipp, Bela and Wilde, Erik},
  date = {2010-01},
  journaltitle = {Journal of Scholarly Publishing},
  volume = {41},
  number = {2},
  pages = {176--190},
  doi = {10/btjd8c},
  oldkey = {Beel10},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel10.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\QFQURJE5\\BeelGW10--academic_search_engine_optimization_aseo_optimizing_scholarly_literature_for_google.pdf}
}

@inproceedings{BeelL11,
  title = {An {{Exploratory Analysis}} of {{Mind Maps}}},
  booktitle = {Proceedings of the 11th {{ACM Symposium}} on {{Document Engineering}} ({{DocEng}}'11)},
  author = {Beel, Joeran and Langer, Stefan},
  date = {2011},
  publisher = {{ACM}},
  doi = {10/cgg8jp},
  oldkey = {Beel11d},
  owner = {admin},
  keywords = {!jb,!jb_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\J2A7RHMP\\BeelL11--an_exploratory_analysis_of_mind_maps.pdf}
}

@inproceedings{BeelLG13,
  title = {Mind {{Map}} based {{Research Paper Recommendations}}},
  author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel},
  date = {2013},
  oldkey = {Beel13},
  owner = {joeran},
  keywords = {!jb,!jb_author,\#nosource,⛔ No DOI found,jabref_imp2}
}

@inproceedings{BeelLG13JCDL,
  title = {Introducing {{Docear}}'s {{Research Paper Recommender System}}},
  booktitle = {under review at {{JCDL}} 2013},
  author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel},
  date = {2013},
  doi = {10.1145/2467696.2467786},
  oldkey = {Beel13a},
  owner = {admin},
  keywords = {!jb,!jb_author,\#nosource,jabref_imp2}
}

@inproceedings{BeelLG13SIGIR,
  title = {User {{Modeling Based}} on {{Mind Maps}}: {{A Thorough Analysis}} of {{How Mind Maps Can Be Utilized}} to {{Generate Literature Recommendations}}},
  booktitle = {Under review at {{SIGIR}}'s 2013 {{Full Research Paper Track}}},
  author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel},
  date = {2013},
  pages = {141--150},
  oldkey = {JoeranBeel13},
  organization = {{ACM}},
  owner = {admin},
  keywords = {!jb,!jb_author,\#nosource,⛔ No DOI found,jabref_imp2}
}

@inproceedings{BeelLG14,
  title = {The {{Architecture}} and {{Datasets}} of {{Docear}}'s {{Research Paper Recommender System}}},
  booktitle = {Proceedings of the 3rd {{International Workshop}} on {{Mining Scientific Publications}} ({{WOSP}} 2014) at the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}} 2014)},
  author = {Beel, Joeran and Langer, Stefan and Gipp, Bela},
  date = {2014-09},
  location = {{London, UK}},
  doi = {10.1045/november14-beel},
  oldkey = {Beel14b},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel14b.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\SZRKRSNH\\BeelLG14--the_architecture_and_datasets_of_docears_research_paper_recommender_system.pdf}
}

@inproceedings{BeelLG17,
  title = {{{TF}}-{{IDuF}}: {{A Novel Term}}-{{Weighting Scheme}} for {{User Modeling}} based on {{Users}}' {{Personal Document Collections}}},
  booktitle = {Proceedings of the {{iConference}} 2017},
  author = {Beel, Joeran and Langer, Stefan and Gipp, Bela},
  date = {2017-03},
  location = {{Wuhan, China}},
  url = {https://ischools.org/the-iconference/},
  oldkey = {Beel17},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel17.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\FKB94RJH\\BeelLG17--tf-iduf_a_novel_term-weighting_scheme_for_user_modeling_based_on_users_personal_document.pdf}
}

@inproceedings{BeelLGG13Comp,
  title = {A {{Comparative Analysis}} of {{Offline}} and {{Online Evaluations}} and {{Discussion}} of {{Research Paper Recommender System Evaluation}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Reproducibility}} and {{Replication}} in {{Recommender Systems Evaluation}} ({{RepSys}}) at the {{ACM Recommender System Conference}} ({{RecSys}})},
  author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel and Gipp, Bela and Nuernberger, Andreas},
  date = {2013},
  series = {{{ACM}} international conference proceedings series ({{ICPS}})},
  doi = {10.1145/2532508.2532511},
  oldkey = {JoeranBeel2013},
  preprint = {https://ag-gipp.github.io/bib/preprints/joeranbeel2013.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{BeelLGG13RepSysEval,
  title = {Research {{Paper Recommender System Evaluation}}: {{A Quantitative Literature Survey}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Reproducibility}} and {{Replication}} in {{Recommender Systems Evaluation}} ({{RepSys}}) at the {{ACM Recommender System Conference}} ({{RecSys}})},
  author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel and Gipp, Bela and Breitinger, Corinna and Nuernberger, Andreas},
  date = {2013},
  series = {{{ACM}} international conference proceedings series ({{ICPS}})},
  doi = {10/ggv8d7},
  oldkey = {Beel2013i},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2013i.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\A98AS9W2\\BeelLGG13RepSysEval--research_paper_recommender_system_evaluation_a_quantitative_literature_survey.pdf}
}

@article{BeelLGN14,
  title = {The {{Architecture}} and {{Datasets}} of {{Docear}}'s {{Research Paper Recommender System}}},
  author = {Beel, Joeran and Langer, Stefan and Gipp, Bela and Nuernberger, Andreas},
  date = {2014-11},
  journaltitle = {D-Lib Magazine - The Magazine of Digital Library Research},
  volume = {20},
  number = {11/12},
  doi = {10/ggv8d5},
  url = {https://www.dlib.org/dlib/november14/beel/11beel.html},
  oldkey = {Beel14mdl},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel14mdl.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\JQX6VJMT\\BeelLGN14--the_architecture_and_datasets_of_docears_research_paper_recommender_system.pdf}
}

@inproceedings{BeelLGN14a,
  title = {Utilizing {{Mind}}-{{Maps}} for {{Information Retrieval}} and {{User Modelling}}},
  booktitle = {Proceedings of the 22nd {{Conference}} on {{User Modelling}}, {{Adaption}}, and {{Personalization}} ({{UMAP}})},
  author = {Beel, Joeran and Langer, Stefan and Gipp, Bela and Nuernberger, Andreas},
  editor = {Dimitrova, Vania and Kuflik, Tsvi and Chin, David and Ricci, Francesco and Dolog, Peter and Houben, Geert-Jan},
  date = {2014},
  series = {Lecture notes in computer science},
  volume = {8538},
  pages = {301--313},
  publisher = {{Springer}},
  doi = {10/ggv8d5},
  oldkey = {Beel2014d},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel2014d.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\M7EH94Z4\\BeelLGN14a--utilizing_mind-maps_for_information_retrieval_and_user_modelling.pdf}
}

@inproceedings{BeelLKB15,
  title = {Exploring the {{Potential}} of {{User Modeling}} based on {{Mind Maps}}},
  booktitle = {User {{Modeling}}, {{Adaptation}} and {{Personalization}} - 23rd {{International Conference}}, {{UMAP}} 2015, {{Dublin}}, {{Ireland}}},
  author = {Beel, Joeran and Langer, Stefan and Kapitsaki, Georgia M. and Breitinger, Corinna and Gipp, Bela},
  date = {2015-06},
  series = {Lecture notes of computer science},
  pages = {3--17},
  publisher = {{Springer}},
  doi = {10/ggv8d6},
  isbn = {978-3-319-20266-2},
  oldkey = {Beel15u},
  preprint = {https://ag-gipp.github.io/bib/preprints/beel15u.pdf},
  topic = {knowledgemgmt},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RFD6XSUV\\BeelLKB15--exploring_the_potential_of_user_modeling_based_on_mind_maps.pdf}
}

@inproceedings{BreitingerG17,
  title = {{{VirtualPatent}} - {{Enabling}} the {{Traceability}} of {{Ideas Shared Online}} using {{Decentralized Trusted Timestamping}}},
  booktitle = {Proceedings of the 15th {{International Symposium}} of {{Information Science}}},
  author = {Breitinger, Corinna and Gipp, Bela},
  editor = {Gaede, Maria and Trkulja, Violeta and Petra, Vivien},
  date = {2017-03},
  pages = {89--95},
  location = {{Berlin}},
  url = {http://edoc.hu-berlin.de/docviews/abstract.php?lang=ger&id=43360},
  oldkey = {Breitinger2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/breitinger2017.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\8MJG8MYJ\\BreitingerG17--virtualpatent_-_enabling_the_traceability_of_ideas_shared_online_using_decentralized.pdf}
}

@inproceedings{BreitingerGWR19,
  title = {‘{{Too Late}} to {{Collaborate}}’: {{Challenges}} to the {{Discovery}} of in-progress {{Research}}},
  booktitle = {Proceedings of the {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Breitinger, Corinna and Gipp, Bela and Wortner, Patrick and Reiterer, Harald},
  date = {2019-06},
  location = {{Urbana-Champaign, IL, USA}},
  oldkey = {Breitinger2019},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\UYZWSBTL\\BreitingerGWR19--too_late_to_collaborate_challenges_to_the_discovery_of_in-progress_research.pdf}
}

@inproceedings{BreitingerKMM20,
  ids = {BreitingerKMM20a},
  title = {Supporting the {{Exploration}} of {{Semantic Features}} in {{Academic Literature}} using {{Graph}}-based {{Visualizations}}},
  author = {Breitinger, Corinna and Kolcu, Birkan and Meuschke, Monique and Meuschke, Norman and Gipp, Bela},
  date = {2020-08},
  eventtitle = {Proceedings of the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  oldkey = {Breitinger2020},
  topic = {rec},
  keywords = {!bg,!bg_author,!cb,!cb_author,!nm,!nm_author,\#nosource,jabref_imp1_clean}
}

@inproceedings{CohlGS18,
  title = {Automated {{Symbolic}} and {{Numerical Testing}} of {{DLMF Formulae Using Computer Algebra Systems}}},
  booktitle = {Intelligent {{Computer Mathematics}} - 11th {{International Conference}}, {{CICM}} 2018, {{Hagenberg}}, {{Austria}}, {{August}} 13-17, 2018, {{Proceedings}}},
  author = {Cohl, Howard S. and Greiner-Petter, André and Schubotz, Moritz},
  editor = {Rabe, Florian and Farmer, William M. and Passmore, Grant O. and Youssef, Abdou},
  date = {2018},
  series = {Lecture notes in computer science},
  volume = {11006},
  pages = {39--52},
  publisher = {{Springer}},
  doi = {10/ggv8dn},
  url = {http://hcohl.sdf.org/CICM2018_Chap4.pdf},
  biburl = {https://dblp.uni-trier.de/rec/bibtex/conf/mkm/CohlGS18},
  oldkey = {Cohl2018},
  url_orig = {https://doi.org/10.1007/978-3-319-96812-4₄},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\NUXXS3WC\\CohlGS18--automated_symbolic_and_numerical_testing_of_dlmf_formulae_using_computer_algebra.pdf}
}

@inproceedings{CohlMSS14,
  ids = {CohlMSS14a},
  title = {Digital {{Repository}} of {{Mathematical Formulae}}},
  booktitle = {Intelligent {{Computer Mathematics}} - {{International Conference}}, {{CICM}} 2014, {{Coimbra}}, {{Portugal}}, {{July}} 7-11, 2014. {{Proceedings}}},
  author = {Cohl, Howard S. and McClain, Marjorie A. and Saunders, Bonita V. and Schubotz, Moritz and Williams, Janelle C.},
  editor = {Watt, Stephen M. and Davenport, James H. and Sexton, Alan P. and Sojka, Petr and Urban, Josef},
  date = {2014},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {8543},
  pages = {419--422},
  publisher = {{Springer}},
  doi = {10.1007/978-3-319-08434-3_30},
  biburl = {https://dblp.org/rec/bib/conf/mkm/CohlMSSW14},
  jabref-groups = {phd-m},
  oldkey = {Cohl2014},
  owner = {Moritz},
  preprint = {https://arxiv.org/pdf/1404.6519.pdf},
  keywords = {!ms,!ms_author,!ms_cv,\#nosource,cicm,conference,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{CohlSMS15,
  ids = {CohlSMS15a},
  title = {Growing the {{Digital Repository}} of {{Mathematical Formulae}} with {{Generic Sources}}},
  shorttitle = {Growing the drmf with generic sources},
  booktitle = {Intelligent {{Computer Mathematics}}, {{Lecture Notes}} in {{Artificial Intelligence}} 9150},
  author = {Cohl, Howard S. and Schubotz, Moritz and McClain, Marjorie A. and Saunders, Bonita V. and Zou, Cherry Y. and Mohammed, Azeem S. and Danoff, Alex A.},
  editor = {Kerber, Manfred and Carette, Jacques and Kaliszyk, Cezary and Rabe, Florian and Sorge, Volker},
  date = {2015},
  series = {{{LNCS}}},
  volume = {9150},
  pages = {280--287},
  publisher = {{Springer}},
  doi = {10/ggv8dm},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/mkm/CohlSMSZMD15},
  jabref-groups = {phd-m},
  oldkey = {Cohl2015},
  owner = {Moritz},
  preprint = {https://arxiv.org/pdf/1505.01431.pdf},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RSDWGBZJ\\CohlSMS15--growing_the_digital_repository_of_mathematical_formulae_with_generic_sources.pdf}
}

@inproceedings{CohlSYG17,
  title = {Semantic {{Preserving Bijective Mappings}} of {{Mathematical Formulae Between Document Preparation Systems}} and {{Computer Algebra Systems}}},
  booktitle = {Intelligent {{Computer Mathematics}} - 10th {{International Conference}}, {{CICM2017}}, {{Edinburgh}}, {{Uk}}, {{July}} 17-21, 2017, {{Proceedings}}},
  author = {Cohl, Howard S. and Schubotz, Moritz and Youssef, Abdou and Greiner-Petter, André and Gerhard, Jürgen and Saunders, Bonita V. and McClain, Marjorie A. and Bang, Joon and Chen, Kevin},
  editor = {Geuvers, Herman and England, Matthew and Hasan, Osman and Rabe, Florian and Teschke, Olaf},
  date = {2017},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {10383},
  pages = {115--131},
  publisher = {{Springer}},
  doi = {10/ggv8dk},
  url = {http://hcohl.sdf.org/drmfcas.pdf},
  biburl = {https://dblp.org/rec/bib/conf/mkm/CohlSYGGSMBC17},
  oldkey = {Cohl2017},
  owner = {Moritz},
  url_orig = {https://doi.org/10.1007/978-3-319-62075-6\_9},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\G2EFDNHG\\CohlSYG17--semantic_preserving_bijective_mappings_of_mathematical_formulae_between_document.pdf}
}

@inproceedings{CorneliS17,
  title = {math.wikipedia.org: {{A}} vision for a collaborative semi-formal, language independent math(s) encyclopedia},
  booktitle = {Conference on {{Artificial Intelligence}} and {{Theorem Proving}}},
  author = {Corneli, Joe and Schubotz, Moritz},
  date = {2017},
  url = {https://www.research.ed.ac.uk/portal/files/32938085/corneli2017math.pdf},
  biburl = {https://www.research.ed.ac.uk/portal/en/publications/mathwikipediaorg-a-vision-for-a-collaborative-semiformal-language-independent-maths-encyclopedia(9588c61f-5234-4f9d-a036-c7c3daac9307).bibtex?download=true},
  oldkey = {Corneli2017},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\2MYN2PYT\\CorneliS17--mathwikipediaorg_a_vision_for_a_collaborative_semi-formal_language_independent_maths.pdf}
}

@inproceedings{DahmSMG17,
  ids = {DahmSMG17a},
  title = {A {{Vision}} for {{Performing Social}} and {{Economic Data Analysis}} using {{Wikipedia}}'s {{Edit History}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{World Wide Web Companion}}},
  author = {Dahm, Erik and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
  date = {2017-04},
  pages = {1627--1634},
  publisher = {{ACM}},
  doi = {10/ggv8f3},
  url = {http://doi.acm.org/10.1145/3041021.3053363},
  abstract = {In this vision paper, we suggest combining two lines of research to study the collective behavior of Wikipedia contributors. The first line of research analyzes Wikipedia's edit history to quantify the quality of individual contributions and the resulting reputation of the contributor. The second line of research surveys Wikipedia contributors to gain insights, e.g., on their personal and professional background, socioeconomic status, or motives to contribute toWikipedia. While both lines of research are valuable on their own, we argue that the combination of both approaches could yield insights that exceed the sum of the individual parts. Linking survey data to contributor reputation and content-based quality metrics could provide a large-scale, public domain data set to perform user modeling, i.e. deducing interest profiles of user groups. User profiles can, among other applications, help to improve recommender systems. The resulting dataset can also enable a better understanding and improved prediction of high quality Wikipedia content and successfulWikipedia contributors. Furthermore, the dataset can enable novel research approaches to investigate team composition and collective behavior as well as help to identify domain experts and young talents. We report on the status of implementing our large-scale, content-based analysis of the Wikipedia edit history using the big data processing framework Apache Flink. Additionally, we describe our plans to conduct a survey among Wikipedia contributors to enhance the content-based quality metrics.},
  isbn = {978-1-4503-4914-7},
  oldkey = {Dahm2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/dahm2017.pdf},
  topic = {wiki},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,wikipedia},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\EAQ3C5XR\\DahmSMG17--a_vision_for_performing_social_and_economic_data_analysis_using_wikipedias_edit_history.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\VNK7WDTA\\DahmSMG17--a_vision_for_performing_social_and_economic_data_analysis_using_wikipedias_edit_history.pdf}
}

@inproceedings{EhretZG17,
  title = {University {{Rankings}} in {{Computer Science}}: {{A Study}} and {{Visualization}} of '{{Geo}}-{{Based}}' {{Impact}} and {{Conference Proceeding}} ({{CORE}}) {{Scores}}},
  booktitle = {Proceedings of {{ISSI}} 2017: 17th {{International Society}} of {{Scientometrics}} and {{Informetrics Conference}}},
  author = {Ehret, Philip and Zucalla, Alesia and Gipp, Bela},
  date = {2017-10},
  location = {{Wuhan, China}},
  oldkey = {Ehret2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/ehret2017.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\BD6AMVHR\\EhretZG17--university_rankings_in_computer_science_a_study_and_visualization_of_geo-based_impact.pdf}
}

@inproceedings{ElAssadySGK17,
  title = {{{NEREx}}: {{Named}}-{{Entity Relationship Exploration}} in {{Multi}}-{{Party Conversations}}},
  booktitle = {Proceedings of the {{Eurographics Conference}} on {{Visualization}} ({{EuroVis}})},
  author = {El-Assady, Mennatallah and Sevastjanova, Rita and Gipp, Bela and Keim, Daniel and Collins, Christopher},
  date = {2017},
  volume = {36},
  number = {3},
  doi = {10/gbnth4},
  oldkey = {Elassady2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/elassady2017.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\FZKNEDNQ\\ElAssadySGK17--nerex_named-entity_relationship_exploration_in_multi-party_conversations.pdf}
}

@inproceedings{FeyerSGA17,
  title = {Integration of the {{Scientific Recommender System Mr}}. {{DLib}} into the {{Reference Manager JabRef}}},
  booktitle = {Proceedings of the 29th {{European Conference}} on {{Information Retrieval}} ({{ECIR17}})},
  author = {Feyer, Stefan and Siebert, Sophie and Gipp, Bela and Aizawa, Akiko and Beel, Joeran},
  date = {2017-04},
  location = {{Aberdeen, Scotland}},
  url = {https://www.ecir2017.org/},
  oldkey = {Feyer17},
  preprint = {https://ag-gipp.github.io/bib/preprints/feyer17.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TBUTRNRH\\FeyerSGA17--integration_of_the_scientific_recommender_system_mr_dlib_into_the_reference_manager.pdf}
}

@article{FoltynekMG19,
  ids = {FoltynekMG19a},
  title = {Academic {{Plagiarism Detection}}: {{A Systematic Literature Review}}},
  author = {Foltýnek, Tomáš and Meuschke, Norman and Gipp, Bela},
  date = {2019-10},
  journaltitle = {ACM Comput. Surv.},
  volume = {52},
  number = {6},
  pages = {112:1-112:42},
  issn = {0360-0300},
  doi = {10/dcxc},
  abstract = {This article summarizes the research on computational methods to detect academic plagiarism by systematically reviewing 239 research papers published between 2013 and 2018. To structure the presentation of the research contributions, we propose novel technically oriented typologies for plagiarism prevention and detection efforts, the forms of academic plagiarism, and computational plagiarism detection methods. We show that academic plagiarism detection is a highly active research field. Over the period we review, the field has seen major advances regarding the automated detection of strongly obfuscated and thus hard-to-identify forms of academic plagiarism. These improvements mainly originate from better semantic text analysis methods, the investigation of non-textual content features, and the application of machine learning. We identify a research gap in the lack of methodologically thorough performance evaluations of plagiarism detection systems. Concluding from our analysis, we see the integration of heterogeneous analysis methods for textual and non-textual content features using machine learning as the most promising area for future research contributions to improve the detection of academic plagiarism further.},
  oldkey = {Foltynek2019},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\K3B2MC34\\FoltynekMG19--academic_plagiarism_detection_a_systematic_literature_review.pdf}
}

@incollection{FoltynekRSM20,
  ids = {FoltynekRSM20a},
  title = {Detecting {{Machine}}-{{Obfuscated Plagiarism}}},
  booktitle = {Sustainable {{Digital Communities}}},
  author = {Foltýnek, Tomáš and Ruas, Terry and Scharpf, Philipp and Meuschke, Norman and Schubotz, Moritz and Grosky, William and Gipp, Bela},
  editor = {Sundqvist, Anneli and Berget, Gerd and Nolin, Jan and Skjerdingstad, Kjell Ivar},
  date = {2020-03},
  volume = {12051 LNCS},
  pages = {816--827},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-43687-2_68},
  url = {http://link.springer.com/10.1007/978-3-030-43687-2_68},
  abstract = {Research on academic integrity has identified online paraphrasing tools as a severe threat to the effectiveness of plagiarism detection systems. To enable the automated identification of machine-paraphrased text, we make three contributions. First, we evaluate the effectiveness of six prominent word embedding models in combination with five classifiers for distinguishing human-written from machine-paraphrased text. The best performing classification approach achieves an accuracy of 99.0\% for documents and 83.4\% for paragraphs. Second, we show that the best approach outperforms human experts and established plagiarism detection systems for these classification tasks. Third, we provide a Web application that uses the best performing classification approach to indicate whether a text underwent machine-paraphrasing. The data and code of our study are openly available.},
  isbn = {978-3-030-43686-5 978-3-030-43687-2},
  langid = {english},
  oldkey = {Foltynek2020},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ZJQSG2ZF\\FoltynekRSM20--detecting_machine-obfuscated_plagiarism.pdf}
}

@inproceedings{FoltynekVMD20,
  title = {Cross-{{Language Source Code Plagiarism Detection}} using {{Explicit Semantic Analysis}} and {{Scored Greedy String Tilling}}},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Foltynek, Tomas and Vsiansky, Richard and Meuschke, Norman and Dlabolova, Dita and Gipp, Bela},
  date = {2020-08},
  doi = {10.1145/3383583.3398594},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,⚠️ Invalid DOI},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\GFY3GBP9\\FoltynekVMD20--NM--cross-language_source_code_plagiarism_detection_using_explicit_semantic_analysis.pdf}
}

@report{Gipp06,
  title = {({{Co}}-){{Citation Proximity Analysis}} - {{A Measure}} to {{Identify Related Work}}},
  author = {Gipp, Bela},
  date = {2006-02},
  institution = {{Doctoral Proposal, VLBA-Lab, Otto-von-Guericke University, Germany. Supervisor: Prof. Claus Rautenstrauch.}},
  url = {http://www.vlba-lab.de; http://www.ovgu.de/},
  oldkey = {Gipp2006},
  preprint = {https://www.vlba-lab.de; https://www.ovgu.de/},
  topic = {cit},
  keywords = {!bg,!bg_author,\#nosource,⛔ No DOI found,jabref_imp2,old_tex_field_preprint}
}

@incollection{Gipp09,
  title = {Very {{Large Business Applications}} ({{VLBA}}): {{Systemlandschaften}} der {{Zukunft}}},
  author = {Gipp, Bela},
  editor = {Arndt, H.-K. and Krcmar, H.},
  date = {2009-10},
  series = {3. {{Workshop}} des centers for very large business applications ({{CVLBA}})},
  pages = {163--173},
  publisher = {{Shaker Verlag}},
  location = {{Magdeburg}},
  chapter = {Entwicklung neuer Verfahren zur Bestimmung von Dokumentenaehnlichkeiten mittels Referenz- und Zitationsanalyse},
  oldkey = {Gipp09b},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp09b.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{Gipp10ECDL,
  title = {Measuring {{Document Relatedness}} by {{Citation Proximity Analysis}} and {{Citation Order Analysis}}},
  booktitle = {Research and {{Advanced Technology}} for {{Digital Libraries}}: {{Proceedings}} of the 14th {{European Conference}} on {{Digital Libraries}} ({{ECDL}}'10)},
  author = {Gipp, Bela},
  editor = {Lalmas, M. and Jose, J. and Rauber, A. and Sebastiani, F. and Frommholz, I.},
  date = {2010-09},
  series = {Lecture notes of computer science ({{LNCS}})},
  volume = {6273},
  publisher = {{Springer}},
  oldkey = {Gipp10d},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp10d.pdf},
  topic = {cit},
  keywords = {!bg,!bg_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@article{Gipp10Talk,
  title = {Citation {{Proximity Analysis}}},
  author = {Gipp, Bela},
  date = {2010-01},
  journaltitle = {Invited Talk: Seminar on Information Access at the School of Information, University of California, Berkeley; Invitation by Michael Buckland.},
  howpublished = {Invited Talk, Seminar on Information Access at the School of Information, University of California, Berkeley},
  oldkey = {Gipp10},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp10.pdf},
  topic = {cit},
  keywords = {!bg,!bg_author,\#nosource,⛔ No DOI found,jabref_imp2,old_tex_field_preprint}
}

@article{Gipp11,
  title = {Identifying {{Related Work}} and {{Plagiarism}} by {{Citation Analysis}}},
  author = {Gipp, Bela},
  date = {2011},
  journaltitle = {IEEE-TCDL Bulletin},
  volume = {7},
  oldkey = {Gipp11a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp11a.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\6PT6RK67\\Gipp11--identifying_related_work_and_plagiarism_by_citation_analysis.pdf}
}

@book{Gipp13,
  title = {Doctoral {{Thesis}}: {{Citation}}-based {{Plagiarism Detection}}: {{Applying Citation Pattern Analysis}} to {{Identify Currently Non}}-{{Machine}}-{{Detectable Disguised Plagiarism}} in {{Scientific Publications}}},
  author = {Gipp, Bela},
  date = {2013},
  publisher = {{University of Magdeburg / Department of Computer Science, Otto-von-Guericke University Magdeburg, Germany}},
  oldkey = {Gipp13a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp13a.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\BSEQPACJ\\Gipp13--doctoral_thesis_citation-based_plagiarism_detection_applying_citation_pattern_analysis.pdf}
}

@book{Gipp14,
  title = {Citation-based {{Plagiarism Detection}} - {{Detecting Disguised}} and {{Cross}}-language {{Plagiarism}} using {{Citation Pattern Analysis}}},
  author = {Gipp, Bela},
  date = {2014},
  publisher = {{Springer Vieweg Research / Department of Computer Science, Otto-von-Guericke-University Magdeburg, Germany}},
  doi = {0.1007/978-3-658-06394-8},
  url = {https://www.springer.com/978-3-658-06393-1},
  isbn = {978-3-658-06393-1},
  oldkey = {ThesisBelaGipp},
  pagetotal = {350},
  preprint = {https://ag-gipp.github.io/bib/preprints/thesisbelagipp.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\6FKVG3Q8\\Gipp14--citation-based_plagiarism_detection_-_detecting_disguised_and_cross-language_plagiarism.pdf}
}

@inproceedings{GippB09ISSI,
  title = {Citation {{Proximity Analysis}} ({{CPA}}) - {{A New Approach}} for {{Identifying Related Work Based}} on {{Co}}-{{Citation Analysis}}},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Scientometrics}} and {{Informetrics}} ({{ISSI}}'09)},
  author = {Gipp, Bela and Beel, Joeran},
  editor = {Larsen, Birger and Leta, Jacqueline},
  date = {2009-07},
  volume = {2},
  publisher = {{International Society for Scientometrics and Informetrics}},
  location = {{Rio de Janeiro, Brazil}},
  oldkey = {Gipp09a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp09a.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\X47G2TX5\\GippB09ISSI--citation_proximity_analysis_cpa_-_a_new_approach_for_identifying_related_work_based.pdf}
}

@inproceedings{GippB09WCECC,
  title = {Identifying {{Related Documents For Research Paper Recommender By CPA And COA}}},
  booktitle = {Proceedings of {{The World Congress}} on {{Engineering}} and {{Computer Science}} 2009},
  author = {Gipp, Bela and Beel, Joeran},
  editor = {Ao, S. I. and Douglas, C. and Grundfest, W. S. and Burgstone, J.},
  date = {2009-10},
  series = {Lecture notes in engineering and computer science},
  volume = {1},
  publisher = {{Newswood Limited}},
  location = {{Berkeley, USA}},
  isbn = {978-988-17012-6-8},
  oldkey = {Gipp09c},
  organization = {{International Association of Engineers (IAENG)}},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp09c.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@article{GippB10Google,
  title = {Integrating {{Citation Proximity Analysis}} into {{Google Books}} and {{Google Scholar}}},
  author = {Gipp, Bela and Beel, Joeran},
  date = {2010-01},
  journaltitle = {Invited Talk at Google Inc., Mountain View, Ca, USA},
  howpublished = {Invited Talk at Google Inc., Mountain View, CA, USA},
  oldkey = {Gipp10a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp10a.pdf},
  topic = {cit},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,⛔ No DOI found,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{GippB10HT,
  title = {Citation {{Based Plagiarism Detection}} - {{A New Approach}} to {{Identify Plagiarized Work Language Independently}}},
  booktitle = {Proceedings of the 21st {{ACM Conference}} on {{Hypertext}} and {{Hypermedia}} ({{HT}}'10)},
  author = {Gipp, Bela and Beel, Joeran},
  date = {2010-06},
  publisher = {{ACM}},
  location = {{Toronto, Ontario, Canada}},
  doi = {10/c9gh89},
  isbn = {978-1-4503-0041-4},
  oldkey = {Gipp10c},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp10c.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ALEXRTPI\\GippB10HT--citation_based_plagiarism_detection_-_a_new_approach_to_identify_plagiarized_work.pdf}
}

@patent{GippB10Pat,
  type = {patent},
  title = {({{WO2010078857}}) {{Detection}} of a {{Similarity}} of {{Documents}} by {{Citation Proximity Analysis}}},
  author = {Gipp, Bela and Beel, Joeran},
  date = {2010-10-15},
  number = {WO/2010/078857},
  url = {https://patentscope.wipo.int/search/en/WO2010078857},
  oldkey = {Gipp2010},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp2010.pdf},
  topic = {cit},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@patent{GippB11,
  type = {patent},
  title = {Method and {{System}} for {{Detecting}} a {{Similarity}} of {{Documents}}},
  author = {Gipp, Bela and Beel, Joeran},
  date = {2011-10-27},
  url = {https://www.patentlens.net/patentlens/patent/US_2011_0264672_A1/en/},
  abstract = {The invention relates to a method and a system for detecting a similarity of documents. The similarity of documents is detected with the help of an analysis of citations in one or more citation document(s), wherein the distance between the individual citations is used as criterion of the analysis. On the basis of the determined distance between two citations, respectively, a similarity value is determined, which is characteristic of the cited documents. A small distance between two citations leads to a high similarity of the cited documents. In case of several citations with regard to documents from several citation documents, the similarity values for the citation pairs from the individual citation documents are used for determining a final similarity value.},
  howpublished = {Patent Application},
  oldkey = {GIPP11pat},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp11pat.pdf},
  topic = {cit},
  version = {A1},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{GippBH09,
  title = {Scienstein: {{A Research Paper Recommender System}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Emerging Trends}} in {{Computing}} ({{ICETiC}}'09)},
  author = {Gipp, Bela and Beel, Joeran and Hentschel, Christian},
  date = {2009-01},
  publisher = {{IEEE}},
  location = {{Virudhunagar, India}},
  oldkey = {Gipp09},
  organization = {{Kamaraj College of Engineering and Technology India}},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp09.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\FX6FFT4P\\GippBH09--scienstein_a_research_paper_recommender_system.pdf}
}

@inproceedings{GippBMB17,
  ids = {GippBMB17a},
  title = {{{CryptSubmit}}: {{Introducing Securely Timestamped Manuscript Submission}} and {{Peer Review Feedback Using}} the {{Blockchain}}},
  booktitle = {Proceedings of the 17th {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Gipp, Bela and Breitinger, Corinna and Meuschke, Norman and Beel, Joeran},
  date = {2017-06},
  pages = {1--4},
  location = {{Toronto, Canada}},
  doi = {10/gd2447},
  abstract = {Manuscript submission systems are a central fixture in scholarly publishing. However, with existing systems, researchers must trust that their yet unpublished findings will not prematurely be disseminated due to technical weaknesses and that anonymous peer reviewers or committee members will not plagiarize unpublished content. To address this limitation, we present CryptSubmit - a system that automatically creates a decentralized, tamperproof, and publicly verifiable timestamp for each submitted manuscript by utilizing the blockchain of the cryptocurrency Bitcoin. The publicly accessible and tamperproof infrastructure of the blockchain allows researchers to independently verify the validity of the timestamp associated with their manuscript at the time of submission to a conference or journal. Our system supports researchers in protecting their intellectual property even in the face of vulnerable submission platforms or dishonest peer reviewers. Optionally, the system also generates trusted timestamps for the feedback shared by peer reviewers to increase the traceability of ideas. CryptSubmit integrates these features into the open source conference management system OJS. In the future, the method could be integrated at nearly no overhead cost into other manuscript submission systems, such as EasyChair, ConfTool, or Ambra. The introduced method can also improve electronic pre-print services and storage systems for research data.},
  isbn = {978-1-5386-3861-3},
  oldkey = {Gipp2017b},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp2017b.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\PES2HU3A\\GippBMB17--cryptsubmit_introducing_securely_timestamped_manuscript_submission_and_peer_review.pdf}
}

@article{GippBP01,
  title = {Der {{GSM}}-{{Schutzengel}} ("{{The GSM}} guardian angel")},
  author = {Gipp, Bela and Beel, Joeran and Petersen, Lars},
  date = {2001},
  journaltitle = {Research project in the national competition of the Foundation 'Jugend forscht', (Germany's premier youth science competition); http://www.gsm-schutzengel.de, Hamburg, Germany},
  abstract = {Jedes Jahr sterben auf deutschen Strassen 7.000 Menschen durch Verkehrsunfaelle. Davon koennten ueber 700 vor dem Tod bewahrt werden, wenn die Rettungsdienste unverzueglich nach dem Unfall informiert wuerden. Leider kommt es immer wieder vor, dass Verunfallte erst nach Minuten oder gar Stunden gefunden werden und so wertvolle Zeit bis zur Benachrichtigung der Rettungskraefte verstreicht. Warum nicht das flaechendeckend verfuegbare Mobilfunknetz nutzen, um automatisch Hilfe herbeizuholen? Urspruenglich im Rahmen von Jugend-forscht entwickelten wir in den vergangenen zwei Jahren ein flexibles und kostenguenstiges Notrufsystem - den "GSM Schutzengel". Dieser sieht aus wie ein gewoehnlicher Mobiltelefonakku, enthaelt aber zusaetzlich einen Beschleunigungssensor und einen Mikrokontroller zum Auswerten der Messdaten. Mit dieser Technik ist es moeglich, jedes handelsuebliche Mobiltelefon zu einem mobilen Schutzengel aufzuruesten, der Unfaelle sicher erkennt. Fehlalarme, beispielsweise durch Vollbremsungen waehrend der Autofahrt oder Hinunterfallen des Mobiltelefons, sind dabei ausgeschlossen. Bei einem Unfall ruft der GSM Schutzengel sofort die Rettungskraefte herbei. Dadurch kann selbst bewusstlosen Fahrern schnellstmoeglich geholfen werden. Die Position des Unfalls wird dabei ueber das Mobilfunknetz bestimmt - bis auf 150 m genau. Somit kann zielgenaue Hilfe gewaehrleistet werden, denn wer kann schon direkt nach einem Unfall beschreiben, wo genau er ist?},
  oldkey = {Gipp01},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp01.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@book{GippBR07,
  title = {{{ePassport}}: {{The World}}'s {{New Electronic Passport}}},
  author = {Gipp, Bela and Beel, Joeran and Roessling, Ivo},
  date = {2007-10},
  publisher = {{Createspace}},
  location = {{Scotts Valley, USA}},
  url = {http://epassport-book.com},
  oldkey = {Gipp07},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp07.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\QL3AR6UI\\GippBR07--epassport_the_worlds_new_electronic_passport.pdf}
}

@inproceedings{GippKB16,
  title = {Securing {{Video Integrity Using Decentralized Trusted Timestamping}} on the {{Blockchain}}},
  booktitle = {Proceedings of the 10th {{Mediterranean Conference}} on {{Information Systems}} ({{MCIS}})},
  author = {Gipp, Bela and Kosti, Jagrut and Breitinger, Corinna},
  date = {2016-09},
  location = {{Paphos, Cyprus}},
  oldkey = {Gipp2016a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp2016a.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TC9GM37Q\\GippKB16--securing_video_integrity_using_decentralized_trusted_timestamping_on_the_blockchain.pdf}
}

@inproceedings{GippM11,
  ids = {GippM11a},
  title = {Citation {{Pattern Matching Algorithms}} for {{Citation}}-based {{Plagiarism Detection}}: {{Greedy Citation Tiling}}, {{Citation Chunking}} and {{Longest Common Citation Sequence}}},
  booktitle = {Proceedings of the 11th {{ACM Symposium}} on {{Document Engineering}}},
  author = {Gipp, Bela and Meuschke, Norman},
  date = {2011-09},
  pages = {249--258},
  publisher = {{ACM}},
  location = {{Mountain, View, CA, USA}},
  doi = {10/dmtt7w},
  abstract = {Plagiarism Detection Systems have been developed to locate instances of plagiarism e.g. within scientific papers. Studies have shown that the existing approaches deliver reasonable results in identifying copy\&paste plagiarism, but fail to detect more sophisticated forms such as paraphrased plagiarism, translation plagiarism or idea plagiarism. The authors of this paper demonstrated in recent studies that the detection rate can be significantly improved by not only relying on text analysis, but by additionally analyzing the citations of a document. Citations are valuable language independent markers that are similar to a fingerprint. In fact, our examinations of real world cases have shown that the order of citations in a document often remains similar even if the text has been strongly paraphrased or translated in order to disguise plagiarism. This paper introduces three algorithms and discusses their suitability for the purpose of citation-based plagiarism detection. Due to the numerous ways in which plagiarism can occur, these algorithms need to be versatile. They must be capable of detecting transpositions, scaling and combinations in a local and global form. The algorithms are coined Greedy Citation Tiling, Citation Chunking and Longest Common Citation Sequence. The evaluation showed that if these algorithms are combined, common forms of plagiarism can be detected reliably. ? 2011 ACM.},
  isbn = {978-1-4503-0863-2},
  oldkey = {Gipp11c},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp11c.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\6ZNKNBWR\\GippM11--citation_pattern_matching_algorithms_for_citation-based_plagiarism_detection_greedy.pdf}
}

@inproceedings{GippMB11,
  ids = {GippMB11a},
  title = {Comparative {{Evaluation}} of {{Text}}- and {{Citation}}-based {{Plagiarism Detection Approaches}} using {{GuttenPlag}}},
  booktitle = {Proceedings of 11th {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Gipp, Bela and Meuschke, Norman and Beel, Joeran},
  date = {2011-06},
  pages = {255--258},
  location = {{Ottawa, Canada}},
  doi = {10/d6q5xt},
  abstract = {Various approaches for plagiarism detection exist. All are based on more or less sophisticated text analysis methods such as string matching, fingerprinting or style comparison. In this paper a new approach called Citation-based Plagiarism Detection is evaluated using a doctoral thesis [8], in which a volunteer crowd-sourcing project called GuttenPlag [1] identified substantial amounts of plagiarism through careful manual inspection. This new approach is able to identify similar and plagiarized documents based on the citations used in the text. It is shown that citation-based plagiarism detection performs significantly better than text-based procedures in identifying strong paraphrasing, translation and some idea plagiarism. Detection rates can be improved by combining citation-based with text-based plagiarism detection.},
  isbn = {978-1-4503-0744-4},
  oldkey = {Gipp11},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp11.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TCB79GXX\\GippMB11--comparative_evaluation_of_text-_and_citation-based_plagiarism_detection_approaches.pdf}
}

@article{GippMB14,
  ids = {GippMB14a},
  title = {Citation-based {{Plagiarism Detection}}: {{Practicability}} on a {{Large}}-{{Scale Scientific Corpus}}},
  author = {Gipp, Bela and Meuschke, Norman and Breitinger, Corinna},
  date = {2014-08},
  journaltitle = {Journal of the Association for Information Science and Technology},
  volume = {65},
  number = {8},
  pages = {1527--1540},
  issn = {2330-1635},
  doi = {10.1002/asi.23228},
  abstract = {The automated detection of plagiarism is an information retrieval task of increasing importance as the volume of readily accessible information on the web expands. A major shortcoming of current automated plagiarism detection approaches is their dependence on high character-based similarity. As a result, heavily disguised plagiarism forms, such as paraphrases, translated plagiarism, or structural and idea plagiarism, remain undetected. A recently proposed language-independent approach to plagiarism detection, Citation-based Plagiarism Detection (CbPD), allows the detection of semantic similarity even in the absence of text overlap by analyzing the citation placement in a document's full text to determine similarity. This article evaluates the performance of CbPD in detecting plagiarism with various degrees of disguise in a collection of 185,000 biomedical articles. We benchmark CbPD against two character-based detection approaches using a ground truth approximated in a user study. Our evaluation shows that the citation-based approach achieves superior ranking performance for heavily disguised plagiarism forms. Additionally, we demonstrate CbPD to be computationally more efficient than character-based approaches. Finally, upon combining the citation-based with the traditional character-based document similarity visualization methods in a hybrid detection prototype, we observe a reduction in the required user effort for document verification.},
  oldkey = {Gipp13b},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp13b.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\I9MLFLM3\\GippMB14--citation-based_plagiarism_detection_practicability_on_a_large-scale_scientific_corpus.pdf}
}

@inproceedings{GippMBB16,
  ids = {GippMBB17},
  title = {Using the {{Blockchain}} of {{Cryptocurrencies}} for {{Timestamping Digital Cultural Heritage}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Web Archiving}} and {{Digital Libraries}} ({{WADL}}) held in conjunction with the 16th {{ACM}}/{{IEEE}}-{{CS Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Gipp, Bela and Meuschke, Norman and Beel, Joeran and Breitinger, Corinna},
  date = {2016},
  volume = {13},
  pages = {1--3},
  doi = {10.5281/zenodo.3547510},
  abstract = {The proportion of information that is exclusively available online is continuously increasing. Unlike physical print media, online news outlets, magazines, or blogs are not immune to retrospective modification. Even significant editing of text in online news sources can easily go unnoticed. This poses a challenge to the preservation of digital cultural heritage. It is nearly impossible for regular readers to verify whether the textual content they encounter online has at one point been modified from its initial state, and at what time or to what extent the text was modified to its current version. In this paper, we propose a web-based platform that allows users to submit the URL for any web content they wish to track for changes. The system automatically creates a trusted timestamp stored in the blockchain of the cryptocurrency Bitcoin for the hash of the HTML content available at the user-specified URL. By using trusted timestamping to secure a ‘snapshot’ of online information as it existed at a specific time, any subsequent changes made to the content can be identified.},
  oldkey = {Gipp2017a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp2017a.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!cb,!cb_author,!jb,!jb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\LL59CEU9\\GippMBB16--using_the_blockchain_of_cryptocurrencies_for_timestamping_digital_cultural_heritage.pdf}
}

@inproceedings{GippMBL13,
  ids = {GippMBL13a},
  title = {Demonstration of the {{First Citation}}-based {{Plagiarism Detection Prototype}}},
  booktitle = {Proceedings of the 36th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Gipp, Bela and Meuschke, Norman and Breitinger, Corinna and Lipinski, Mario and Nürnberger, Andreas},
  date = {2013-07},
  pages = {1119--1120},
  publisher = {{ACM}},
  location = {{Dublin, UK}},
  doi = {10/ggv8g2},
  oldkey = {Gipp13},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp13.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\35XT2UHW\\GippMBL13--demonstration_of_the_first_citation-based_plagiarism_detection_prototype.pdf}
}

@inproceedings{GippMBP14,
  ids = {GippMBP14a},
  title = {Web-based {{Demonstration}} of {{Semantic Similarity Detection Using Citation Pattern Visualization}} for a {{Cross Language Plagiarism Case}}},
  booktitle = {Proceedings {{International Conference}} on {{Enterprise Information Systems}} ({{ICEIS}})},
  author = {Gipp, Bela and Meuschke, Norman and Breitinger, Corinna and Pitman, Jim and Nürnberger, Andreas},
  date = {2014-04},
  volume = {2},
  pages = {677--683},
  location = {{Lisbon, Portugal}},
  doi = {10/c9wf},
  abstract = {In a previous paper, we showed that analyzing citation patterns in the well-known plagiarized thesis by K. T. zu Guttenberg clearly outperformed current detection methods in identifying cross-language plagiarism. However, the experiment was a proof of concept and we did not provide a prototype. This paper presents a fully functional, web-based visualization of citation patterns for this verified cross-language plagiarism case, allowing the user to interactively experience the benefits of citation pattern analysis for plagiarism detection. Using examples from the Guttenberg plagiarism case, we demonstrate that the citation pattern visualization reduces the required examiner effort to verify the extent of plagiarism. Copyright ? 2014 SCITEPRESS - Science and Technology Publications.},
  isbn = {978-989-758-028-4},
  oldkey = {gipp14a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp14a.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\4XHSQIYS\\GippMBP14--web-based_demonstration_of_semantic_similarity_detection_using_citation_pattern_visualization.pdf}
}

@inproceedings{GippMG15iConfTT,
  title = {Decentralized {{Trusted Timestamping}} using the {{Crypto Currency Bitcoin}}},
  booktitle = {Proceedings of the {{iConference}} 2015},
  author = {Gipp, Bela and Meuschke, Norman and Gernandt, Andre},
  date = {2015-03},
  location = {{Newport Beach, California}},
  doi = {10/ggv8g4},
  url = {http://ischools.org/the-iconference/},
  oldkey = {Gipp15a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp15a.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,!nm_author,!nm_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\CPA87IZC\\GippMG15iConfTT--decentralized_trusted_timestamping_using_the_crypto_currency_bitcoin.pdf}
}

@inproceedings{GippML15,
  ids = {GippML15a},
  title = {{{CITREC}}: {{An Evaluation Framework}} for {{Citation}}-{{Based Similarity Measures}} based on {{TREC Genomics}} and {{PubMed Central}}},
  booktitle = {Proceedings of the {{iConference}}},
  author = {Gipp, Bela and Meuschke, Norman and Lipinski, Mario},
  date = {2015-03},
  location = {{Newport Beach, California}},
  doi = {10/ggv8g3},
  url = {http://hdl.handle.net/2142/73680},
  abstract = {Citation-based similarity measures such as Bibliographic Coupling and Co-Citation are an integral component of many information retrieval systems. However, comparisons of the strengths and weaknesses of measures are challenging due to the lack of suitable test collections. This paper presents CITREC, an open evaluation framework for citation-based and text-based similarity measures. CITREC prepares the data from the PubMed Central Open Access Subset and the TREC Genomics collection for a citation-based analysis and provides tools necessary for performing evaluations of similarity measures. To account for different evaluation purposes, CITREC implements 35 citation-based and text-based similarity measures, and features two gold standards. The first gold standard uses the Medical Subject Headings (MeSH) thesaurus and the second uses the expert relevance feedback that is part of the TREC Genomics collection to gauge similarity. CITREC additionally offers a system that allows creating user defined gold standards to adapt the evaluation framework to individual information needs and evaluation purposes.},
  oldkey = {Gipp15b},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp15b.pdf},
  topic = {cit},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RV3DG3HY\\GippML15--citrec_an_evaluation_framework_for_citation-based_similarity_measures_based_on_trec.pdf}
}

@article{GippS97,
  title = {Glasfaserbasierte analoge {{Bilduebertragung}} ("{{Fiber}} optic-based analog image transfer")},
  author = {Gipp, Bela and Stiller, Jan-Olaf},
  date = {1997},
  journaltitle = {Research project in the national competition of the Foundation 'Jugend forscht', (Germany's premier youth science competition), Hamburg, Germany},
  oldkey = {Gipp97},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp97.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,\#nosource,⛔ No DOI found,jabref_imp2,old_tex_field_preprint}
}

@article{GippS98,
  title = {Verlaengerung der {{Standby}}-{{Zeit}} von {{Mobiltelefonen}} mittels intelligenter {{Integration}} eines {{Zusatzempfaengers}} im 433 {{MHz}}-{{Bereich}} ("{{Extending}} cell phone standby time by intelligent integration of an additional receiver in the 433 {{MHz}}-field")},
  author = {Gipp, Bela and Stiller, Jan-Olaf},
  date = {1998},
  journaltitle = {Research project in the state-wide competition of the Foundation 'Jugend forscht', (Germany's premier youth science competition) Hamburg, Germany},
  oldkey = {Gipp98},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp98.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@article{GippS99,
  title = {Der {{High}}-{{Tech Bernhardiner}} - {{Ein Rettungssystem}} fuer {{Lawinenopfer}} ("{{The High}}-tech {{St}}. {{Bernhard}} - an avalanche rescue system")},
  author = {Gipp, Bela and Stiller, Jan-Olaf},
  date = {1999},
  journaltitle = {Research project in the state-wide competition of the Foundation 'Jugend forscht', (Germany's premier youth science competition); http://www.gsm-schutzengel.de/hightec-index.shtml, Hamburg, Germany},
  abstract = {"Wo Menschen von Lawinen verschuettet werden, zaehlt bei der Rettung und Bergung jede Minute. Was in der Vergangenheit die traditionellen Lawinenhunde geleistet haben, muss in Zeiten des Massen-Tourismus mit technischem Know-how geloest werden. Die Idee von Bela Gipp, Jan-Olaf Stiller und Florian Krueger: Ein System, bei dem eine Infrarotkamera von einem Modellhubschrauber aus Bilder an ein Leitsystem weitergibt, auf dem sich die Temperaturunterschiede zwischen warmen Koerpern und Schnee erkennen lassen. Zur Orientierung des Hubschraubers dient eine zusaetzliche Echtfarbkamera, ein Ultraschallgeraet fuer schlechte Sicht und ein Global Positioning System (GPS). Alles kann mit einem Programm, das die jungen Erfinder geschrieben haben, ueber das Internet gesteuert und ausgewertet werden." 1999, Bundesjury 'Jugend forscht' zu dem Projekt "Der High-tech Bernhardiner"},
  oldkey = {Gipp99},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp99.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@patent{GippSB11,
  type = {patent},
  title = {({{WO2011044865}}) {{Method}} for {{Determining}} a {{Similarity}} of {{Objects}}},
  author = {Gipp, Bela and Stiller, Jan-Olaf and Beel, Joeran},
  date = {2011-04-21},
  number = {WO/2011/044865},
  url = {https://www.wipo.int/patentscope/search/en/WO2011044865},
  oldkey = {Gipp2011a},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp2011a.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!jb,!jb_author,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{GippTB10,
  title = {Link {{Proximity Analysis}} - {{Clustering Websites}} by {{Examining Link Proximity}}},
  booktitle = {Research and {{Advanced Technology}} for {{Digital Libraries}}: {{Proceedings}} of the 14th {{European Conference}} on {{Digital Libraries}} ({{ECDL}}'10)},
  author = {Gipp, Bela and Taylor, Adriana and Beel, Joeran},
  editor = {Lalmas, M. and Jose, J. and Rauber, A. and Sebastiani, F. and Frommholz, I.},
  date = {2010-09},
  series = {Lecture notes of computer science ({{LNCS}})},
  volume = {6273},
  publisher = {{Springer}},
  oldkey = {Gipp10b},
  preprint = {https://ag-gipp.github.io/bib/preprints/gipp10b.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\DVK8A8VU\\GippTB10--link_proximity_analysis_-_clustering_websites_by_examining_link_proximity.pdf}
}

@report{GomezQuesadaIMT08,
  title = {{{BoKlok Sweet Boklok}}: {{A Joint Innovation}} of {{Skanska}} and {{IKEA}}},
  author = {Gomez Quesada, Victoria and Idone, Claudia and Meuschke, Norman and Teboul, Nicolas},
  date = {2008-01-08},
  doi = {10.5281/zenodo.3548729},
  abstract = {Test},
  keywords = {!nm_author,!nm_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RDYJ5DK5\\GomezQuesadaIMT08--boklok_sweet_boklok_a_joint_innovation_of_skanska_and_ikea.pdf}
}

@inproceedings{GreinerPetterRSA19,
  ids = {GreinerPetter2019b},
  title = {Why {{Machines Cannot Learn Mathematics}}, {{Yet}}},
  booktitle = {4th {{Joint Workshop}} on {{Bibliometric}}-{{Enhanced Information Retrieval}} and {{Natural Language Processing}} for {{Digital Libraries}} co-located with the 42nd {{Annual International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Greiner-Petter, Andre and Ruas, Terry and Schubotz, Moritz and Aizawa, Akiko and Grosky, William and Gipp, Bela},
  date = {2019},
  location = {{Paris, France}},
  oldkey = {GreinerPetter2019a},
  topic = {mathir},
  url_orig = {http://ceur-ws.org/Vol-2414/paper14.pdf},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\54EPBT3R\\GreinerPetterRSA19--why_machines_cannot_learn_mathematics_yet.pdf}
}

@inproceedings{GreinerPetterSCG18,
  ids = {GreinerPetterSCG18a},
  title = {{{MathTools}}: {{An}} open {{API}} for convenient {{MathML}} handling},
  booktitle = {Intelligent {{Computer Mathematics}} - 11th {{International Conference}}, {{CICM}} 2018, {{Hagenberg}}, {{Austria}}, {{August}} 13-17, 2018, {{Proceedings}}},
  author = {Greiner-Petter, André and Schubotz, Moritz and Cohl, Howard S. and Gipp, Bela},
  editor = {Rabe, Florian and Farmer, William M. and Passmore, Grant O. and Youssef, Abdou},
  date = {2018},
  series = {Lecture notes in computer science},
  volume = {11006},
  pages = {104--110},
  publisher = {{Springer}},
  doi = {10.1007/978-3-319-96812-4\\_9},
  url = {https://www.gipp.com/wp-content/papercite-data/pdf/greinerpetter2018.pdf},
  biburl = {https://dblp.org/rec/bib/conf/mkm/Greiner-PetterS18},
  oldkey = {Greiner-Petter2018},
  topic = {mathir},
  url_orig = {https://doi.org/10.1007/978-3-319-96812-4\_9},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\DWFDM4GT\\GreinerPetterSCG18--mathtools_an_open_api_for_convenient_mathml_handling.pdf}
}

@article{GreinerPetterSCG19,
  title = {Semantic {{Preserving Bijective Mappings}} for {{Expressions Involving Special Functions}} in {{Computer Algebra Systems}} and {{Document Preparation Systems}}},
  author = {Greiner-Petter, Andre and Schubotz, Moritz and Cohl, Howard S. and Gipp, Bela},
  date = {2019-07},
  journaltitle = {Aslib Journal of Information Management},
  volume = {71},
  number = {3},
  pages = {415--439},
  issn = {2050-3806},
  doi = {10/ggv8gx},
  biburl = {https://www.emeraldinsight.com/action/showCitFormats?doi=10.1108\%2FAJIM-08-2018-0185},
  oldkey = {GreinerPetter2019},
  preprint = {https://ag-gipp.github.io/bib/preprints/greinerpetter2019.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\GFDVPJXL\\GreinerPetterSCG19--semantic_preserving_bijective_mappings_for_expressions_involving_special_functions.pdf}
}

@inproceedings{GreinerPetterSMB20,
  title = {Discovering {{Mathematical Objects}} of {{Interest}} - a {{Study}} of {{Mathematical Notations}}},
  booktitle = {Proceedings of the {{Web Conference}} 2020 ({{WWW}}'20), {{April}} 20–24, 2020, {{Taipei}}, {{Taiwan}}},
  author = {Greiner-Petter, André and Schubotz, Moritz and Müller, Fabian and Breitinger, Corinna and Cohl, Howard S. and Aizawa, Akiko and Gipp, Bela},
  date = {2020-04},
  doi = {10/ggv8gw},
  core = {0;Core Rank A*;http://portal.core.edu.au/conf-ranks/1548/},
  oldkey = {GreinerPetter2020},
  preprint = {https://ag-gipp.github.io/bib/preprints/greinerpetter2020.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\GSHJW6W3\\GreinerPetterSMB20--discovering_mathematical_objects_of_interest_-_a_study_of_mathematical_notations.pdf}
}

@inproceedings{HamborgBG19,
  title = {{{Giveme5W1H}}: {{A Universal System}} for {{Extracting Main Events}} from {{News Articles}}},
  booktitle = {Proceedings of the 13th {{ACM}} conference on recommender systems, 7th international workshop on news recommendation and analytics ({{INRA}} 2019)},
  author = {Hamborg, Felix and Breitinger, Corinna and Gipp, Bela},
  date = {2019-09},
  location = {{Copenhagen, Denmark}},
  oldkey = {Hamborg2019b},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!fh,!fh_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ZEEDBQY7\\HamborgBG19--giveme5w1h_a_universal_system_for_extracting_main_events_from_news_articles.pdf}
}

@inproceedings{HamborgBSL18,
  title = {Extraction of {{Main Event Descriptors}} from {{News Articles}} by {{Answering}} the {{Journalistic Five W}} and {{One H Questions}}},
  booktitle = {Proceedings of the 18th {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}}) {{Fort Worth}}, {{TX}}, {{USA}}, {{June}} 03-07, 2018},
  author = {Hamborg, Felix and Breitinger, Corinna and Schubotz, Moritz and Lachnit, Soeren and Gipp, Bela},
  editor = {Chen, Jiangping and Gonçalves, Marcos André and Allen, Jeff M. and Fox, Edward A. and Kan, Min-Yen and Petras, Vivien},
  date = {2018},
  pages = {339--340},
  publisher = {{ACM}},
  doi = {10/ggv8gq},
  url = {http://doi.acm.org/10.1145/3197026.3203899},
  biburl = {https://dblp.uni-trier.de/rec/bibtex/conf/jcdl/HamborgBSLG18},
  core = {A*},
  oldkey = {Hamborg2018},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/hamborg2018a.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!fh,!fh_author,!ms,!ms_author,!ms_cv,!ms_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\F8W5WX8P\\HamborgBSL18--extraction_of_main_event_descriptors_from_news_articles_by_answering_the_journalistic.pdf}
}

@article{HamborgDG18,
  title = {Automated {{Identification}} of {{Media Bias}} in {{News Articles}}: {{An Interdisciplinary Literature Review}}},
  author = {Hamborg, Felix and Donnay, Karsten and Gipp, Bela},
  date = {2018},
  journaltitle = {International Journal on Digital Libraries (IJDL)},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10/ggv8pp},
  oldkey = {Hamborg2018c},
  preprint = {https://ag-gipp.github.io/bib/preprints/hamborg2018c.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\6K4PVCWT\\HamborgDG18--automated_identification_of_media_bias_in_news_articles_an_interdisciplinary_literature.pdf}
}

@inproceedings{HamborgEBG17,
  title = {Automated {{Generation}} of {{Timestamped Patent Abstracts}} at {{Scale}} to {{Outsmart Patent}}-{{Trolls}}},
  booktitle = {2nd {{Joint Workshop}} on {{Bibliometric}}-{{Enhanced Information Retrieval}} and {{Natural Language Processing}} for {{Digital Libraries}} ({{BINDL}} 2017) {{Held}} in {{Conjunction}} with the 40th {{Annual International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Hamborg, Felix and Elmaghraby, Moustafa and Breitinger, Corinna and Gipp, Bela},
  date = {2017-08},
  location = {{Tokyo, Japan}},
  oldkey = {Hamborg2017c},
  preprint = {https://ag-gipp.github.io/bib/preprints/hamborg2017c.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!fh,!fh_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\HERTIXCX\\HamborgEBG17--automated_generation_of_timestamped_patent_abstracts_at_scale_to_outsmart_patent.pdf}
}

@inproceedings{HamborgLSH18,
  title = {{{Giveme5W}}: {{Main Event Retrieval}} from {{News Articles}} by {{Extraction}} of the {{Five Journalistic W Questions}}},
  booktitle = {Transforming {{Digital Worlds}} - 13th {{International Conference}}, {{iConference}} 2018, {{Sheffield}}, {{Uk}}, {{March}} 25-28, 2018, {{Proceedings}}},
  author = {Hamborg, Felix and Lachnit, Soeren and Schubotz, Moritz and Hepp, Thomas and Gipp, Bela},
  editor = {Chowdhury, Gobinda and McLeod, Julie and Gillet, Valerie J. and Willett, Peter},
  date = {2018},
  series = {Lecture notes in computer science},
  volume = {10766},
  pages = {356--366},
  publisher = {{Springer}},
  doi = {10/ggv8pn},
  url = {https://doi.org/10.1007/978-3-319-78105-1_39},
  biburl = {https://dblp.org/rec/bib/conf/iconference/HamborgLSHG18},
  oldkey = {Hamborg2018a},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/hamborg2018.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!ms,!ms_author,!ms_cv,!ms_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\WYI6YCVW\\HamborgLSH18--giveme5w_main_event_retrieval_from_news_articles_by_extraction_of_the_five_journalistic.pdf}
}

@inproceedings{HamborgMAG17,
  ids = {HamborgMAG17a},
  title = {Identification and {{Analysis}} of {{Media Bias}} in {{News Articles}}},
  booktitle = {Proceedings of the 15th {{International Symposium}} of {{Information Science}}},
  author = {Hamborg, Felix and Meuschke, Norman and Aizawa, Akiko and Gipp, Bela},
  editor = {Gaede, Maria and Trkulja, Violeta and Petra, Vivien},
  date = {2017-03},
  pages = {224--236},
  location = {{Berlin}},
  doi = {10/ggv8pk},
  url = {http://edoc.hu-berlin.de/docviews/abstract.php?id=43364},
  abstract = {Depending on the news source, a reader can be exposed to a different narrative and conflicting perceptions for the same event. Today, news aggregators help users cope with the large volume of news published daily. However, aggregators focus on presenting shared information, but do not expose the different perspectives from articles on same topics. Thus, users of such aggregators suffer from media bias, which is often implemented intentionally to influence public opinion. In this paper, we present NewsBird, an aggregator that presents shared and different information on topics. Currently, NewsBird reveals different perspectives on international news. Our system has led to insights about media bias and news analysis, which we use to propose approaches to be investigated in future research. Our vision is to provide a system that reveals media bias, and thus ultimately allows users to make their own judgement on the potential bias inherent in news.},
  oldkey = {Hamborg2017a},
  preprint = {https://ag-gipp.github.io/bib/preprints/hamborg2017a.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\I3ILVY89\\HamborgMAG17--identification_and_analysis_of_media_bias_in_news_articles.pdf}
}

@inproceedings{HamborgMBG17,
  title = {news-please: {{A Generic News Crawler}} and {{Extractor}}},
  booktitle = {Proceedings of the 15th {{International Symposium}} of {{Information Science}}},
  author = {Hamborg, Felix and Meuschke, Norman and Breitinger, Corinna and Gipp, Bela},
  editor = {Gaede, Maria and Trkulja, Violeta and Petra, Vivien},
  date = {2017-03},
  pages = {218--223},
  location = {{Berlin}},
  url = {http://edoc.hu-berlin.de/docviews/abstract.php?id=43365},
  oldkey = {Hamborg2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/hamborg2017.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!fh,!fh_author,!nm_author,!nm_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\BAFZ46PE\\HamborgMBG17--news-please_a_generic_news_crawler_and_extractor.pdf}
}

@inproceedings{HamborgMG17,
  ids = {HamborgMG17a},
  title = {Matrix-{{Based News Aggregation}}: {{Exploring Different News Perspectives}}},
  booktitle = {Proceedings of the 17th {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Hamborg, Felix and Meuschke, Norman and Gipp, Bela},
  date = {2017-06},
  pages = {1--10},
  doi = {10/ggv8pm},
  abstract = {News aggregators capably handle the large amount of news that is published nowadays. However, these systems focus on the presentation of important, common information in news, but do not reveal different perspectives on the same topic. Thus, current news aggregators suffer from media bias, i.e. differences in the content or presentation of news. Finding such differences is crucial to reduce the effects of media bias. This paper presents matrix-based news analysis (MNA), a novel design for news exploration. MNA helps users gain a broad and diverse news understanding by presenting various news perspectives on the same topic. Furthermore, we present NewsBird, a news aggregator that implements MNA to find different perspectives on international news topics. The results of a case study demonstrate that NewsBird broadens the user's news understanding while it also provides similar news aggregation functionalities as established systems.},
  isbn = {978-1-5386-3861-3},
  oldkey = {Hamborg2017b},
  preprint = {https://ag-gipp.github.io/bib/preprints/hamborg2017b.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ZRPKWESS\\HamborgMG17--matrix-based_news_aggregation_exploring_different_news_perspectives.pdf}
}

@article{HamborgMG18,
  ids = {HamborgMG18a},
  title = {Bias-aware {{News Analysis Using Matrix}}-based {{News Aggregation}}},
  author = {Hamborg, Felix and Meuschke, Norman and Gipp, Bela},
  date = {2018-05-18},
  journaltitle = {Int J Digit Libr},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {1432-5012, 1432-1300},
  doi = {10.1007/s00799-018-0239-9},
  url = {http://link.springer.com/10.1007/s00799-018-0239-9},
  abstract = {Media bias describes differences in the content or presentation of news. It is an ubiquitous phenomenon in news coverage that can have severely negative effects on individuals and society. Identifying media bias is a challenging problem, for which current information systems offer little support. News aggregators are the most important class of systems to support users in coping with the large amount of news that is published nowadays. These systems focus on identifying and presenting important, common information in news articles, but do not reveal different perspectives on the same topic. Due to this analysis approach, current news aggregators cannot effectively reveal media bias. To address this problem, we present matrix-based news aggregation, a novel approach for news exploration that helps users gain a broad and diverse news understanding by presenting various perspectives on the same news topic. Additionally, we present NewsBird, an open-source news aggregator that implements matrix-based news aggregation for international news topics. The results of a user study showed that NewsBird more effectively broadens the user’s news understanding than the list-based visualization approach employed by established news aggregators, while achieving comparable effectiveness and efficiency for the two main use cases of news consumption: getting an overview of and finding details on current news topics.},
  oldkey = {Hamborg2018b},
  preprint = {https://ag-gipp.github.io/bib/preprints/hamborg2018b.pdf},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\84LR54M3\\HamborgMG18--bias-aware_news_analysis_using_matrix-based_news_aggregation.pdf}
}

@inproceedings{HamborgZG19iConf,
  title = {Illegal {{Aliens}} or {{Undocumented Immigrants}}? {{Towards}} the {{Automated Identification}} of {{Bias}} by {{Word Choice}} and {{Labeling}}},
  booktitle = {Proceedings of the {{iConference}} 2019},
  author = {Hamborg, Felix and Zhukova, Anastasia and Gipp, Bela},
  date = {2019-03},
  location = {{Washington, DC, USA}},
  doi = {10/ggv8gk},
  url = {https://doi.org/10.1007/978-3-030-15742-5_17},
  oldkey = {Hamborg2019},
  topic = {newsanalysis},
  keywords = {!az,!az_author,!bg,!bg_author,!bg_preprint,!fh,!fh_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\QECZ2ZQN\\HamborgZG19iConf--illegal_aliens_or_undocumented_immigrants_towards_the_automated_identification_of.pdf}
}

@inproceedings{HamborgZG19JCDL,
  title = {Automated {{Identification}} of {{Media Bias}} by {{Word Choice}} and {{Labeling}} in {{News Articles}}},
  booktitle = {Proceedings of the  {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Hamborg, Felix and Zhukova, Anastasia and Gipp, Bela},
  date = {2019-06},
  location = {{Urbana-Champaign, IL, USA}},
  doi = {10/ggv8gj},
  oldkey = {Hamborg2019a},
  topic = {newsanalysis},
  keywords = {!az,!az_author,!bg,!bg_author,!bg_preprint,!fh,!fh_author,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\M3586NWI\\HamborgZG19JCDL--automated_identification_of_media_bias_by_word_choice_and_labeling_in_news_articles.pdf}
}

@article{HeckS18,
  title = {{{DiViDu}} - an {{Open Source Solution}} for {{Dual Task Experiments}} with {{Integrated Divided Visual Field Paradigm}}},
  author = {Heck, Nina and Schubotz, Moritz},
  date = {2018},
  journaltitle = {Journal of Open Research Software},
  volume = {6},
  publisher = {{Ubiquity Press, Ltd.}},
  doi = {10.5334/jors.199},
  url = {https://doi.org/10.5334/jors.199},
  biburl = {https://kops.uni-konstanz.de/handle/123456789/42726},
  oldkey = {Heck2018},
  keywords = {!ms,!ms_author,!ms_cv,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@article{HeppSES18,
  title = {On-{{Chain Vs}}. {{Off}}-{{Chain Storage}} for {{Supply}}- and {{Blockchain Integration}}},
  author = {Hepp, Thomas and Sharinghousen, Matthew and Ehret, Philip and Schoenhals, Alexander and Gipp, Bela},
  date = {2018-12},
  journaltitle = {it - Information Technology},
  volume = {60},
  number = {5-6},
  pages = {283--291},
  publisher = {{Walter de Gruyter GmbH}},
  doi = {10/ggv8p4},
  url = {https://doi.org/10.1515/itit-2018-0019},
  oldkey = {Hepp2018b},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\N8PL9SKX\\HeppSES18--on-chain_vs_off-chain_storage_for_supply-_and_blockchain_integration.pdf}
}

@article{HeppSGG18,
  title = {{{OriginStamp}}: {{A Blockchain}}-{{Backed System}} for {{Decentralized Trusted Timestamping}}},
  author = {Hepp, Thomas and Schoenhals, Alexander and Gondek, Christopher and Gipp, Bela},
  date = {2018-12},
  journaltitle = {it - Information Technology},
  volume = {60},
  number = {5-6},
  pages = {273--281},
  publisher = {{Walter de Gruyter GmbH}},
  doi = {10/ggfmjb},
  url = {https://doi.org/10.1515/itit-2018-0020},
  oldkey = {Hepp2018c},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\H486AZ5L\\HeppSGG18--originstamp_a_blockchain-backed_system_for_decentralized_trusted_timestamping.pdf}
}

@inproceedings{HeppSSE19,
  title = {Exploring {{Potentials}} and {{Challenges}} of {{Blockchain}}-{{Based Public Key Infrastructures}}},
  booktitle = {{{IEEE INFOCOM}} 2019 - 2nd {{Workshop}} on on {{Cryptocurrencies}} and {{Blockchains}} for {{Distributed Systems}}  ({{CryBlock}} 2019)},
  author = {Hepp, Thomas and Spaeh, Fabian and Schoenhals, Alexander and Ehret, Philip and Gipp, Bela},
  date = {2019-05},
  location = {{Paris, France}},
  oldkey = {Hepp2019},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\QE5XXZKG\\HeppSSE19--exploring_potentials_and_challenges_of_blockchain-based_public_key_infrastructures.pdf}
}

@inproceedings{HeppWSG18,
  title = {Securing {{Physical Assets}} on the {{Blockchain}} - {{Linking}} a {{Novel Object Identification Concept}} with {{Distributed Ledgers}}},
  booktitle = {Proceedings of the 1st {{Workshop}} on {{Cryptocurrencies}} and {{Blockchains}} for {{Distributed Systems}} ({{CryBlock}}'18)},
  author = {Hepp, Thomas and Wortner, Patrick and Schoenhals, Alexander and Gipp, Bela},
  date = {2018-06},
  publisher = {{ACM}},
  location = {{Munich, Germany}},
  doi = {10/gfv9x7},
  oldkey = {Hepp2018},
  preprint = {https://ag-gipp.github.io/bib/preprints/hepp2018.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\JJTU9HMX\\HeppWSG18--securing_physical_assets_on_the_blockchain_-_linking_a_novel_object_identification.pdf}
}

@inproceedings{HofmannMGR16,
  title = {bibox: {{A Tangible Approach}} to {{Motivating Participation}} in {{Public Libraries}}},
  booktitle = {Humans and {{Computers}} 2016, {{Proceedings}}},
  author = {Hofmann, Jacqueline and Mueller, Jens and Gipp, Bela and Reiterer, Harald},
  date = {2016},
  doi = {10/ggv8p6},
  oldkey = {Hofmann2016},
  preprint = {https://ag-gipp.github.io/bib/preprints/hofmann2016.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\VSWGBQGR\\HofmannMGR16--bibox_a_tangible_approach_to_motivating_participation_in_public_libraries.pdf}
}

@article{HulekMST19,
  title = {Mathematical {{Research Data}} – an {{Analysis Through zbMATH References}}.},
  author = {Hulek, Klaus and Müller, Fabian and Schubotz, Moritz and Teschke, Olaf},
  date = {2019},
  journaltitle = {European Mathematical Society. Newsletter},
  volume = {113},
  pages = {54--57},
  publisher = {{European Mathematical Society (EMS) Publishing House, Zurich}},
  issn = {1027-488X},
  doi = {10/ggv8m7},
  url = {https://www.ems-ph.org/journals/show_pdf.php?issn=1027-488X&vol=9&iss=113&rank=14},
  biburl = {https://zbmath.org/bibtex/07111212.bib},
  langid = {english},
  oldkey = {Hulek19},
  keywords = {!ms,!ms_author,!ms_cv,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{IhleSMG20,
  ids = {IhleSMG20a},
  title = {A {{First Step Towards Content Protecting Plagiarism Detection}}},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Ihle, Cornelius and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
  date = {2020-08},
  oldkey = {Ihle2020},
  topic = {pd},
  keywords = {!bg,!bg_author,!ms,!ms_author,!nm,!nm_author,\#nosource,jabref_imp1_clean}
}

@inproceedings{JentnerEGK17,
  title = {Feature {{Alignment}} for the {{Analysis}} of {{Verbatim Text Transcripts}}},
  booktitle = {Proceedings of the {{Eurographics Conference}} on {{Visualization}} ({{EuroVis}})},
  author = {Jentner, Wolfgang and El-Assady, Mennatallah and Gipp, Bela and Keim, Daniel},
  date = {2017},
  oldkey = {Jentner2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/jentner2017.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\9PC8KS5D\\JentnerEGK17--feature_alignment_for_the_analysis_of_verbatim_text_transcripts.pdf}
}

@inproceedings{LeibleSSG18,
  title = {Fostering {{Open Science}} by {{Using Blockchain Technology}}},
  author = {Leible, Stephan and Schlager, Steffen and Schubotz, Moritz and Gipp, Bela},
  date = {2018-11},
  doi = {10/ggv8f7},
  url = {https://zenodo.org/record/2454725/files/Blockchain-For-Science%20Poster-1.0-final.pdf?download=1},
  biburl = {https://zenodo.org/record/2454725/export/hx\#.XCJgpMYo8ax},
  oldkey = {Leible2018},
  url_orig = {https://doi.org/10.5281/zenodo.2454725},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\DYJ9PMI8\\LeibleSSG18--fostering_open_science_by_using_blockchain_technology.pdf}
}

@article{LeibleSSG19,
  title = {A {{Review}} on {{Blockchain Technology}} and {{Blockchain Projects Fostering Open Science}}},
  author = {Leible, Stephan and Schlager, Steffen and Schubotz, Moritz and Gipp, Bela},
  date = {2019},
  journaltitle = {Frontiers in Blockchain},
  volume = {2},
  pages = {16},
  issn = {2624-7852},
  doi = {10/ggjbpg},
  url = {https://www.frontiersin.org/article/10.3389/fbloc.2019.00016},
  abstract = {Many sectors, like finance, medicine, manufacturing, and education, use blockchain applications to profit from the unique bundle of characteristics of this technology. Blockchain technology (BT) promises benefits in trustability, collaboration, organization, identification, credibility, and transparency. In this paper, we conduct an analysis in which we show how open science can benefit from this technology and its properties. For this, we determined the requirements of an open science ecosystem and compared them with the characteristics of BT to prove that the technology suits as an infrastructure. We also review literature and promising blockchain-based projects for open science to describe the current research situation. To this end, we examine the projects in particular for their relevance and contribution to open science and categorize them afterwards according to their primary purpose. Several of them already provide functionalities that can have a positive impact on current research workflows. So, BT offers promising possibilities for its use in science, but why is it then not used on a large-scale in that area? To answer this question, we point out various shortcomings, challenges, unanswered questions, and research potentials that we found in the literature and identified during our analysis. These topics shall serve as starting points for future research to foster the BT for open science and beyond, especially in the long-term.},
  biburl = {https://www.frontiersin.org/articles/10.3389/fbloc.2019.00016/bibTex},
  oldkey = {Leible2019},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/leible2019.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\F8X667QE\\LeibleSSG19--a_review_on_blockchain_technology_and_blockchain_projects_fostering_open_science.pdf}
}

@inproceedings{LeichASH13,
  title = {Applying {{Stratosphere}} for {{Big Data Analytics}}},
  booktitle = {Datenbanksysteme {{Für Business}}, {{Technologie Und Web}} ({{BTW}}), 15. {{Fachtagung Des GI}}-{{Fachbereichs}} "{{Datenbanken}} und {{Informationssysteme}}" ({{DBIS}}), 11.-15.3.2013 in {{Magdeburg}}, {{Germany}}. {{Proceedings}}},
  author = {Leich, Marcus and Adamek, Jochen and Schubotz, Moritz and Heise, Arvid and Rheinländer, Astrid and Markl, Volker},
  editor = {Markl, Volker and Saake, Gunter and Sattler, Kai-Uwe and Hackenbroich, Gregor and Mitschang, Bernhard and Härder, Theo and Köppen, Veit},
  date = {2013},
  series = {{{LNI}}},
  volume = {214},
  pages = {507--510},
  publisher = {{GI}},
  doi = {10/ggv8cg},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/btw/LeichASHRM13},
  oldkey = {Leich2013},
  keywords = {!ms,!ms_author,!ms_cv,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{LipinskiYBB13,
  title = {Evaluation of {{Header Metadata Extraction Approaches}} and {{Tools}} for {{Scientific PDF Documents}}},
  booktitle = {Proceedings of the 13th {{ACM}}/{{IEEE}}-{{CS Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Lipinski, Mario and Yao, Kevin and Breitinger, Corinna and Beel, Joeran and Gipp, Bela},
  date = {2013-07},
  publisher = {{ACM}},
  location = {{Indianapolis, IN, USA}},
  doi = {10/ggckcb},
  oldkey = {Lipinski13},
  preprint = {https://ag-gipp.github.io/bib/preprints/lipinski13.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\A4JSCYG3\\LipinskiYBB13--evaluation_of_header_metadata_extraction_approaches_and_tools_for_scientific_pdf.pdf}
}

@article{MeschenmoserMHG16,
  title = {Scraping {{Scientific Web Repositories}}: {{Challenges}} and {{Solutions}} for {{Automated Content Extraction}}},
  shorttitle = {Scraping {{Scientific Web Repositories}}},
  author = {Meschenmoser, Philipp and Meuschke, Norman and Hotz, Manuel and Gipp, Bela},
  date = {2016-10},
  journaltitle = {D-Lib Magazine},
  volume = {22},
  number = {9/10},
  issn = {1082-9873},
  doi = {10/ggv8ck},
  abstract = {Aside from improving the visibility and accessibility of scientific publications, many scientific Web repositories also assess researchers' quantitative and qualitative publication performance, e.g., by displaying metrics such as the h-index. These metrics have become important for research institutions and other stakeholders to support impactful decision making processes such as hiring or funding decisions. However, scientific Web repositories typically offer only simple performance metrics and limited analysis options. Moreover, the data and algorithms to compute performance metrics are usually not published. Hence, it is not transparent or verifiable which publications the systems include in the computation and how the systems rank the results. Many researchers are interested in accessing the underlying scientometric raw data to increase the transparency of these systems. In this paper, we discuss the challenges and present strategies to programmatically access such data in scientific Web repositories. We demonstrate the strategies as part of an open source tool (MIT license) that allows research performance comparisons based on Google Scholar data. We would like to emphasize that the scraper included in the tool should only be used if consent was given by the operator of a repository. In our experience, consent is often given if the research goals are clearly explained and the project is of a non-commercial nature.},
  langid = {english},
  oldkey = {Meschenmoser2016a},
  preprint = {https://ag-gipp.github.io/bib/preprints/meschenmoser2016a.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\U4EMPLWD\\MeschenmoserMHG16--scraping_scientific_web_repositories_challenges_and_solutions_for_automated_content.pdf}
}

@inproceedings{MeschenmoserMHG16WOSP,
  title = {Scraping {{Scientific Web Repositories}}: {{Challenges}} and {{Solutions}} for {{Automated Content Extraction}}},
  booktitle = {Proceedings of the 5th {{International Workshop}} on {{Mining Scientific Publications}} ({{WOSP}}) held in conjunction with the 16th {{ACM}}/{{IEEE}}-{{CS Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Meschenmoser, Philipp and Meuschke, Norman and Hotz, Manuel and Gipp, Bela},
  date = {2016},
  location = {{Newark, New Jersey, USA}},
  doi = {10/ggv8ck},
  oldkey = {Meschenmoser2016},
  preprint = {https://ag-gipp.github.io/bib/preprints/meschenmoser2016.pdf},
  topic = {misc},
  keywords = {!bg,!bg_author,!nm_author,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\F7ZJAELM\\MeschenmoserMHG16WOSP--scraping_scientific_web_repositories_challenges_and_solutions_for_automated_content.pdf}
}

@thesis{Meuschke11,
  type = {Diploma Thesis},
  ids = {Meuschke11a},
  title = {Citation-{{Based Plagiarism Detection}} for {{Scientific Documents}}},
  author = {Meuschke, Norman},
  date = {2011-06},
  institution = {{Dep. of Computer Science, Otto-von-Guericke-University Magdeburg, Germany}},
  location = {{Magdeburg}},
  oldkey = {Meuschke11b},
  owner = {Norman},
  keywords = {!nm,!nm_author,\#nosource,jabref_imp1_clean}
}

@article{MeuschkeG13,
  ids = {MeuschkeG13a},
  title = {State of the {{Art}} in {{Detecting Academic Plagiarism}}},
  author = {Meuschke, Norman and Gipp, Bela},
  date = {2013-06},
  journaltitle = {International Journal for Educational Integrity},
  volume = {9},
  number = {1},
  pages = {50--71},
  issn = {1833-2595},
  doi = {10/gf9rvh},
  url = {https://www.ojs.unisa.edu.au/index.php/IJEI/article/view/847/610},
  abstract = {The problem of academic plagiarism has been present for centuries. Yet, the widespread dissemination of information technology, including the internet, made plagiarising much easier. Consequently, methods and systems aiding in the detection of plagiarism have attracted much research within the last two decades. Researchers proposed a variety of solutions, which we will review comprehensively in this article. Available detection systems use sophisticated and highly efficient character-based text comparisons, which can reliably identify verbatim and moderately disguised copies. Automatically detecting more strongly disguised plagiarism, such as paraphrases, translations or idea plagiarism, is the focus of current research. Proposed approaches for this task include intrinsic, cross-lingual and citation-based plagiarism detection. Each method offers unique strengths and weaknesses; however, none is currently mature enough for practical use. In the future, plagiarism detection systems may benefit from combining traditional character-based detection methods with these emerging detection approaches. Introduction},
  oldkey = {Meuschke13},
  preprint = {https://ag-gipp.github.io/bib/preprints/meuschke13.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\ETK4X4E8\\MeuschkeG13--state_of_the_art_in_detecting_academic_plagiarism.pdf}
}

@inproceedings{MeuschkeG14,
  ids = {MeuschkeG14a},
  title = {Reducing {{Computational Effort}} for {{Plagiarism Detection}} by {{Using Citation Characteristics}} to {{Limit Retrieval Space}}},
  booktitle = {Proceedings of the 14th {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Meuschke, Norman and Gipp, Bela},
  date = {2014-09},
  pages = {197--200},
  location = {{London, UK}},
  doi = {10/ggv8jc},
  abstract = {This paper proposes a hybrid approach to plagiarism detection in academic documents that integrates detection methods using citations, semantic argument structure, and semantic word similarity with character-based methods to achieve a higher detection performance for disguised plagiarism forms. Currently available software for plagiarism detection exclusively performs text string comparisons. These systems find copies, but fail to identify disguised plagiarism, such as paraphrases, translations, or idea plagiarism. Detection approaches that consider semantic similarity on word and sentence level exist and have consistently achieved higher detection accuracy for disguised plagiarism forms compared to character-based approaches. However, the high computational effort of these semantic approaches makes them infeasible for use in real-world plagiarism detection scenarios. The proposed hybrid approach uses citation-based methods as a preliminary heuristic to reduce the retrieval space with a relatively low loss in detection accuracy. This preliminary step can then be followed by a computationally more expensive semantic and character-based analysis. We show that such a hybrid approach allows semantic plagiarism detection to become feasible even on large collections for the first time.},
  isbn = {978-1-4799-5569-5},
  jabref-groups = {phd-m, CbPD thesis},
  oldkey = {Meuschke14},
  owner = {Norman},
  preprint = {https://ag-gipp.github.io/bib/preprints/meuschke14.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\V7LJMYWE\\MeuschkeG14--reducing_computational_effort_for_plagiarism_detection_by_using_citation_characteristics.pdf}
}

@inproceedings{MeuschkeGB12,
  ids = {MeuschkeGB12a},
  title = {{{CitePlag}}: {{A Citation}}-based {{Plagiarism Detection System Prototype}}},
  booktitle = {Proceedings of the 5th {{International Plagiarism Conference}}},
  author = {Meuschke, Norman and Gipp, Bela and Breitinger, Corinna},
  date = {2012-07},
  location = {{Newcastle upon Tyne, UK}},
  doi = {10/ggm3qb},
  abstract = {This paper presents an open-source prototype of a citation-based plagiarism detection system called CitePlag. The underlying idea of the system is to evaluate the citations of academic documents as language independent markers to detect plagiarism. CitePlag uses three different detection algorithms that analyze the citation sequence of academic documents for similar patterns that may indicate unduly used foreign text or ideas. The algorithms consider multiple citation related factors such as proximity and order of citations within the text, or their probability of co-occurrence in order to compute document similarity scores. We present technical details of CitePlag's detection algorithms and the acquisition of test data from the PubMed Central Open Access Subset. Future advancements of the prototype focus on increasing the reference database by enabling the system to process more document and citation formats. Furthermore, we aim to improve CitePlag's detection algorithms and scoring functions for reducing the number of false positives. Eventually, we plan to integrate text with citation-based detection algorithms within CitePlag.},
  oldkey = {Meuschke12},
  preprint = {https://ag-gipp.github.io/bib/preprints/meuschke12.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\FYG54A4G\\MeuschkeGB12--citeplag_a_citation-based_plagiarism_detection_system_prototype.pdf}
}

@inproceedings{MeuschkeGSB18,
  ids = {MeuschkeGSB18a},
  title = {An {{Adaptive Image}}-{{Based Plagiarism Detection Approach}}},
  booktitle = {Proceedings of the 18th {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Meuschke, Norman and Gondek, Christopher and Seebacher, Daniel and Breitinger, Corinna and Keim, Daniel and Gipp, Bela},
  date = {2018-06},
  pages = {131--140},
  location = {{Fort Worth, USA}},
  doi = {10/ggv8jf},
  abstract = {Identifying plagiarized content is a crucial task for educational and research institutions, funding agencies, and academic publishers. Plagiarism detection systems available for productive use reliably identify copied text, or near-copies of text, but oſten fail to detect disguised forms of academic plagiarism, such as paraphrases, trans- lations, and idea plagiarism. To improve the detection capabilities for disguised forms of academic plagiarism, we analyze the images in academic documents as text-independent features. We propose an adaptive, scalable, and extensible image-based plagiarism de- tection approach suitable for analyzing a wide range of image similarities that we observed in academic documents. The proposed detection approach integrates established image analysis methods, such as perceptual hashing, with newly developed similarity assess- ments for images, such as ratio hashing and position-aware OCR text matching. We evaluate our approach using 15 image pairs that are representative of the spectrum of image similarity we observed in alleged and confirmed cases of academic plagiarism. We embed the test cases in a collection of 4,500 related images from academic texts. Our detection approach achieved a recall of 0.73 and a pre- cision of 1. These results indicate that our image-based approach can complement other content-based feature analysis approaches to retrieve potential source documents for suspiciously similar con- tent from large collections. We provide our code as open source to facilitate future research on image-based plagiarism detection.},
  isbn = {978-1-4503-5178-2},
  oldkey = {Meuschke2018},
  preprint = {https://ag-gipp.github.io/bib/preprints/meuschke2018.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\3THWH4SF\\MeuschkeGSB18--an_adaptive_image-based_plagiarism_detection_approach.pdf}
}

@inproceedings{MeuschkeSHS17,
  ids = {MeuschkeSHS17a,MeuschkeSHS17b},
  title = {Analyzing {{Mathematical Content}} to {{Detect Academic Plagiarism}}},
  shorttitle = {Proc. {{CIKM}}},
  booktitle = {Proceedings {{ACM Conference}} on {{Information}} and {{Knowledge Management}} ({{CIKM}})},
  author = {Meuschke, Norman and Schubotz, Moritz and Hamborg, Felix and Skopal, Tomas and Gipp, Bela},
  date = {2017-11},
  pages = {2211--2214},
  publisher = {{ACM}},
  location = {{Singapore}},
  doi = {10/cf9g},
  url = {http://doi.acm.org/10.1145/3132847.3133144},
  abstract = {This paper presents, to our knowledge, the first study on analyzing mathematical expressions to detect academic plagiarism. We make the following contributions. First, we investigate confirmed cases of plagiarism to categorize the similarities of mathematical content commonly found in plagiarized publications. From this investigation, we derive possible feature selection and feature comparison strategies for developing math-based detection approaches and a ground truth for our experiments. Second, we create a test collection by embedding confirmed cases of plagiarism into the NTCIR-11 MathIR Task dataset, which contains approx. 60 million mathematical expressions in 105,120 documents from arXiv.org. Third, we develop a first math-based detection approach by implementing and evaluating different feature comparison approaches using an open source parallel data processing pipeline built using the Apache Flink framework. The best performing approach identifies all but two of our real-world test cases at the top rank and achieves a mean reciprocal rank of 0.86. The results show that mathematical expressions are promising text-independent features to identify academic plagiarism in large collections. To facilitate future research on math-based plagiarism detection, we make our source code and data available. ? 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
  biburl = {https://dblp.org/rec/bib/conf/cikm/MeuschkeSHSG17},
  core = {A;Core Rank A;http://portal.core.edu.au/conf-ranks/25/},
  isbn = {978-1-4503-4918-5},
  oldkey = {Meuschke2017b},
  owner = {norman},
  preprint = {https://ag-gipp.github.io/bib/preprints/meuschke2017b.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\SHLSRVKM\\MeuschkeSHS17--analyzing_mathematical_content_to_detect_academic_plagiarism.pdf}
}

@inproceedings{MeuschkeSSG17,
  ids = {MeuschkeSSG17a},
  title = {Analyzing {{Semantic Concept Patterns}} to {{Detect Academic Plagiarism}}},
  booktitle = {Proceedings of the {{International Workshop}} on {{Mining Scientific Publications}} ({{WOSP}}) co-located with the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Meuschke, Norman and Siebeck, Nicolas and Schubotz, Moritz and Gipp, Bela},
  date = {2017-06},
  pages = {46--53},
  publisher = {{IEEE Computer Society}},
  location = {{Toronto, Canada}},
  doi = {10/ggv8ch},
  abstract = {Detecting academic plagiarism is a pressing problem, e.g., for educational and research institutions, funding agencies, and academic publishers. Existing plagiarism detection systems reliably identify copied text, or near copies of text, but often fail to detect disguised forms of academic plagiarism, such as paraphrases, translations, and idea plagiarism. We present Semantic Concept Pattern Analysis - an approach that performs an integrated analysis of semantic text relatedness and structural text similarity. Using 25 officially retracted academic plagiarism cases, we demonstrate that our approach can detect plagiarism that established text matching approaches would not identify. We view our approach as a promising addition to improve the detection capabilities for strong paraphrases. We plan to further improve Semantic Concept Pattern Analysis and include the approach as part of an integrated detection process that analyzes heterogeneous similarity features to better identify the many possible forms of plagiarism in academic documents.},
  biburl = {https://dblp.org/rec/bib/conf/jcdl/MeuschkeSSG17},
  isbn = {978-1-4503-5388-5},
  oldkey = {Meuschke2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/meuschke2017a.pdf},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\YXJ93M6C\\MeuschkeSSG17--analyzing_semantic_concept_patterns_to_detect_academic_plagiarism.pdf}
}

@inproceedings{MeuschkeSSG18,
  ids = {MeuschkeSSG18a},
  title = {{{HyPlag}}: {{A Hybrid Approach}} to {{Academic Plagiarism Detection}}},
  booktitle = {Proceedings of the 41st {{International ACM SIGIR Conference}} on {{Research}} \& {{Development}} in {{Information Retrieval}}},
  author = {Meuschke, Norman and Stange, Vincent and Schubotz, Moritz and Gipp, Bela},
  date = {2018-06},
  pages = {1321--1324},
  location = {{Ann Arbor, MI, USA}},
  doi = {10/ggv8jg},
  abstract = {Current plagiarism detection systems reliably find instances of copied and moderately altered text, but often fail to detect strong paraphrases, translations, and the reuse of non-textual content and ideas. To improve upon the detection capabilities for such concealed content reuse in academic publications, we make four contributions: i) We present the first plagiarism detection approach that combines the analysis of mathematical expressions, images, citations and text. ii) We describe the implementation of this hybrid detection approach in the research prototype HyPlag. iii) We present novel visualization and interaction concepts to aid users in reviewing content similarities identified by the hybrid detection approach. iv) We demonstrate the usefulness of the hybrid detection and result visualization approaches by using HyPlag to analyze a confirmed case of content reuse present in a retracted research publication.},
  biburl = {https://dblp.uni-trier.de/rec/bibtex/conf/sigir/MeuschkeSSG18},
  core = {A*},
  isbn = {978-1-4503-5657-2},
  oldkey = {Meuschke2018a},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/meuschke2018a.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,DFG1259-1,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TFGTPQTF\\MeuschkeSSG18--hyplag_a_hybrid_approach_to_academic_plagiarism_detection.pdf}
}

@inproceedings{MeuschkeSSK19,
  ids = {MeuschkeSSK19a},
  title = {Improving {{Academic Plagiarism Detection}} for {{STEM Documents}} by {{Analyzing Mathematical Content}} and {{Citations}}},
  booktitle = {Proceedings of the  {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Meuschke, Norman and Stange, Vincent and Schubotz, Moritz and Kramer, Michael and Gipp, Bela},
  date = {2019-06},
  pages = {120--129},
  location = {{Urbana-Champaign, Illinois, USA}},
  doi = {10/ggv8jd},
  abstract = {Identifying academic plagiarism is a pressing task for educational and research institutions, publishers, and funding agencies. Current plagiarism detection systems reliably find instances of copied and moderately reworded text. However, reliably detecting concealed plagiarism, such as strong paraphrases, translations, and the reuse of nontextual content and ideas is an open research problem. In this paper, we extend our prior research on analyzing mathematical content and academic citations. Both are promising approaches for improving the detection ofconcealed academic plagiarism primarily in Science, Technology, Engineering and Mathematics (STEM). We make the following contributions: i) We present a two-stage detec- tion process that combines similarity assessments of mathematical content, academic citations, and text. ii) We introduce new similar- ity measures that consider the order of mathematical features and outperform the measures in our prior research. iii) We compare the effectiveness of the math-based, citation-based, and text-based detection approaches using confirmed cases of academic plagia- rism. iv) We demonstrate that the combined analysis of math-based and citation-based content features allows identifying potentially suspicious cases in a collection of 102K STEM documents. Overall, we show that analyzing the similarity of mathematical content and academic citations is a striking supplement for conventional text- based detection approaches for academic literature in the STEM disciplines. The data and code of our study are openly available at https://purl.org/hybridPD},
  core = {0;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/},
  isbn = {978-1-72811-547-4},
  oldkey = {Meuschke2019},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/meuschke2019.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,DFG1259-1,jabref_imp1_clean,old_tex_field_preprint,pd_litrev19},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\JXU7JFVG\\MeuschkeSSK19--improving_academic_plagiarism_detection_for_stem_documents_by_analyzing_mathematical.pdf}
}

@article{MienertG17,
  title = {Dashcam, {{Blockchain}} und der {{Beweis}} im {{Prozess Kriterien}} für einen {{Privacy}} by {{Design}}-{{Lösungsansatz}} bei {{Dashcams}}},
  author = {Mienert, Heval and Gipp, Bela},
  date = {2017},
  journaltitle = {Zeitschrift für Datenschutz},
  number = {11},
  pages = {514--519},
  url = {https://beck-online.beck.de},
  oldkey = {Mienert2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/mienert2017.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\PY4Y8LMH\\MienertG17--dashcam_blockchain_und_der_beweis_im_prozess_kriterien_fr_einen_privacy_by_design.pdf}
}

@article{MienertHG19,
  title = {Prioritätsnachweis des {{Urhebers}} durch blockchainbasierten {{Zeitstempel}}},
  author = {Mienert, Heval and Hepp, Thomas and Gipp, Bela},
  date = {2019},
  doi = {10/ggv8cj},
  url = {https://zenodo.org/record/2547964},
  oldkey = {Mienert2019},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\YDJKAUQJ\\MienertHG19--priorittsnachweis_des_urhebers_durch_blockchainbasierten_zeitstempel.pdf}
}

@inproceedings{OstendorffRSG20,
  title = {Pairwise {{Multi}}-{{Class Document Classification}} for {{Semantic Relations Between Wikipedia Articles}}},
  booktitle = {Proceedings of the {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Ostendorff, Malte and Ruas, Terry and Schubotz, Moritz and Gipp, Bela},
  date = {2020-08},
  oldkey = {Ostendorff2020},
  topic = {wiki},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\DXCX2JDG\\OstendorffRSG20--pairwise_multi-class_document_classification_for_semantic_relations_between_wikipedia.pdf}
}

@inproceedings{PagelS14,
  ids = {PagelS14a},
  title = {Mathematical {{Language Processing Project}}},
  booktitle = {Joint {{Proceedings}} of the {{MathUI}}, {{OpenMath}} and {{ThEdu Workshops}} and {{Work}} in {{Progress}} track at {{CICM}} co-located with {{Conferences}} on {{Intelligent Computer Mathematics}} ({{CICM}} 2014), {{Coimbra}}, {{Portugal}}, {{July}} 7-11, 2014.},
  author = {Pagel, Robert and Schubotz, Moritz},
  editor = {England, Matthew and Davenport, James H. and Kohlhase, Andrea and Kohlhase, Michael and Libbrecht, Paul and Neuper, Walther and Quaresma, Pedro and Sexton, Alan P. and Sojka, Petr and Urban, Josef and Watt, Stephen M.},
  date = {2014},
  series = {{{CEUR Workshop Proceedings}}},
  volume = {1186},
  publisher = {{CEUR-WS.org}},
  url = {http://ceur-ws.org/Vol-1186/paper-23.pdf},
  biburl = {https://dblp.org/rec/bib/conf/mkm/PagelS14},
  jabref-groups = {phd-m},
  oldkey = {Pagel2014},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,cicm,conference,jabref_imp2,old_tex_field_preprint,peerreview,wip},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\LV6Z6I6H\\PagelS14--mathematical_language_processing_project.pdf}
}

@inproceedings{PetersenSG18,
  title = {Towards {{Formula Translation Using Recursive Neural Networks}}},
  booktitle = {Proceedings of the 11th {{Conference}} on {{Intelligent Computer Mathematics}} ({{CICM}})},
  author = {Petersen, Felix and Schubotz, Moritz and Gipp, Bela},
  date = {2018},
  location = {{Hagenberg, Austria}},
  url = {http://arxiv.org/abs/1811.04234},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1811-04234},
  oldkey = {Petersen2018},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/petersen2018.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RFC4CR7W\\PetersenSG18--towards_formula_translation_using_recursive_neural_networks.pdf}
}

@inproceedings{ScharpfMSB19,
  title = {{{AnnoMath TeX}}- a {{Formula Identifier Annotation Recommender System}} for {{STEM Documents}}},
  booktitle = {Proceedings of the 13th {{ACM Conference}} on {{Recommender Systems}} 2019, {{Copenhagen}}, {{Denmark}}, {{September}} 16-20, 2019},
  author = {Scharpf, Philipp and Mackerracher, Ian and Schubotz, Moritz and Beel, Jöran and Breitinger, Corinna and Gipp, Bela},
  editor = {Bogers, Toine and Said, Alan and Brusilovsky, Peter and Tikk, Domonkos},
  date = {2019},
  pages = {532--533},
  publisher = {{ACM}},
  doi = {10/ggv8jt},
  url = {https://doi.org/10.1145/3298689.3347042},
  biburl = {https://dblp.org/rec/bib/conf/recsys/ScharpfMSBBG19},
  core = {B;Core Rank B;http://portal.core.edu.au/conf-ranks/28/},
  homepage = {https://annomathtex.wmflabs.org/},
  oldkey = {Scharpf2019b},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/scharpf2019b.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!jb,!jb_author,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\KDP4YKDT\\ScharpfMSB19--annomath_tex-_a_formula_identifier_annotation_recommender_system_for_stem_documents.pdf}
}

@inproceedings{ScharpfSCG19,
  ids = {ScharpfSCG19a},
  title = {Towards {{Formula Concept Discovery}} and {{Recognition}}},
  booktitle = {Proceedings of the 4th {{Joint Workshop}} on {{Bibliometric}}-{{Enhanced Information Retrieval}} and {{Natural Language Processing}} for {{Digital Libraries}} ({{BIRNDL}} 2019) co-located with the 42nd {{Annual International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}, {{Paris}}, {{France}}, {{July}} 25, 2019.},
  author = {Scharpf, Philipp and Schubotz, Moritz and Cohl, Howard S. and Gipp, Bela},
  editor = {Chandrasekaran, Muthu Kumar and Mayr, Philipp},
  date = {2019},
  series = {{{CEUR}} workshop proceedings},
  volume = {2414},
  pages = {108--115},
  publisher = {{CEUR-WS.org}},
  url = {http://ceur-ws.org/Vol-2414/paper11.pdf},
  biburl = {https://dblp.org/rec/bib/conf/sigir/ScharpfSCG19},
  oldkey = {Scharpf2019a},
  preprint = {http://ceur-ws.org/Vol-2414/paper11.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!ms,!ms_author,!ms_cv,\#nosource,DFG1259-1,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{ScharpfSG18,
  title = {Representing {{Mathematical Formulae}} in {{Content MathML Using Wikidata}}},
  booktitle = {Proceedings of the 3rd joint workshop on bibliometric-enhanced information retrieval and natural language processing for digital libraries ({{BIRNDL}} 2018) co-located with the 41st international {{ACM SIGIR}} conference on research and development in information retrieval ({{SIGIR}} 2018), ann arbor, {{USA}}, july 12, 2018.},
  author = {Scharpf, Philipp and Schubotz, Moritz and Gipp, Bela},
  editor = {Mayr, Philipp and Chandrasekaran, Muthu Kumar and Jaidka, Kokil},
  date = {2018},
  series = {{{CEUR}} workshop proceedings},
  volume = {2132},
  pages = {46--59},
  publisher = {{CEUR-WS.org}},
  url = {http://ceur-ws.org/Vol-2132/paper5.pdf},
  biburl = {https://dblp.org/rec/bib/conf/sigir/ScharpfSG18},
  oldkey = {Scharpf2018},
  preprint = {https://ag-gipp.github.io/bib/preprints/scharpf2018.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\326UPFBD\\ScharpfSG18--representing_mathematical_formulae_in_content_mathml_using_wikidata.pdf}
}

@inproceedings{ScharpfSYH20,
  ids = {ScharpfSYH20a},
  title = {Classification and {{Clustering}} of {{arXiv Documents}}, {{Sections}}, and {{Abstracts Comparing Encodings}} of {{Natural}} and {{Mathematical Language}}},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Scharpf, Philipp and Schubotz, Moritz and Youssef, Abdou and Hamborg, Felix and Meuschke, Norman and Gipp, Bela},
  date = {2020-06},
  oldkey = {Scharpf2020},
  topic = {mathir},
  keywords = {!bg,!bg_author,!fh,!fh_author,!ms,!ms_author,!nm,!nm_author,\#nosource,jabref_imp1_clean}
}

@article{SchoenhalsHEG18,
  title = {Tracking of {{Intellectual Property Using}} the {{Blockchain}}},
  author = {Schoenhals, Alexander and Hepp, Thomas and Ehret, Philip and Gipp, Bela},
  date = {2018-11},
  doi = {10/ggv8js},
  url = {https://doi.org/10.5281/zenodo.2537209},
  biburl = {https://zenodo.org/record/2537209/export/hx\#.XDhlxMYo8aw},
  oldkey = {Schoenhals2018a},
  preprint = {https://zenodo.org/record/2537209/files/bfsₚosterₛchoenhals.pdf?download=1},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\XSQL6LWI\\SchoenhalsHEG18--tracking_of_intellectual_property_using_the_blockchain.pdf}
}

@inproceedings{SchoenhalsHG18,
  title = {Design {{Thinking Using}} the {{Blockchain}} - {{Enable Traceability}} of {{Intellectual Property}} in {{Problem}}-{{Solving Processes}} for {{Open Innovation}}},
  booktitle = {Proceedings of the 1st {{Workshop}} on {{Cryptocurrencies}} and {{Blockchains}} for {{Distributed Systems}} ({{CryBlock}}'18)},
  author = {Schoenhals, Alexander and Hepp, Thomas and Gipp, Bela},
  date = {2018-06},
  publisher = {{ACM}},
  location = {{Munich, Germany}},
  doi = {10/gfv9zd},
  oldkey = {Schoenhals2018},
  preprint = {https://ag-gipp.github.io/bib/preprints/schoenhals2018.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\M5YFGNLH\\SchoenhalsHG18--design_thinking_using_the_blockchain_-_enable_traceability_of_intellectual_property.pdf}
}

@inproceedings{SchoenhalsHLE19,
  title = {Overview of {{Licensing Platforms Based}} on {{Distributed Ledger Technology}}},
  booktitle = {Proceedings of the 52nd {{International Conference}} on {{System Sciences}}},
  author = {Schoenhals, Alexander and Hepp, Thomas and Leible, Stephan and Ehret, Philip and Gipp, Bela},
  date = {2019-01},
  location = {{USA}},
  oldkey = {Schoenhals2019},
  organization = {{IEEE}},
  preprint = {https://ag-gipp.github.io/bib/preprints/schoenhals2019.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\9LM5KWKW\\SchoenhalsHLE19--overview_of_licensing_platforms_based_on_distributed_ledger_technology.pdf}
}

@thesis{Schubotz11,
  type = {Diplomarbeit},
  ids = {Schubotz11a},
  title = {Full {{Counting Statistics}} - {{A}} quantum master equation approach},
  author = {Schubotz, Moritz},
  date = {2011},
  institution = {{Institut für theoretische Phyisk an der Fakultät für Mathematik und Naturwissenschaften an der Technische Universität Berlin}},
  location = {{Berlin}},
  jabref-groups = {phd-m},
  langid = {english},
  oldkey = {Schubotz11fse},
  owner = {Moritz},
  pagetotal = {189},
  pubstate = {unpublished},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\AZ3RTEHN\\Schubotz11--full_counting_statistics_-_a_quantum_master_equation_approach.pdf}
}

@article{Schubotz12CICM,
  ids = {Schubotz12},
  title = {Making {{Math Searchable}} in {{Wikipedia}}},
  author = {Schubotz, Moritz},
  date = {2012-07-30},
  journaltitle = {CoRR},
  volume = {abs/1304.5475},
  eprint = {1304.5475},
  eprinttype = {arxiv},
  doi = {10/ggv8jr},
  abstract = {Wikipedia, the world largest encyclopedia contains a lot of knowledge that is expressed as formulae exclusively. Unfortunately, this knowledge is currently not fully accessible by intelligent information retrieval systems. This immense body of knowledge is hidden form value-added services, such as search. In this paper, we present our MathSearch implementation for Wikipedia that enables users to perform a combined text and fully unlock the potential benefits.},
  archiveprefix = {arXiv},
  arxivid = {1304.5475},
  biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1304-5475},
  jabref-groups = {phd-m},
  oldkey = {corneli17},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,arxiv,cicm,conference,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\YJU6LZ63\\Schubotz12CICM--making_math_searchable_in_wikipedia.pdf}
}

@online{Schubotz12FSE,
  title = {Formulasearchengine},
  author = {Schubotz, Moritz},
  date = {2012},
  url = {http://mlp.formulasearchengine.com},
  urldate = {2016-04-01},
  jabref-groups = {phd-m},
  oldkey = {hp},
  owner = {Moritz},
  keywords = {!ms,!ms_author,\#nosource,⛔ No DOI found,jabref_imp2}
}

@software{Schubotz12MathSearch,
  title = {Extension:{{MathSearch}} - {{MediaWiki}}},
  author = {Schubotz, Moritz},
  date = {2012},
  url = {http://www.mediawiki.org/wiki/Extension:MathSearch},
  urldate = {2012-10-05},
  jabref-groups = {phd-m},
  oldkey = {MathSearch},
  owner = {Moritz},
  keywords = {!ms,!ms_author,\#nosource,⛔ No DOI found,jabref_imp2}
}

@unpublished{Schubotz16CICM,
  title = {Implicit {{Content Dictionaries}} in the {{NIST Digital Repository}} of {{Mathematical Formulae}}},
  author = {Schubotz, Moritz},
  date = {2016-07-25},
  url = {http://cicm-conference.org/2016/cicm.php?event=&menu=talks#O3},
  urldate = {2016-10-03},
  eventtitle = {{{OpenMath Workshop}} of the 9th {{Conference}} on {{Intelligent Computer Mathematics CICM}} 2016},
  jabref-groups = {phd-m},
  langid = {english},
  oldkey = {schubotz16implCd},
  owner = {Moritz},
  venue = {{Bialystok, Poland}},
  keywords = {!ms,!ms_author,\#nosource,jabref_imp2}
}

@report{Schubotz16NTCIRData,
  ids = {11303_6571},
  title = {Identifier {{Gold Standard}} for {{NTCIR}} 11 {{Math Wikipedia Dataset}}},
  author = {Schubotz, Moritz},
  date = {2016-07-18},
  publisher = {{Technische Universität Berlin}},
  doi = {10.14279/depositonce-6064},
  url = {https://depositonce.tu-berlin.de/handle/11303/6571},
  urldate = {2020-04-11},
  abstract = {Mathematical formulae are essential in science, but face challenges of ambiguity, due to the use of a small number of identifiers to represent an immense number of concepts. Corresponding to word sense disambiguation in Natural Language Processing, we disambiguate mathematical identifiers. By regarding formulae and natural text as one monolithic information source, we are able to extract the semantics of identifiers in a process we term Mathematical Language Processing (MLP). As scientific communities tend to establish standard (identifier) notations, we use the document domain to infer the actual meaning of an identifier. Therefore, we adapt the software development concept of namespaces to mathematical notation. Thus, we learn namespace definitions by clustering the MLP results and mapping those clusters to subject classification schemata. In addition, this gives fundamental insights into the usage of mathematical notations in science, technology, engineering and mathematics. Our gold standard based evaluation shows that MLP extracts relevant identifier-definitions. Moreover, we discover that identifier namespaces improve the performance of automated identifier-definition extraction, and elevate it to a level that cannot be achieved within the document context alone.},
  editora = {{Technische Universität Berlin} and Howard, S. Cohl},
  editoratype = {collaborator},
  langid = {english},
  oldkey = {dataIdentifierGold16},
  owner = {Moritz},
  keywords = {!ms,!ms_author,\#nosource,jabref_imp2}
}

@book{Schubotz17,
  title = {Augmenting {{Mathematical Formulae}} for {{More Effective Querying}} \& {{Efficient Presentation}}},
  author = {Schubotz, Moritz},
  date = {2017},
  publisher = {{Epubli Verlag, Berlin}},
  doi = {10.14279/depositonce-6034},
  url = {https://www.epubli.de/preview/publication/64471},
  isbn = {978-3-7450-6208-3},
  oldkey = {dis},
  owner = {Moritz},
  keywords = {!ms,!ms_author,\#nosource,jabref_imp2}
}

@inproceedings{Schubotz18CICM,
  title = {Generating {{OpenMath Content Dictionaries}} from {{Wikidata}}},
  booktitle = {Joint {{Proceedings}} of the {{CME}}-{{EI}}, {{FMM}}, {{CAAT}}, {{FVPS}}, {{M3SRD}}, {{OpenMath Workshops}}, {{Doctoral Program}} and {{Work}} in {{Progress}} at the {{Conference}} on {{Intelligent Computer Mathematics}} 2018 co-located with the 11th {{Conference}} on {{Intelligent Computer Mathematics}} ({{CICM}} 2018)},
  author = {Schubotz, Moritz},
  editor = {Hasan, Osman and Youssef, Abdou and Naumowicz, Adam and Farmer, William and Kaliszyk, Cezary and Gallois-Wong, Diane and Rabe, Florian and Reis, Gabriel Dos and Passmore, Grant and Davenport, James and Pfeiffer, Markus and Kohlhase, Michael and Autexier, Serge and Tahar, Sofiene and Koprucki, Thomas and Siddique, Umair and Neuper, Walther and Windsteiger, Wolfgang and Schreiner, Wolfgang and Sperber, Wolfram and Kovács, Zoltán},
  date = {2018},
  doi = {10/ggv8jq},
  oldkey = {Schubotz2018b},
  preprint = {https://github.com/ag-gipp/18CicmWikidata/releases/download/build-master-2018-10-16-15/main.pdf},
  topic = {blockchain},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\FDUM32YA\\Schubotz18CICM--generating_openmath_content_dictionaries_from_wikidata.pdf}
}

@inproceedings{Schubotz18GI,
  title = {Mathematische Formeln in Wikipedia},
  booktitle = {Beiträge zum Mathematikunterricht 2018},
  author = {Schubotz, Moritz},
  editor = {der Mathematik der Universität Paderborn, Fachgruppe Didaktik},
  options = {useprefix=true},
  date = {2018},
  pages = {1635--1638},
  publisher = {{Gesellschaft für Didaktik der Mathematik}},
  doi = {10/ggv8jn},
  biburl = {https://search.datacite.org/works/10.17877/DE290R-19676},
  langid = {german},
  oldkey = {Schubotz2018},
  preprint = {https://eldorado.tu-dortmund.de/bitstream/2003/37681/1/BzMU18\textsubscript{S}CHUBOTZₘathwiki.pdf},
  topic = {mathir},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\XZ3V9G3S\\Schubotz18GI--mathematische_formeln_in_wikipedia.pdf}
}

@article{SchubotzB11,
  ids = {SchubotzB11a},
  title = {Random {{Backaction}} in {{Tunneling}} of {{Single Electrons Through Nanostructures}}},
  author = {Schubotz, Moritz and Brandes, Tobias},
  date = {2011-08},
  journaltitle = {Physical Review B},
  volume = {84},
  number = {7},
  pages = {1--8},
  issn = {1098-0121},
  doi = {10/dkr5b2},
  jabref-groups = {phd-m},
  oldkey = {Schubotz11},
  owner = {Moritz},
  preprint = {https://arxiv.org/pdf/1105.4422.pdf},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,arxiv,jabref_imp2,journal,old_tex_field_preprint,peerreview},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\7CIEAV6R\\SchubotzB11--random_backaction_in_tunneling_of_single_electrons_through_nanostructures.pdf}
}

@article{SchubotzBHG18,
  title = {Repurposing {{Open Source Tools}} for {{Open Science}}: {{A Practical Guide}}},
  author = {Schubotz, Moritz and Breitinger, Corinna and Hepp, Thomas and Gipp, Bela},
  date = {2018-11},
  doi = {10/ggv8jp},
  url = {https://zenodo.org/record/2453415/files/bc4openScience.pdf?download=1},
  biburl = {https://zenodo.org/record/2453415/export/hx\#.XCJhJ8Yo8aw},
  oldkey = {Schubotz2018d},
  url_orig = {https://doi.org/10.5281/zenodo.2453415},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!ms,!ms_author,!ms_cv,!ms_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TN325PYX\\SchubotzBHG18--repurposing_open_source_tools_for_open_science_a_practical_guide.pdf}
}

@inproceedings{SchubotzGLC16,
  ids = {SchubotzGLC16a,disSigir16},
  title = {Semantification of {{Identifiers}} in {{Mathematics}} for {{Better Math Information Retrieval}}},
  shorttitle = {Semantification of {{Identifiers}} in {{Mathematics}} for {{MIR}}},
  booktitle = {Proceedings of the 39th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Schubotz, Moritz and Grigorev, Alexey and Leich, Marcus and Cohl, Howard S. and Meuschke, Norman and Gipp, Bela and Youssef, Abdou S. and Markl, Volker},
  date = {2016-07},
  series = {{{SIGIR}} '16},
  pages = {135--144},
  publisher = {{ACM}},
  location = {{New York, NY, USA}},
  doi = {10/ggv8jm},
  abstract = {Mathematical formulae are essential in science, but face challenges of ambiguity, due to the use of a small number of identifiers to represent an immense number of concepts. Corresponding to word sense disambiguation in Natural Language Processing, we disambiguate mathematical identifiers. By regarding formulae and natural text as one monolithic information source, we are able to extract the semantics of identifiers in a process we term Mathematical Language Processing (MLP). As scientific communities tend to establish standard (identifier) notations, we use the document domain to infer the actual meaning of an identifier. Therefore, we adapt the software development concept of namespaces to mathematical notation. Thus, we learn namespace definitions by clustering the MLP results and mapping those clusters to subject classification schemata. In addition, this gives fundamental insights into the usage of mathematical notations in science, technology, engineering and mathematics. Our gold standard based evaluation shows that MLP extracts relevant identifier-definitions. Moreover, we discover that identifier namespaces improve the performance of automated identifier-definition extraction, and elevate it to a level that cannot be achieved within the document context alone.},
  core = {A*},
  isbn = {978-1-4503-4069-4},
  jabref-groups = {phd-m},
  numpages = {10},
  oldkey = {Schubotz16},
  owner = {Moritz},
  preprint = {https://ag-gipp.github.io/bib/preprints/schubotz16.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,definitions,identifiers,jabref_imp1_clean,mathematical information retrieval,mathematical knowledge management,mathematical language processing,mathematics,mathoid,mathosphere,MIR,MLP,namespace discovery,old_tex_field_preprint,wikipedia},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\2XX9XEG4\\SchubotzGLC16--semantification_of_identifiers_in_mathematics_for_better_math_information_retrieval.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\49BB753K\\SchubotzGLC16--semantification_of_identifiers_in_mathematics_for_better_math_information_retrieval.pdf}
}

@inproceedings{SchubotzGSM18,
  ids = {Schubotz2018c,SchubotzGSM18a},
  title = {Improving the {{Representation}} and {{Conversion}} of {{Mathematical Formulae}} by {{Considering}} their {{Textual Context}}},
  booktitle = {Proceedings of the 18th {{ACM}}/{{IEEE}} on {{Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Schubotz, Moritz and Greiner-Petter, André and Scharpf, Philipp and Meuschke, Norman and Cohl, Howard S. and Gipp, Bela},
  date = {2018-06},
  pages = {233--242},
  publisher = {{ACM}},
  location = {{Fort Worth, USA}},
  doi = {10/ggv8jk},
  url = {http://doi.acm.org/10.1145/3197026.3197058},
  abstract = {Mathematical formulae represent complex semantic information in a concise form. Especially in Science, Technology, Engineering, and Mathematics, mathematical formulae are crucial to communicate information, e.g., in scientific papers, and to perform computations using computer algebra systems. Enabling computers to access the information encoded in mathematical formulae requires machine-readable formats that can represent both the presentation and content, i.e., the semantics, of formulae. Exchanging such information between systems additionally requires conversion methods for mathematical representation formats. We analyze how the semantic enrichment of formulae improves the format conversion process and show that considering the textual context of formulae reduces the error rate of such conversions. Our main contributions are: (1) providing an openly available benchmark dataset for the mathematical format conversion task consisting of a newly created test collection, an extensive, manually curated gold standard and task-specific evaluation metrics; (2) performing a quantitative evaluation of state-of-the-art tools for mathematical format conversions; (3) presenting a new approach that considers the textual context of formulae to reduce the error rate for mathematical format conversions. Our benchmark dataset facilitates future research on mathematical format conversions as well as research on many problems in mathematical information retrieval. Because we annotated and linked all components of formulae, e.g., identifiers, operators and other entities, to Wikidata entries, the gold standard can, for instance, be used to train methods for formula concept discovery and recognition. Such methods can then be applied to improve mathematical information retrieval systems, e.g., for semantic formula search, recommendation of mathematical content, or detection of mathematical plagiarism.},
  biburl = {https://dblp.org/rec/bib/conf/jcdl/SchubotzGSMCG18},
  core = {0;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/},
  isbn = {978-1-4503-5178-2},
  oldkey = {SchubotzGSMCG18},
  preprint = {https://arxiv.org/pdf/1804.04956.pdf},
  url_orig = {http://doi.acm.org/10.1145/3197026.3197058},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,DFG1259-1,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\65QGRUQJ\\SchubotzGSM18--improving_the_representation_and_conversion_of_mathematical_formulae_by_considering.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\QLKLEDSY\\SchubotzGSM18--improving_the_representation_and_conversion_of_mathematical_formulae_by_considering.pdf}
}

@incollection{SchubotzKMH17,
  ids = {SchubotzKMH17a},
  title = {Evaluating and {{Improving}} the {{Extraction}} of {{Mathematical Identifier Definitions}}},
  booktitle = {Experimental {{IR Meets Multilinguality}}, {{Multimodality}}, and {{Interaction}}},
  author = {Schubotz, Moritz and Krämer, Leonard and Meuschke, Norman and Hamborg, Felix and Gipp, Bela},
  editor = {Jones, Gareth J.F. and Lawless, Séamus and Gonzalo, Julio and Kelly, Liadh and Goeuriot, Lorraine and Mandl, Thomas and Cappellato, Linda and Ferro, Nicola},
  date = {2017-08},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {10456 LNCS},
  pages = {82--94},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-65813-1_7},
  url = {http://link.springer.com/10.1007/978-3-319-65813-1_7},
  abstract = {Mathematical formulae in academic texts significantly contribute to the overall semantic content of such texts, especially in the fields of Science, Technology, Engineering and Mathematics. Knowing the definitions of the identifiers in mathematical formulae is essential to understand the semantics of the formulae. Similar to the sense-making process of human readers, mathematical information retrieval systems can analyze the text that surrounds formulae to extract the definitions of identifiers occurring in the formulae. Several approaches for extracting the definitions of mathematical identifiers from documents have been proposed in recent years. So far, these approaches have been evaluated using different collections and gold standard datasets, which prevented comparative performance assessments. To facilitate future research on the task of identifier definition extraction, we make three contributions. First, we provide an automated evaluation framework, which uses the dataset and gold standard of the NTCIR-11 Math Retrieval Wikipedia task. Second, we compare existing identifier extraction approaches using the developed evaluation framework. Third, we present a new identifier extraction approach that uses machine learning to combine the well-performing features of previous approaches. The new approach increases the precision of extracting identifier definitions from 17.85\% to 48.60\%, and increases the recall from 22.58\% to 28.06\%. The evaluation framework, the dataset and our source code are openly available at: https://ident.formulasearchengine.com.},
  biburl = {https://dblp.org/rec/bib/conf/clef/SchubotzKMHG17},
  isbn = {978-3-319-65812-4 978-3-319-65813-1},
  oldkey = {Schubotz2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/schubotz2017.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\6MVTKEUA\\SchubotzKMH17--evaluating_and_improving_the_extraction_of_mathematical_identifier_definitions.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\TKXQK4TI\\SchubotzKMH17--evaluating_and_improving_the_extraction_of_mathematical_identifier_definitions.pdf}
}

@inproceedings{SchubotzLM13,
  ids = {SchubotzLM13a},
  title = {Querying {{Large Collections}} of {{Mathematical Publications}}: {{NTCIR10 Math Task}}},
  shorttitle = {Querying large collections of mathematical publications},
  booktitle = {Proceedings of the 10th {{NTCIR Conference}} on {{Evaluation}} of {{Information Access Technologies}}, {{NTCIR}}-10, {{National Center}} of {{Sciences}}, {{Tokyo}}, {{Japan}}, {{June}} 18-21, 2013},
  author = {Schubotz, Moritz and Leich, Marcus and Markl, Volker},
  editor = {Kando, Noriko and Kato, Tsuneaki},
  date = {2013},
  series = {ntcir-math.nii.ac.jp},
  pages = {667--674},
  publisher = {{National Institute of Informatics (NII)}},
  url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings10/pdf/NTCIR/MATH/03-NTCIR10-MATH-SchubotzM.pdf},
  abstract = {In this paper, we present our approach for searching mathematical formulae. We focus on a batch query approach that does not rely on specialized indexes, which are usually domain dependent and restrict the expressiveness of the query language. Instead, we use Stratosphere, a distributed data processing platform for Big Data Analytics that accesses data in a non-indexed format. This system is very effective for answering batches of queries that a researcher may wish to evaluate in bulk on large data sets. We demonstrate our approach using the NTCIR10 Math task, which provides a set of formula patterns and a test data corpus. We showcase a simple data analysis program for answering the given queries. We interpret the patterns as regular expressions and assume that matches to these expressions are also relevant search results to the end-user. Based on the evaluation of our results by mathematicians from Zentralblatt Math and mathematics students from Jacobs University, we conclude that our assumption holds principally with regard to precision and recall. Our work is just a first step towards a well-defined query language and processing system for scientific publications that allows researchers to specify their information need in terms of mathematical formulae and their contexts. We envision that our system can be utilized to realize such a vision.},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/ntcir/SchubotzLM13},
  jabref-groups = {GuidiReview, phd-m},
  maintitle = {Querying large collections of mathematical publications},
  oldkey = {Schubotz2013},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,conference,jabref_imp2,math search,mathml,ntcir,old_tex_field_preprint,peerreview,query language,stratosphere},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\PFLPUHHL\\SchubotzLM13--querying_large_collections_of_mathematical_publications_ntcir10_math_task.pdf}
}

@incollection{SchubotzMHC17,
  ids = {SchubotzMHC17a,SchubotzMHC17b},
  title = {{{VMEXT}}: {{A Visualization Tool}} for {{Mathematical Expression Trees}}},
  shorttitle = {{{VMEXT}}},
  booktitle = {Intelligent {{Computer Mathematics}}},
  author = {Schubotz, Moritz and Meuschke, Norman and Hepp, Thomas and Cohl, Howard S. and Gipp, Bela},
  editor = {Geuvers, Herman and England, Matthew and Hasan, Osman and Rabe, Florian and Teschke, Olaf},
  date = {2017-07},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {10383 LNCS},
  pages = {340--355},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/978-3-319-62075-6_24},
  abstract = {Mathematical expressions can be represented as a tree consisting of terminal symbols, such as identifiers or numbers (leaf nodes), and functions or operators (non-leaf nodes). Expression trees are an important mechanism for storing and processing mathematical expressions as well as the most frequently used visualization of the structure of mathematical expressions. Typically, researchers and practitioners manually visualize expression trees using general-purpose tools. This approach is laborious, redundant, and error-prone. Manual visualizations represents a user’s notion of what the markup of an expression should be, but not necessarily what the actual markup is. This paper presents VMEXT – a free and open source tool to directly visualize expression trees from parallel  Open image in new window. VMEXT simultaneously visualizes the presentation elements and the semantic structure of mathematical expressions to enable users to quickly spot deficiencies in the Content  Open image in new window markup that does not affect the presentation of the expression. Identifying such discrepancies previously required reading the verbose and complex  Open image in new window markup. VMEXT also allows one to visualize similar and identical elements of two expressions. Visualizing expression similarity can support developers in designing retrieval approaches and enable improved interaction concepts for users of mathematical information retrieval systems. We demonstrate VMEXT’s visualizations in two web-based applications. The first application presents the visualizations alone. The second application shows a possible integration of the visualizations in systems for mathematical knowledge management and mathematical information retrieval. The application converts  Open image in new window input to parallel  Open image in new window, computes basic similarity measures for mathematical expressions, and visualizes the results using VMEXT.},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/mkm/SchubotzMHCG17},
  isbn = {978-3-319-62074-9},
  oldkey = {vmext17},
  preprint = {https://arxiv.org/pdf/1707.03540.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\MM2AGMI7\\SchubotzMHC17--vmext_a_visualization_tool_for_mathematical_expression_trees.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\NINLQE6E\\SchubotzMHC17--vmext_a_visualization_tool_for_mathematical_expression_trees.pdf}
}

@inproceedings{SchubotzMLG16,
  ids = {SchubotzMLG16a,SchubotzMLG16b},
  title = {Exploring the {{One}}-brain {{Barrier}}: a {{Manual Contribution}} to the {{NTCIR}}-12 {{Math Task}}},
  shorttitle = {Exploring the one-brain-barrier},
  booktitle = {Proceedings of the 12th {{NTCIR Conference}} on {{Evaluation}} of {{Information Access Technologies}}},
  author = {Schubotz, Moritz and Meuschke, Norman and Leich, Marcus and Gipp, Bela},
  date = {2016-06},
  doi = {10/ggv8px},
  url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings12/pdf/ntcir/MathIR/02-NTCIR12-MathIR-SchubotzM.pdf},
  abstract = {This paper compares the search capabilities of a single human brain supported by the text search built into Wikipedia with state-of-the-art math search systems. To achieve this, we compare results of manual Wikipedia searches with the aggregated and assessed results of all systems participating in the NTCIR-12 MathIR Wikipedia Task. For 26 of the 30 topics, the average relevance score of our manually retrieved results exceeded the average relevance score of other participants by more than one standard deviation. However, math search engines at large achieved better recall and retrieved highly relevant results that our ‘single-brain system’ missed for 12 topics. By categorizing the topics of NTCIR-12 into six types of queries, we observe a particular strength of math search engines to answer queries of the types ‘definition lookup’ and ‘application look-up’. However, we see the low precision of current math search engines as the main challenge that prevents their wide-spread adoption in STEM research. By combining our results with highly relevant results of all other participants, we compile a new gold standard dataset and a dataset of duplicate content items. We discuss how the two datasets can be used to improve the query formulation and content augmentation capabilities of match search engines in the future},
  biburl = {https://dblp.org/rec/bib/conf/ntcir/SchubotzMLG16},
  jabref-groups = {phd-m},
  maintitle = {Exploring the one-brain-barrier},
  oldkey = {Schubotz2016b},
  owner = {Moritz},
  preprint = {https://ag-gipp.github.io/bib/preprints/schubotz2016b.pdf},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\76N3VCRP\\SchubotzMLG16--exploring_the_one-brain_barrier_a_manual_contribution_to_the_ntcir-12_math_task.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\G8RDELGE\\SchubotzMLG16--exploring_the_one-brain_barrier_a_manual_contribution_to_the_ntcir-12_math_task.pdf}
}

@inproceedings{SchubotzS16,
  title = {A {{Smooth Transition}} to {{Modern Mathoid}}-{{Based Math Rendering}} in {{Wikipedia}} with {{Automatic Visual Regression Testing}}},
  booktitle = {Joint {{Proceedings}} of the {{FM4M}}, {{MathUI}}, and {{ThEdu Workshops}}, {{Doctoral Program}}, and {{Work}} in {{Progress}} at the {{Conference}} on {{Intelligent Computer Mathematics}} 2016 co-located with the 9th {{Conference}} on {{Intelligent Computer Mathematics}} ({{CICM}} 2016), {{Bialystok}}, {{Poland}}, {{July}} 25-29, 2016.},
  author = {Schubotz, Moritz and Sexton, Alan P.},
  editor = {Kohlhase, Andrea and Libbrecht, Paul and Miller, Bruce R. and Naumowicz, Adam and Neuper, Walther and Quaresma, Pedro and Tompa, Frank Wm. and Suda, Martin},
  date = {2016},
  series = {{{CEUR}} workshop proceedings},
  volume = {1785},
  pages = {132--145},
  publisher = {{CEUR-WS.org}},
  doi = {10/ggv8mp},
  url = {http://ceur-ws.org/Vol-1785/W48.pdf},
  biburl = {https://dblp.org/rec/bib/conf/cikm/SchubotzS16},
  homepage = {https://github.com/wikimedia/mathoid/},
  jabref-groups = {phd-m},
  oldkey = {disCicm16Mathpipe},
  owner = {Moritz},
  preprint = {http://pure-oai.bham.ac.uk/ws/files/31196373/Schubotz\textsubscript{S}exton\textsubscript{S}mooth\textsubscript{T}ransition\textsubscript{C}EUR\textsubscript{P}roceedings.pdf},
  keywords = {!ms,!ms_author,!ms_cv,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{SchubotzSDN18,
  title = {Introducing {{MathQA}}  - a {{Math}}-{{Aware Question Answering System}}},
  booktitle = {Proceedings of the {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}}), {{Workshop}} on {{Knowledge Discovery}}},
  author = {Schubotz, Moritz and Scharpf, Philipp and Dudhat, Kaushal and Nagar, Yash and Hamborg, Felix and Gipp, Bela},
  date = {2018-06},
  location = {{Fort Worth, USA}},
  doi = {10/gf4mvh},
  biburl = {https://www.emeraldinsight.com/action/showCitFormats?doi=10.1108\%2FIDD-06-2018-0022},
  oldkey = {Schubotz2018a},
  preprint = {https://www.emeraldinsight.com/eprint/FXthtRDDEGcMVzInHphu/full},
  topic = {mathir},
  keywords = {!bg,!bg_author,!bg_preprint,!fh,!fh_author,!ms,!ms_author,!ms_cv,!ms_preprint,DFG1259-1,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\RUXS4Y94\\SchubotzSDN18--introducing_mathqa__-_a_math-aware_question_answering_system.pdf}
}

@article{SchubotzT19,
  title = {Four {{Decades}} of {{TeX}} at {{zbMATH}}.},
  author = {Schubotz, Moritz and Teschke, Olaf},
  date = {2019},
  journaltitle = {European Mathematical Society Newsletter},
  volume = {112},
  pages = {50--52},
  publisher = {{European Mathematical Society (EMS) Publishing House, Zurich}},
  issn = {1027-488X},
  doi = {10/ggv8mq},
  url = {http://www.ems-ph.org/journals/show_pdf.php?issn=1027-488x&vol=6&iss=112&rank=15},
  biburl = {https://zbmath.org/bibtex/07065264.bib},
  langid = {english},
  oldkey = {Schubotz2019b},
  keywords = {!ms,!ms_author,!ms_cv,\#nosource,jabref_imp2,old_tex_field_preprint}
}

@inproceedings{SchubotzTSM19,
  ids = {SchubotzTSM19a},
  title = {Forms of {{Plagiarism}} in {{Digital Mathematical Libraries}}},
  booktitle = {Proceedings {{International Conference}} on {{Intelligent Computer Mathematics}}},
  author = {Schubotz, Moritz and Teschke, Olaf and Stange, Vincent and Meuschke, Norman and Gipp, Bela},
  date = {2019-07},
  volume = {11617 LNCS},
  pages = {258--274},
  location = {{Czech Republic}},
  doi = {10/ggv8ps},
  abstract = {We report on an exploratory analysis of the forms of plagiarism observable in mathematical publications, which we identified by investigating editorial notes from zbMATH. While most cases we encountered were simple copies of earlier work, we also identified several forms of disguised plagiarism. We investigated 11 cases in detail and evaluate how current plagiarism detection systems perform in identifying these cases. Moreover, we describe the steps required to discover these and potentially undiscovered cases in the future.},
  oldkey = {Schubotz2019},
  preprint = {https://ag-gipp.github.io/bib/preprints/schubotz2019.pdf},
  topic = {pd},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,DFG1259-1,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\R2HJA4HQ\\SchubotzTSM19--forms_of_plagiarism_in_digital_mathematical_libraries.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\SY6NAZVR\\SchubotzTSM19--forms_of_plagiarism_in_digital_mathematical_libraries.pdf}
}

@inproceedings{SchubotzVC16,
  title = {Getting the {{Units Right}}},
  booktitle = {Joint {{Proceedings}} of the {{FM4M}}, {{MathUI}}, and {{ThEdu Workshops}}, {{Doctoral Program}}, and {{Work}} in {{Progress}} at the {{Conference}} on {{Intelligent Computer Mathematics}} 2016 co-located with the 9th {{Conference}} on {{Intelligent Computer Mathematics}} ({{CICM}} 2016), {{Bialystok}}, {{Poland}}, {{July}} 25-29, 2016.},
  author = {Schubotz, Moritz and Veenhuis, David and Cohl, Howard S.},
  editor = {Kohlhase, Andrea and Libbrecht, Paul and Miller, Bruce R. and Naumowicz, Adam and Neuper, Walther and Quaresma, Pedro and Tompa, Frank Wm. and Suda, Martin},
  date = {2016},
  series = {{{CEUR}} workshop proceedings},
  volume = {1785},
  pages = {146--156},
  publisher = {{CEUR-WS.org}},
  doi = {10/ggv8pv},
  url = {http://ceur-ws.org/Vol-1785/W45.pdf},
  biburl = {https://dblp.org/rec/bib/conf/cikm/SchubotzVC16},
  jabref-groups = {phd-m},
  oldkey = {disCicm16Units},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\WG9KQDR7\\SchubotzVC16--getting_the_units_right.pdf}
}

@inproceedings{SchubotzW14,
  ids = {SchubotzW14a},
  title = {Mathoid: {{Robust}}, {{Scalable}}, {{Fast}} and {{Accessible Math Rendering}} for {{Wikipedia}}},
  booktitle = {Intelligent {{Computer Mathematics}} - {{International Conference}}, {{CICM}} 2014, {{Coimbra}}, {{Portugal}}, {{July}} 7-11, 2014. {{Proceedings}}},
  author = {Schubotz, Moritz and Wicke, Gabriel},
  editor = {Watt, Stephen M. and Davenport, James H. and Sexton, Alan P. and Sojka, Petr and Urban, Josef},
  date = {2014},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {8543},
  pages = {224--235},
  publisher = {{Springer}},
  doi = {10/ggv8pz},
  biburl = {https://dblp.org/rec/bib/conf/mkm/SchubotzW14},
  homepage = {https://github.com/wikimedia/mathoid/},
  jabref-groups = {phd-m},
  oldkey = {Schubotz2014},
  owner = {Moritz},
  preprint = {https://arxiv.org/pdf/1404.6179.pdf},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\34E568W7\\SchubotzW14--mathoid_robust_scalable_fast_and_accessible_math_rendering_for_wikipedia.pdf}
}

@inproceedings{SchubotzYMC14,
  title = {Evaluation of {{Similarity}}-{{Measure Factors}} for {{Formulae Based}} on the {{NTCIR}}-11 {{Math Task}}},
  shorttitle = {Evaluation of {{Similarity}}-{{Measure Factors}} for {{Formulae}}},
  booktitle = {Proceedings of the 11th {{NTCIR Conference}} on {{Evaluation}} of {{Information Access Technologies}}, {{NTCIR}}-11, {{National Center}} of {{Sciences}}, {{Tokyo}}, {{Japan}}, {{December}} 9-12, 2014},
  author = {Schubotz, Moritz and Youssef, Abdou and Markl, Volker and Cohl, Howard S. and Li, Jimmy J.},
  editor = {Kando, Noriko and Joho, Hideo and Kishida, Kazuaki},
  date = {2014},
  publisher = {{National Institute of Informatics (NII)}},
  url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings11/pdf/NTCIR/Math-2/04-NTCIR11-MATH-SchubotzM.pdf},
  abstract = {In this paper we evaluate the similarity-measure factors pro- posed by Zhang and Youssef based on the NTCIR-11 gold standard. In contrast to Zhang and Youssef we evaluate them individually. The evaluation indicates that four of five factors are relevant. The fifth factor alone is of lower rele- vance than the other four factors. However, we do not prove that the fifth factor is irrelevant.},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/ntcir/SchubotzYMCL14},
  jabref-groups = {GuidiReview, phd-m},
  maintitle = {Evaluation of similarity-measure factors for formulae},
  oldkey = {disNtcir11Sim},
  owner = {Moritz},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\J8FMLIJ2\\SchubotzYMC14--evaluation_of_similarity-measure_factors_for_formulae_based_on_the_ntcir-11_math.pdf}
}

@inproceedings{SchubotzYMC15,
  title = {Challenges of {{Mathematical Information Retrieval}} in the {{NTCIR}}-11 {{Math Wikipedia Task}}},
  shorttitle = {Challenges of  {{MIR}} in {{WMC}}},
  booktitle = {Proceedings of the 38th {{Annual International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Schubotz, Moritz and Youssef, Abdou and Markl, Volker and Cohl, Howard S.},
  editor = {Baeza-Yates, Ricardo A. and Lalmas, Mounia and Moffat, Alistair and Ribeiro-Neto, Berthier A.},
  date = {2015},
  series = {{{SIGIR}} '15},
  pages = {951--954},
  publisher = {{ACM}},
  location = {{Santiago, Chile}},
  doi = {10/ggv8pt},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/sigir/SchubotzYMC15},
  core = {A*},
  isbn = {978-1-4503-3621-5},
  jabref-groups = {phd-m},
  numpages = {4},
  oldkey = {disSigir15},
  owner = {Moritz},
  preprint = {https://www2.seas.gwu.edu/ ayoussef/papers/Challenges\%20of\%20Mathematical\%20Information\%20Retrieval\%20in\%20the\%20NTCIR-11-SIGIR2015.pdf},
  keywords = {!ms,!ms_author,!ms_cv,!ms_preprint,\#nosource,benchmark,dataset,jabref_imp2,LaTeXML,math information retrieval,math search,mathML,mathoid,MIR,NTCIR,old_tex_field_preprint,task,wikipedia},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TMD3AHLG\\SchubotzYMC15--challenges_of_mathematical_information_retrieval_in_the_ntcir-11_math_wikipedia_task.pdf}
}

@inproceedings{SchwarzerBSM17,
  ids = {SchwarzerBSM17a},
  title = {Citolytics: {{A Link}}-based {{Recommender System}} for {{Wikipedia}}},
  shorttitle = {Citolytics},
  booktitle = {Proceedings of the 11th {{ACM Conference}} on {{Recommender Systems}} ({{RecSys}})},
  author = {Schwarzer, Malte and Breitinger, Corinna and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
  date = {2017-08},
  pages = {360--361},
  publisher = {{ACM}},
  doi = {10/ggv8pw},
  abstract = {We present Citolytics - a novel link-based recommendation system for Wikipedia articles. In a preliminary study, Citolytics achieved promising results compared to the widely used text-based approach of Apache Lucene's MoreLikeThis (MLT). In this demo paper, we describe how we plan to integrate Citolytics into the Wikipedia infrastructure by using Elasticsearch and Apache Flink to serve recommendations for Wikipedia articles. Additionally, we propose a large-scale online evaluation design using the Wikipedia Android app. Working with Wikipedia data has several unique advantages. First, the availability of a very large user sample contributes to statistically significant results. Second, the openness of Wikipedia's architecture allows making our source code and evaluation data public, thus benefiting other researchers. If link-based recommendations show promise in our online evaluation, a deployment of the presented system within Wikipedia would have a far-reaching impact on Wikipedia's more than 30 million users.},
  biburl = {https://dblp.org/rec/bib/conf/recsys/SchwarzerBSMG17},
  isbn = {978-1-4503-4652-8},
  oldkey = {Schwarzer2017},
  preprint = {https://ag-gipp.github.io/bib/preprints/schwarzer2017.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\QJR67A34\\SchwarzerBSM17--citolytics_a_link-based_recommender_system_for_wikipedia.pdf;D\:\\Zotero\\nmeuschke\\Data\\storage\\WDE3CYWU\\SchwarzerBSM17--citolytics_a_link-based_recommender_system_for_wikipedia.pdf}
}

@inproceedings{SchwarzerSMB16,
  ids = {SchwarzerSMB16a},
  title = {Evaluating {{Link}}-based {{Recommendations}} for {{Wikipedia}}},
  booktitle = {Proceedings of the 16th {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Schwarzer, Malte and Schubotz, Moritz and Meuschke, Norman and Breitinger, Corinna and Markl, Volker and Gipp, Bela},
  date = {2016-06},
  pages = {191--200},
  publisher = {{ACM}},
  location = {{Newark, New Jersey, USA}},
  doi = {10/ggv7ns},
  abstract = {Literature recommender systems support users in filtering the vast and increasing number of documents in digital libraries and on the Web. For academic literature, research has proven the ability of citation-based document similarity measures, such as Co-Citation (CoCit), or Co-Citation Proximity Analysis (CPA) to improve recommendation quality. In this paper, we report on the first large-scale investigation of the performance of the CPA approach in generating literature recommendations for Wikipedia, which is fundamentally different from the academic literature domain. We analyze links instead of citations to generate article recommendations. We evaluate CPA, CoCit, and the Apache Lucene MoreLikeThis (MLT) function, which represents a traditional text-based similarity measure. We use two datasets of 779,716 and 2.57 million Wikipedia articles, the Big Data processing framework Apache Flink, and a ten-node computing cluster. To enable our large-scale evaluation, we derive two quasi-gold standards from the links in Wikipedia's "See also" sections and a comprehensive Wikipedia clickstream dataset. Our results show that the citation-based measures CPA and CoCit have complementary strengths compared to the text-based MLT measure. While MLT performs well in identifying narrowly similar articles that share similar words and structure, the citation- based measures are better able to identify topically related information, such as information on the city of a certain university or other technical universities in the region. The CPA approach, which consistently outperformed CoCit, is better suited for identifying a broader spectrum of related articles, as well as popular articles that typically exhibit a higher quality. Additional benefits of the CPA approach are its lower runtime requirements and its language-independence that allows for a cross-language retrieval of articles. We present a manual analysis of exemplary articles to demonstrate and discuss our findings. The raw data and source code of our study, together with a manual on how to use them, are openly available at: https://github.com/wikimedia/citolytics},
  core = {A*},
  isbn = {978-1-4503-4229-2},
  oldkey = {Schwarzer2016},
  preprint = {https://ag-gipp.github.io/bib/preprints/schwarzer2016.pdf},
  topic = {rec},
  keywords = {!bg,!bg_author,!bg_preprint,!cb,!cb_author,!ms,!ms_author,!ms_cv,!ms_preprint,!nm,!nm_author,!nm_preprint,jabref_imp1_clean,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\TPJX9NQL\\SchwarzerSMB16--evaluating_link-based_recommendations_for_wikipedia.pdf}
}

@inproceedings{SpindeHBD20,
  title = {Enabling {{News Consumers}} to {{View}} and {{Understand Biased News Coverage}}: {{A Study}} on the {{Perception}} and {{Visualization}} of {{Media Bias}}},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Spinde, Timo and Hamborg, Felix and Becerra, Angelica and Donnay, Karsten and Gipp, Bela},
  date = {2020-08},
  oldkey = {Spinde2020},
  topic = {newsanalysis},
  keywords = {!bg,!bg_author,!fh,!fh_author,\#nosource,jabref_imp2}
}

@incollection{WeilerBGG16,
  title = {Stability {{Evaluation}} of {{Event Detection Techniques}} for {{Twitter}}  - {{Proceedings}} of the 15th {{International Symposium}} on {{Intelligent Data Analysis}} ({{IDA}}'16)},
  booktitle = {Advances in intelligent data analysis {{XV}}},
  author = {Weiler, Andreas and Beel, Joeran and Gipp, Bela and Grossniklaus, Michael},
  editor = {Bostroem, Henrik and Knobbe, Arno and Soares, Carlos and Papapetrou, Panagiotis},
  date = {2016},
  series = {Lecture notes in computer science ({{LNCS}})},
  publisher = {{Springer}},
  doi = {10.1007/978-3-319-46349-0},
  isbn = {978-3-319-46348-3},
  oldkey = {Weiler2016},
  preprint = {https://ag-gipp.github.io/bib/preprints/weiler2016.pdf},
  topic = {misc},
  volumes = {9897},
  keywords = {!bg,!bg_author,!bg_preprint,!jb,!jb_author,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\795EX366\\WeilerBGG16--stability_evaluation_of_event_detection_techniques_for_twitter__-_proceedings_of.pdf}
}

@inproceedings{WortnerSLG19,
  title = {Securing the {{Integrity}} of {{Time Series Data}} in {{Open Science Projects Using Blockchain}}-{{Based Trusted Timestamping}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Web Archiving}} and {{Digital Libraries}} ({{WADL}}) co-located with the {{Annual International ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Wortner, Patrick and Schubotz, Moritz and Leible, Stephan and Gipp, Bela},
  date = {2019-06},
  location = {{Urbana-Champaign, IL, USA}},
  oldkey = {Wortner2019},
  preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/wortner2019.pdf},
  topic = {blockchain},
  keywords = {!bg,!bg_author,!bg_preprint,!ms,!ms_author,!ms_cv,!ms_preprint,jabref_imp2,old_tex_field_preprint},
  file = {D\:\\Zotero\\nmeuschke\\Data\\storage\\9SKIBXYU\\WortnerSLG19--securing_the_integrity_of_time_series_data_in_open_science_projects_using_blockchain.pdf}
}


