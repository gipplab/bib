
@inproceedings{ScharpfSG21,
	title = {Fast Linking of Mathematical Wikidata Entities in Wikipedia Articles Using Annotation Recommendation},
	url = {https://doi.org/10.1145/3442442.3452348},
	doi = {10/gk5d3d},
	pages = {602--609},
	booktitle = {Companion of The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021},
	publisher = {{ACM} / {IW}3C2},
	author = {Scharpf, Philipp and Schubotz, Moritz and Gipp, Bela},
	editor = {Leskovec, Jure and Grobelnik, Marko and Najork, Marc and Tang, Jie and Zia, Leila},
	date = {2021},
	note = {tex.bibsource: dblp computer science bibliography, https://dblp.org
tex.biburl: https://dblp.org/rec/conf/www/{ScharpfSG}21.bib
tex.timestamp: Mon, 07 Jun 2021 14:34:36 +0200
tex.preprint: https://arxiv.org/pdf/2104.05111.pdf},
	keywords = {!ms\_author},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/www/ScharpfSG21.bib},
	timestamp = {Mon, 07 Jun 2021 14:34:36 +0200},
	preprint = {https://arxiv.org/pdf/2104.05111.pdf},
}

@inproceedings{OstendorffRSG20,
	title = {Pairwise Multi-Class Document Classification for Semantic Relations Between Wikipedia Articles},
	booktitle = {Proceedings of the Annual International {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	author = {Ostendorff, Malte and Ruas, Terry and Schubotz, Moritz and Gipp, Bela},
	date = {2020-08},
	note = {tex.oldkey: Ostendorff2020
tex.topic: wiki},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_preprint, jabref\_imp2},
	oldkey = {Ostendorff2020},
	topic = {wiki},
}

@article{GreinerPetterYRM20,
	title = {Math-word embedding in math search and semantic extraction},
	issn = {0138-9130, 1588-2861},
	url = {http://link.springer.com/10.1007/s11192-020-03502-9},
	doi = {10.1007/s11192-020-03502-9},
	journaltitle = {Scientometrics},
	shortjournal = {Scientometrics},
	author = {Greiner-Petter, André and Youssef, Abdou and Ruas, Terry and Miller, Bruce R. and Schubotz, Moritz and Aizawa, Akiko and Gipp, Bela},
	urldate = {2020-06-16},
	date = {2020-06-09},
	langid = {english},
	keywords = {!ag\_author, !bg\_author, !ms\_author, !tr\_author, math search, mathematical information retrieval, nlp, nlp\_embeddings},
}

@inproceedings{ScharpfSYH20,
	title = {Classification and Clustering of {arXiv} Documents, Sections, and Abstracts Comparing Encodings of Natural and Mathematical Language},
	rights = {All rights reserved},
	booktitle = {Proceedings of the {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	author = {Scharpf, Philipp and Schubotz, Moritz and Youssef, Abdou and Hamborg, Felix and Meuschke, Norman and Gipp, Bela},
	date = {2020-06},
	note = {tex.ids: {ScharpfSYH}20a
tex.oldkey: Scharpf2020
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !fh, !fh\_author, !ms, !ms\_author, !nm, !nm\_author, \#nosource, jabref\_imp1\_clean},
	ids = {ScharpfSYH20a},
	oldkey = {Scharpf2020},
	topic = {mathir},
}

@inproceedings{SchubotzGMT20,
	title = {Mathematical Formulae in Wikimedia Projects 2020},
	url = {http://arxiv.org/abs/2003.09417},
	doi = {10.1145/3383583.3398557},
	abstract = {This poster summarizes our contributions to Wikimedia's processing pipeline for mathematical formulae. We describe how we have supported the transition from rendering formulae as course-grained {PNG} images in 2001 to providing modern semantically enriched language-independent {MathML} formulae in 2020. Additionally, we describe our plans to improve the accessibility and discoverability of mathematical knowledge in Wikimedia projects further.},
	booktitle = {Proceedings of the {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	author = {Schubotz, Moritz and Greiner-Petter, André and Meuschke, Norman and Teschke, Olaf and Gipp, Bela},
	urldate = {2020-06-11},
	date = {2020-05-06},
	eprinttype = {arxiv},
	eprint = {2003.09417},
	keywords = {!ms\_author, !nm\_author},
}

@inproceedings{GreinerPetterSMB20,
	title = {Discovering Mathematical Objects of Interest - a Study of Mathematical Notations},
	doi = {10.1145/3366423.3380218},
	booktitle = {Proceedings of the Web Conference 2020 ({WWW}'20), April 20–24, 2020, Taipei, Taiwan},
	author = {Greiner-Petter, André and Schubotz, Moritz and Müller, Fabian and Breitinger, Corinna and Cohl, Howard S. and Aizawa, Akiko and Gipp, Bela},
	date = {2020-04},
	note = {tex.core: 0;Core Rank A*;http://portal.core.edu.au/conf-ranks/1548/
tex.oldkey: {GreinerPetter}2020
tex.preprint: https://ag-gipp.github.io/bib/preprints/greinerpetter2020.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !cb, !cb\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	core = {0;Core Rank A*;http://portal.core.edu.au/conf-ranks/1548/},
	oldkey = {GreinerPetter2020},
	preprint = {https://ag-gipp.github.io/bib/preprints/greinerpetter2020.pdf},
	topic = {mathir},
}

@incollection{FoltynekRSM20,
	location = {Cham},
	title = {Detecting Machine-Obfuscated Plagiarism},
	volume = {12051 {LNCS}},
	rights = {Creative Commons Attribution-{ShareAlike} 4.0 International License ({CC}-{BY}-{SA})},
	isbn = {978-3-030-43686-5 978-3-030-43687-2},
	url = {http://link.springer.com/10.1007/978-3-030-43687-2_68},
	abstract = {Research on academic integrity has identified online paraphrasing tools as a severe threat to the effectiveness of plagiarism detection systems. To enable the automated identification of machine-paraphrased text, we make three contributions. First, we evaluate the effectiveness of six prominent word embedding models in combination with five classifiers for distinguishing human-written from machine-paraphrased text. The best performing classification approach achieves an accuracy of 99.0\% for documents and 83.4\% for paragraphs. Second, we show that the best approach outperforms human experts and established plagiarism detection systems for these classification tasks. Third, we provide a Web application that uses the best performing classification approach to indicate whether a text underwent machine-paraphrasing. The data and code of our study are openly available.},
	pages = {816--827},
	booktitle = {Sustainable Digital Communities},
	publisher = {Springer International Publishing},
	author = {Foltýnek, Tomáš and Ruas, Terry and Scharpf, Philipp and Meuschke, Norman and Schubotz, Moritz and Grosky, William and Gipp, Bela},
	editor = {Sundqvist, Anneli and Berget, Gerd and Nolin, Jan and Skjerdingstad, Kjell Ivar},
	date = {2020-03},
	langid = {english},
	doi = {10.1007/978-3-030-43687-2_68},
	note = {tex.ids: {FoltynekRSM}20a
tex.oldkey: Foltynek2020
tex.topic: pd},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean},
	ids = {FoltynekRSM20a},
	oldkey = {Foltynek2020},
	topic = {pd},
}

@inproceedings{IhleSMG20,
	location = {New York, {NY}, {USA}},
	title = {A first step towards content protecting plagiarism detection},
	isbn = {978-1-4503-7585-6},
	url = {https://doi.org/10.1145/3383583.3398620},
	doi = {10.1145/3383583.3398620},
	series = {{JCDL} '20},
	abstract = {Plagiarism detection systems are essential tools for safeguarding academic and educational integrity. However, today's systems require disclosing the full content of the input documents and the document collection to which the input documents are compared. Moreover, the systems are centralized and under the control of individual, typically commercial providers. This situation raises procedural and legal concerns regarding the confidentiality of sensitive data, which can limit or prohibit the use of plagiarism detection services. To eliminate these weaknesses of current systems, we seek to devise a plagiarism detection approach that does not require a centralized provider nor exposing any content as cleartext. This paper presents the initial results of our research. Specifically, we employ Private Set Intersection to devise a content-protecting variant of the citation-based similarity measure Bibliographic Coupling implemented in our plagiarism detection system {HyPlag}. Our evaluation shows that the content-protecting method achieves the same detection effectiveness as the original method while making common attacks to disclose the protected content practically infeasible. Our future work will extend this successful proof-of-concept by devising plagiarism detection methods that can analyze the entire content of documents without disclosing it as cleartext.},
	pages = {341--344},
	booktitle = {Proceedings of the {ACM}/{IEEE} joint conference on digital libraries in 2020},
	publisher = {Association for Computing Machinery},
	author = {Ihle, Cornelius and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
	date = {2020},
	note = {tex.ids: {IhleSMG}20a
tex.oldkey: Ihle2020
tex.topic: pd
tex.core: A*;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/ihle2020.pdf},
	keywords = {!bg, !bg\_author, !ci, !ci\_author, !ms, !ms\_author, !nm, !nm\_author, \#nosource, decentralized\_open\_science, jabref\_imp1\_clean, plagiarism detection, private computation, similarity detection},
	ids = {IhleSMG20a},
	oldkey = {Ihle2020},
	topic = {pd},
	core = {A*;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/ihle2020.pdf},
}

@inproceedings{SchubotzTSM19,
	location = {Czech Republic},
	title = {Forms of Plagiarism in Digital Mathematical Libraries},
	volume = {11617 {LNCS}},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	doi = {10.1007/978-3-030-23250-4_18},
	abstract = {We report on an exploratory analysis of the forms of plagiarism observable in mathematical publications, which we identified by investigating editorial notes from {zbMATH}. While most cases we encountered were simple copies of earlier work, we also identified several forms of disguised plagiarism. We investigated 11 cases in detail and evaluate how current plagiarism detection systems perform in identifying these cases. Moreover, we describe the steps required to discover these and potentially undiscovered cases in the future.},
	pages = {258--274},
	booktitle = {Proceedings International Conference on Intelligent Computer Mathematics},
	author = {Schubotz, Moritz and Teschke, Olaf and Stange, Vincent and Meuschke, Norman and Gipp, Bela},
	date = {2019-07},
	note = {tex.ids: {SchubotzTSM}19a
tex.oldkey: Schubotz2019
tex.preprint: https://ag-gipp.github.io/bib/preprints/schubotz2019.pdf
tex.topic: pd},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, {DFG}1259-1, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {SchubotzTSM19a},
	oldkey = {Schubotz2019},
	preprint = {https://ag-gipp.github.io/bib/preprints/schubotz2019.pdf},
	topic = {pd},
}

@article{GreinerPetterSCG19,
	title = {Semantic Preserving Bijective Mappings for Expressions Involving Special Functions in Computer Algebra Systems and Document Preparation Systems},
	volume = {71},
	issn = {2050-3806},
	doi = {10.1108/ajim-08-2018-0185},
	pages = {415--439},
	number = {3},
	journaltitle = {Aslib Journal of Information Management},
	author = {Greiner-Petter, Andre and Schubotz, Moritz and Cohl, Howard S. and Gipp, Bela},
	date = {2019-07},
	note = {tex.biburl: https://www.emeraldinsight.com/action/{showCitFormats}?doi=10.1108\%2FAJIM-08-2018-0185
tex.oldkey: {GreinerPetter}2019
tex.preprint: https://ag-gipp.github.io/bib/preprints/greinerpetter2019.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://www.emeraldinsight.com/action/showCitFormats?doi=10.1108%2FAJIM-08-2018-0185},
	oldkey = {GreinerPetter2019},
	preprint = {https://ag-gipp.github.io/bib/preprints/greinerpetter2019.pdf},
	topic = {mathir},
}

@inproceedings{WortnerSLG19,
	location = {Urbana-Champaign, {IL}, {USA}},
	title = {Securing the Integrity of Time Series Data in Open Science Projects Using Blockchain-Based Trusted Timestamping},
	booktitle = {Proceedings of the Workshop on Web Archiving and Digital Libraries ({WADL}) co-located with the Annual International {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	author = {Wortner, Patrick and Schubotz, Moritz and Breitinger, Corinna and Leible, Stephan and Gipp, Bela},
	date = {2019-06},
	note = {tex.oldkey: Wortner2019
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/wortner2019.pdf
tex.topic: blockchain},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, decentralized\_open\_science, jabref\_imp2, old\_tex\_field\_preprint},
	oldkey = {Wortner2019},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/wortner2019.pdf},
	topic = {blockchain},
}

@inproceedings{MeuschkeSSK19,
	location = {Urbana-Champaign, Illinois, {USA}},
	title = {Improving Academic Plagiarism Detection for {STEM} Documents by Analyzing Mathematical Content and Citations},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-72811-547-4},
	doi = {10.1109/jcdl.2019.00026},
	abstract = {Identifying academic plagiarism is a pressing task for educational and research institutions, publishers, and funding agencies. Current plagiarism detection systems reliably find instances of copied and moderately reworded text. However, reliably detecting concealed plagiarism, such as strong paraphrases, translations, and the reuse of nontextual content and ideas is an open research problem. In this paper, we extend our prior research on analyzing mathematical content and academic citations. Both are promising approaches for improving the detection ofconcealed academic plagiarism primarily in Science, Technology, Engineering and Mathematics ({STEM}). We make the following contributions: i) We present a two-stage detec- tion process that combines similarity assessments of mathematical content, academic citations, and text. ii) We introduce new similar- ity measures that consider the order of mathematical features and outperform the measures in our prior research. iii) We compare the effectiveness of the math-based, citation-based, and text-based detection approaches using confirmed cases of academic plagia- rism. iv) We demonstrate that the combined analysis of math-based and citation-based content features allows identifying potentially suspicious cases in a collection of 102K {STEM} documents. Overall, we show that analyzing the similarity of mathematical content and academic citations is a striking supplement for conventional text- based detection approaches for academic literature in the {STEM} disciplines. The data and code of our study are openly available at https://purl.org/{hybridPD}},
	pages = {120--129},
	booktitle = {Proceedings of the  Annual International {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	author = {Meuschke, Norman and Stange, Vincent and Schubotz, Moritz and Kramer, Michael and Gipp, Bela},
	date = {2019-06},
	note = {tex.ids: {MeuschkeSSK}19a
tex.core: 0;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/
tex.oldkey: Meuschke2019
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/meuschke2019.pdf
tex.topic: pd},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, {DFG}1259-1, jabref\_imp1\_clean, old\_tex\_field\_preprint, pd\_litrev19},
	ids = {MeuschkeSSK19a},
	core = {0;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/},
	oldkey = {Meuschke2019},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/meuschke2019.pdf},
	topic = {pd},
}

@inproceedings{ScharpfSCG19,
	title = {Towards Formula Concept Discovery and Recognition},
	volume = {2414},
	url = {http://ceur-ws.org/Vol-2414/paper11.pdf},
	series = {{CEUR} workshop proceedings},
	pages = {108--115},
	booktitle = {Proceedings of the 4th Joint Workshop on Bibliometric-Enhanced Information Retrieval and Natural Language Processing for Digital Libraries ({BIRNDL} 2019) co-located with the 42nd Annual International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval, Paris, France, July 25, 2019.},
	publisher = {{CEUR}-{WS}.org},
	author = {Scharpf, Philipp and Schubotz, Moritz and Cohl, Howard S. and Gipp, Bela},
	editor = {Chandrasekaran, Muthu Kumar and Mayr, Philipp},
	date = {2019},
	note = {tex.ids: {ScharpfSCG}19a
tex.biburl: https://dblp.org/rec/bib/conf/sigir/{ScharpfSCG}19
tex.oldkey: Scharpf2019a
tex.preprint: http://ceur-ws.org/Vol-2414/paper11.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !ms, !ms\_author, !ms\_cv, \#nosource, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	ids = {ScharpfSCG19a},
	biburl = {https://dblp.org/rec/bib/conf/sigir/ScharpfSCG19},
	oldkey = {Scharpf2019a},
	preprint = {http://ceur-ws.org/Vol-2414/paper11.pdf},
	topic = {mathir},
}

@inproceedings{ScharpfMSB19,
	title = {{AnnoMath} {TeX}- a Formula Identifier Annotation Recommender System for {STEM} Documents},
	url = {https://doi.org/10.1145/3298689.3347042},
	doi = {10.1145/3298689.3347042},
	pages = {532--533},
	booktitle = {Proceedings of the 13th {ACM} Conference on Recommender Systems 2019, Copenhagen, Denmark, September 16-20, 2019},
	publisher = {{ACM}},
	author = {Scharpf, Philipp and Mackerracher, Ian and Schubotz, Moritz and Beel, Jöran and Breitinger, Corinna and Gipp, Bela},
	editor = {Bogers, Toine and Said, Alan and Brusilovsky, Peter and Tikk, Domonkos},
	date = {2019},
	note = {tex.biburl: https://dblp.org/rec/bib/conf/recsys/{ScharpfMSBBG}19
tex.core: B;Core Rank B;http://portal.core.edu.au/conf-ranks/28/
tex.homepage: https://annomathtex.wmflabs.org/
tex.oldkey: Scharpf2019b
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/scharpf2019b.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !cb, !cb\_author, !jb, !jb\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://dblp.org/rec/bib/conf/recsys/ScharpfMSBBG19},
	core = {B;Core Rank B;http://portal.core.edu.au/conf-ranks/28/},
	homepage = {https://annomathtex.wmflabs.org/},
	oldkey = {Scharpf2019b},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/scharpf2019b.pdf},
	topic = {mathir},
}

@article{LeibleSSG19,
	title = {A Review on Blockchain Technology and Blockchain Projects Fostering Open Science},
	volume = {2},
	issn = {2624-7852},
	url = {https://www.frontiersin.org/article/10.3389/fbloc.2019.00016},
	doi = {10.3389/fbloc.2019.00016},
	abstract = {Many sectors, like finance, medicine, manufacturing, and education, use blockchain applications to profit from the unique bundle of characteristics of this technology. Blockchain technology ({BT}) promises benefits in trustability, collaboration, organization, identification, credibility, and transparency. In this paper, we conduct an analysis in which we show how open science can benefit from this technology and its properties. For this, we determined the requirements of an open science ecosystem and compared them with the characteristics of {BT} to prove that the technology suits as an infrastructure. We also review literature and promising blockchain-based projects for open science to describe the current research situation. To this end, we examine the projects in particular for their relevance and contribution to open science and categorize them afterwards according to their primary purpose. Several of them already provide functionalities that can have a positive impact on current research workflows. So, {BT} offers promising possibilities for its use in science, but why is it then not used on a large-scale in that area? To answer this question, we point out various shortcomings, challenges, unanswered questions, and research potentials that we found in the literature and identified during our analysis. These topics shall serve as starting points for future research to foster the {BT} for open science and beyond, especially in the long-term.},
	pages = {16},
	journaltitle = {Frontiers in Blockchain},
	author = {Leible, Stephan and Schlager, Steffen and Schubotz, Moritz and Gipp, Bela},
	date = {2019},
	note = {tex.biburl: https://www.frontiersin.org/articles/10.3389/fbloc.2019.00016/{bibTex}
tex.oldkey: Leible2019
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/leible2019.pdf
tex.topic: blockchain},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_preprint, jabref\_imp2},
	biburl = {https://www.frontiersin.org/articles/10.3389/fbloc.2019.00016/bibTex},
	oldkey = {Leible2019},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/leible2019.pdf},
	topic = {blockchain},
}

@inproceedings{GreinerPetterRSA19,
	location = {Paris, France},
	title = {Why Machines Cannot Learn Mathematics, Yet},
	booktitle = {4th Joint Workshop on Bibliometric-Enhanced Information Retrieval and Natural Language Processing for Digital Libraries co-located with the 42nd Annual International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	author = {Greiner-Petter, Andre and Ruas, Terry and Schubotz, Moritz and Aizawa, Akiko and Grosky, William and Gipp, Bela},
	date = {2019},
	note = {tex.ids: {GreinerPetter}2019b, {GreinerPetterRSA}19
tex.oldkey: {GreinerPetter}2019a
tex.topic: mathir
tex.url\_orig: http://ceur-ws.org/Vol-2414/paper14.pdf},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	ids = {GreinerPetter2019b, GreinerPetterRSA19},
	oldkey = {GreinerPetter2019a},
	topic = {mathir},
	url_orig = {http://ceur-ws.org/Vol-2414/paper14.pdf},
}

@article{SchubotzT19,
	title = {Four Decades of {TeX} at {zbMATH}.},
	volume = {112},
	issn = {1027-488X},
	url = {http://www.ems-ph.org/journals/show_pdf.php?issn=1027-488x&vol=6&iss=112&rank=15},
	doi = {10.4171/news/112/15},
	pages = {50--52},
	journaltitle = {European Mathematical Society Newsletter},
	author = {Schubotz, Moritz and Teschke, Olaf},
	date = {2019},
	note = {tex.biburl: https://zbmath.org/bibtex/07065264.bib
tex.oldkey: Schubotz2019b
tex.publisher: European Mathematical Society ({EMS}) Publishing House, Zurich},
	keywords = {!ms, !ms\_author, !ms\_cv, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://zbmath.org/bibtex/07065264.bib},
	oldkey = {Schubotz2019b},
	publisher = {European Mathematical Society (EMS) Publishing House, Zurich},
}

@article{HulekMST19,
	title = {Mathematical Research Data – an Analysis Through {zbMATH} References.},
	volume = {113},
	issn = {1027-488X},
	url = {https://www.ems-ph.org/journals/show_pdf.php?issn=1027-488X&vol=9&iss=113&rank=14},
	doi = {10.4171/news/113/14},
	pages = {54--57},
	journaltitle = {European Mathematical Society. Newsletter},
	author = {Hulek, Klaus and Müller, Fabian and Schubotz, Moritz and Teschke, Olaf},
	date = {2019},
	note = {tex.biburl: https://zbmath.org/bibtex/07111212.bib
tex.oldkey: Hulek19
tex.publisher: European Mathematical Society ({EMS}) Publishing House, Zurich},
	keywords = {!ms, !ms\_author, !ms\_cv, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://zbmath.org/bibtex/07111212.bib},
	oldkey = {Hulek19},
	publisher = {European Mathematical Society (EMS) Publishing House, Zurich},
}

@inproceedings{LeibleSSG18,
	title = {Fostering Open Science by Using Blockchain Technology},
	url = {https://zenodo.org/record/2454725/files/Blockchain-For-Science%20Poster-1.0-final.pdf?download=1},
	doi = {10.5281/zenodo.2454725},
	author = {Leible, Stephan and Schlager, Steffen and Schubotz, Moritz and Gipp, Bela},
	date = {2018-11},
	note = {tex.biburl: https://zenodo.org/record/2454725/export/hx\#.{XCJgpMYo}8ax
tex.oldkey: Leible2018
tex.url\_orig: https://doi.org/10.5281/zenodo.2454725},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://zenodo.org/record/2454725/export/hx#.XCJgpMYo8ax},
	oldkey = {Leible2018},
	url_orig = {https://doi.org/10.5281/zenodo.2454725},
}

@article{SchubotzBHG18,
	title = {Repurposing Open Source Tools for Open Science: A Practical Guide},
	url = {https://zenodo.org/record/2453415/files/bc4openScience.pdf?download=1},
	doi = {10.5281/zenodo.2453415},
	author = {Schubotz, Moritz and Breitinger, Corinna and Hepp, Thomas and Gipp, Bela},
	date = {2018-11},
	note = {tex.biburl: https://zenodo.org/record/2453415/export/hx\#.{XCJhJ}8Yo8aw
tex.oldkey: Schubotz2018d
tex.url\_orig: https://doi.org/10.5281/zenodo.2453415},
	keywords = {!bg, !bg\_author, !bg\_preprint, !cb, !cb\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://zenodo.org/record/2453415/export/hx#.XCJhJ8Yo8aw},
	oldkey = {Schubotz2018d},
	url_orig = {https://doi.org/10.5281/zenodo.2453415},
}

@inproceedings{SchubotzSDN18,
	location = {Fort Worth, {USA}},
	title = {Introducing {MathQA}  - a Math-Aware Question Answering System},
	doi = {10.1108/idd-06-2018-0022},
	booktitle = {Proceedings of the Annual International {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL}), Workshop on Knowledge Discovery},
	author = {Schubotz, Moritz and Scharpf, Philipp and Dudhat, Kaushal and Nagar, Yash and Hamborg, Felix and Gipp, Bela},
	date = {2018-06},
	note = {tex.biburl: https://www.emeraldinsight.com/action/{showCitFormats}?doi=10.1108\%2FIDD-06-2018-0022
tex.oldkey: Schubotz2018a
tex.preprint: https://www.emeraldinsight.com/eprint/{FXthtRDDEGcMVzInHphu}/full
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !fh, !fh\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://www.emeraldinsight.com/action/showCitFormats?doi=10.1108%2FIDD-06-2018-0022},
	oldkey = {Schubotz2018a},
	preprint = {https://www.emeraldinsight.com/eprint/FXthtRDDEGcMVzInHphu/full},
	topic = {mathir},
}

@inproceedings{MeuschkeSSG18,
	location = {Ann Arbor, {MI}, {USA}},
	title = {{HyPlag}: A Hybrid Approach to Academic Plagiarism Detection},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-5657-2},
	doi = {10.1145/3209978.3210177},
	abstract = {Current plagiarism detection systems reliably find instances of copied and moderately altered text, but often fail to detect strong paraphrases, translations, and the reuse of non-textual content and ideas. To improve upon the detection capabilities for such concealed content reuse in academic publications, we make four contributions: i) We present the first plagiarism detection approach that combines the analysis of mathematical expressions, images, citations and text. ii) We describe the implementation of this hybrid detection approach in the research prototype {HyPlag}. iii) We present novel visualization and interaction concepts to aid users in reviewing content similarities identified by the hybrid detection approach. iv) We demonstrate the usefulness of the hybrid detection and result visualization approaches by using {HyPlag} to analyze a confirmed case of content reuse present in a retracted research publication.},
	pages = {1321--1324},
	booktitle = {Proceedings of the 41st International {ACM} {SIGIR} Conference on Research \& Development in Information Retrieval},
	author = {Meuschke, Norman and Stange, Vincent and Schubotz, Moritz and Gipp, Bela},
	date = {2018-06},
	note = {tex.ids: {MeuschkeSSG}18a
tex.biburl: https://dblp.uni-trier.de/rec/bibtex/conf/sigir/{MeuschkeSSG}18
tex.core: A*
tex.oldkey: Meuschke2018a
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/meuschke2018a.pdf
tex.topic: pd},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, {DFG}1259-1, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {MeuschkeSSG18a},
	biburl = {https://dblp.uni-trier.de/rec/bibtex/conf/sigir/MeuschkeSSG18},
	core = {A*},
	oldkey = {Meuschke2018a},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/meuschke2018a.pdf},
	topic = {pd},
}

@inproceedings{SchubotzGSM18,
	location = {Fort Worth, {USA}},
	title = {Improving the Representation and Conversion of Mathematical Formulae by Considering their Textual Context},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-5178-2},
	url = {http://doi.acm.org/10.1145/3197026.3197058},
	doi = {10.1145/3197026.3197058},
	abstract = {Mathematical formulae represent complex semantic information in a concise form. Especially in Science, Technology, Engineering, and Mathematics, mathematical formulae are crucial to communicate information, e.g., in scientific papers, and to perform computations using computer algebra systems. Enabling computers to access the information encoded in mathematical formulae requires machine-readable formats that can represent both the presentation and content, i.e., the semantics, of formulae. Exchanging such information between systems additionally requires conversion methods for mathematical representation formats. We analyze how the semantic enrichment of formulae improves the format conversion process and show that considering the textual context of formulae reduces the error rate of such conversions. Our main contributions are: (1) providing an openly available benchmark dataset for the mathematical format conversion task consisting of a newly created test collection, an extensive, manually curated gold standard and task-specific evaluation metrics; (2) performing a quantitative evaluation of state-of-the-art tools for mathematical format conversions; (3) presenting a new approach that considers the textual context of formulae to reduce the error rate for mathematical format conversions. Our benchmark dataset facilitates future research on mathematical format conversions as well as research on many problems in mathematical information retrieval. Because we annotated and linked all components of formulae, e.g., identifiers, operators and other entities, to Wikidata entries, the gold standard can, for instance, be used to train methods for formula concept discovery and recognition. Such methods can then be applied to improve mathematical information retrieval systems, e.g., for semantic formula search, recommendation of mathematical content, or detection of mathematical plagiarism.},
	pages = {233--242},
	booktitle = {Proceedings of the 18th {ACM}/{IEEE} on Joint Conference on Digital Libraries ({JCDL})},
	publisher = {{ACM}},
	author = {Schubotz, Moritz and Greiner-Petter, André and Scharpf, Philipp and Meuschke, Norman and Cohl, Howard S. and Gipp, Bela},
	date = {2018-06},
	note = {tex.ids: Schubotz2018c, {SchubotzGSM}18a
tex.biburl: https://dblp.org/rec/bib/conf/jcdl/{SchubotzGSMCG}18
tex.core: 0;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/
tex.oldkey: {SchubotzGSMCG}18
tex.preprint: https://arxiv.org/pdf/1804.04956.pdf
tex.url\_orig: http://doi.acm.org/10.1145/3197026.3197058},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, {DFG}1259-1, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {Schubotz2018c, SchubotzGSM18a},
	biburl = {https://dblp.org/rec/bib/conf/jcdl/SchubotzGSMCG18},
	core = {0;Core Rank A*;http://portal.core.edu.au/conf-ranks/2085/},
	oldkey = {SchubotzGSMCG18},
	preprint = {https://arxiv.org/pdf/1804.04956.pdf},
	url_orig = {http://doi.acm.org/10.1145/3197026.3197058},
}

@inproceedings{CohlGS18,
	title = {Automated Symbolic and Numerical Testing of {DLMF} Formulae Using Computer Algebra Systems},
	volume = {11006},
	url = {http://hcohl.sdf.org/CICM2018_Chap4.pdf},
	doi = {10.1007/978-3-319-96812-4_4},
	series = {Lecture notes in computer science},
	pages = {39--52},
	booktitle = {Intelligent Computer Mathematics - 11th International Conference, {CICM} 2018, Hagenberg, Austria, August 13-17, 2018, Proceedings},
	publisher = {Springer},
	author = {Cohl, Howard S. and Greiner-Petter, André and Schubotz, Moritz},
	editor = {Rabe, Florian and Farmer, William M. and Passmore, Grant O. and Youssef, Abdou},
	date = {2018},
	note = {tex.biburl: https://dblp.uni-trier.de/rec/bibtex/conf/mkm/{CohlGS}18
tex.oldkey: Cohl2018
tex.url\_orig: https://doi.org/10.1007/978-3-319-96812-4₄},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://dblp.uni-trier.de/rec/bibtex/conf/mkm/CohlGS18},
	oldkey = {Cohl2018},
	url_orig = {https://doi.org/10.1007/978-3-319-96812-4₄},
}

@inproceedings{Schubotz18GI,
	title = {Mathematische Formeln in Wikipedia},
	doi = {10.17877/de290r-19676},
	pages = {1635--1638},
	booktitle = {Beiträge zum Mathematikunterricht 2018},
	publisher = {Gesellschaft für Didaktik der Mathematik},
	author = {Schubotz, Moritz},
	editor = {der Mathematik der Universität Paderborn, Fachgruppe Didaktik},
	date = {2018},
	langid = {german},
	note = {tex.biburl: https://search.datacite.org/works/10.17877/{DE}290R-19676
tex.oldkey: Schubotz2018
tex.preprint: https://eldorado.tu-dortmund.de/bitstream/2003/37681/1/{BzMU}18$_{\textrm{S}}${CHUBOTZₘathwiki}.pdf
tex.topic: mathir},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://search.datacite.org/works/10.17877/DE290R-19676},
	oldkey = {Schubotz2018},
	preprint = {https://eldorado.tu-dortmund.de/bitstream/2003/37681/1/BzMU18<sub>S</sub>CHUBOTZₘathwiki.pdf},
	topic = {mathir},
}

@inproceedings{Schubotz18CICM,
	title = {Generating {OpenMath} Content Dictionaries from Wikidata},
	doi = {10.5281/zenodo.1409946},
	booktitle = {Joint Proceedings of the {CME}-{EI}, {FMM}, {CAAT}, {FVPS}, M3SRD, {OpenMath} Workshops, Doctoral Program and Work in Progress at the Conference on Intelligent Computer Mathematics 2018 co-located with the 11th Conference on Intelligent Computer Mathematics ({CICM} 2018)},
	author = {Schubotz, Moritz},
	editor = {Hasan, Osman and Youssef, Abdou and Naumowicz, Adam and Farmer, William and Kaliszyk, Cezary and Gallois-Wong, Diane and Rabe, Florian and Reis, Gabriel Dos and Passmore, Grant and Davenport, James and Pfeiffer, Markus and Kohlhase, Michael and Autexier, Serge and Tahar, Sofiene and Koprucki, Thomas and Siddique, Umair and Neuper, Walther and Windsteiger, Wolfgang and Schreiner, Wolfgang and Sperber, Wolfram and Kovács, Zoltán},
	date = {2018},
	note = {tex.oldkey: Schubotz2018b
tex.preprint: https://github.com/ag-gipp/18CicmWikidata/releases/download/build-master-2018-10-16-15/main.pdf
tex.topic: blockchain},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint},
	oldkey = {Schubotz2018b},
	preprint = {https://github.com/ag-gipp/18CicmWikidata/releases/download/build-master-2018-10-16-15/main.pdf},
	topic = {blockchain},
}

@inproceedings{ScharpfSG18,
	title = {Representing Mathematical Formulae in Content {MathML} Using Wikidata},
	volume = {2132},
	url = {http://ceur-ws.org/Vol-2132/paper5.pdf},
	series = {{CEUR} workshop proceedings},
	pages = {46--59},
	booktitle = {Proceedings of the 3rd joint workshop on bibliometric-enhanced information retrieval and natural language processing for digital libraries ({BIRNDL} 2018) co-located with the 41st international {ACM} {SIGIR} conference on research and development in information retrieval ({SIGIR} 2018), ann arbor, {USA}, july 12, 2018.},
	publisher = {{CEUR}-{WS}.org},
	author = {Scharpf, Philipp and Schubotz, Moritz and Gipp, Bela},
	editor = {Mayr, Philipp and Chandrasekaran, Muthu Kumar and Jaidka, Kokil},
	date = {2018},
	note = {tex.biburl: https://dblp.org/rec/bib/conf/sigir/{ScharpfSG}18
tex.oldkey: Scharpf2018
tex.preprint: https://ag-gipp.github.io/bib/preprints/scharpf2018.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	biburl = {https://dblp.org/rec/bib/conf/sigir/ScharpfSG18},
	oldkey = {Scharpf2018},
	preprint = {https://ag-gipp.github.io/bib/preprints/scharpf2018.pdf},
	topic = {mathir},
}

@inproceedings{PetersenSG18,
	location = {Hagenberg, Austria},
	title = {Towards Formula Translation Using Recursive Neural Networks},
	url = {http://arxiv.org/abs/1811.04234},
	booktitle = {Proceedings of the 11th Conference on Intelligent Computer Mathematics ({CICM})},
	author = {Petersen, Felix and Schubotz, Moritz and Gipp, Bela},
	date = {2018},
	note = {tex.biburl: https://dblp.org/rec/bib/journals/corr/abs-1811-04234
tex.oldkey: Petersen2018
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/petersen2018.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	biburl = {https://dblp.org/rec/bib/journals/corr/abs-1811-04234},
	oldkey = {Petersen2018},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/petersen2018.pdf},
	topic = {mathir},
}

@inproceedings{HamborgLSH18,
	title = {Giveme5W: Main Event Retrieval from News Articles by Extraction of the Five Journalistic W Questions},
	volume = {10766},
	url = {https://doi.org/10.1007/978-3-319-78105-1_39},
	doi = {10.1007/978-3-319-78105-1_39},
	series = {Lecture notes in computer science},
	pages = {356--366},
	booktitle = {Transforming Digital Worlds - 13th International Conference, {iConference} 2018, Sheffield, Uk, March 25-28, 2018, Proceedings},
	publisher = {Springer},
	author = {Hamborg, Felix and Lachnit, Soeren and Schubotz, Moritz and Hepp, Thomas and Gipp, Bela},
	editor = {Chowdhury, Gobinda and {McLeod}, Julie and Gillet, Valerie J. and Willett, Peter},
	date = {2018},
	note = {tex.biburl: https://dblp.org/rec/bib/conf/iconference/{HamborgLSHG}18
tex.oldkey: Hamborg2018a
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/hamborg2018.pdf
tex.topic: newsanalysis},
	keywords = {!bg, !bg\_author, !bg\_preprint, !fh, !fh\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://dblp.org/rec/bib/conf/iconference/HamborgLSHG18},
	oldkey = {Hamborg2018a},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/hamborg2018.pdf},
	topic = {newsanalysis},
}

@inproceedings{HamborgBSL18,
	title = {Extraction of Main Event Descriptors from News Articles by Answering the Journalistic Five W and One H Questions},
	url = {http://doi.acm.org/10.1145/3197026.3203899},
	doi = {10.1145/3197026.3203899},
	pages = {339--340},
	booktitle = {Proceedings of the 18th Annual International {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL}) Fort Worth, {TX}, {USA}, June 03-07, 2018},
	publisher = {{ACM}},
	author = {Hamborg, Felix and Breitinger, Corinna and Schubotz, Moritz and Lachnit, Soeren and Gipp, Bela},
	editor = {Chen, Jiangping and Gonçalves, Marcos André and Allen, Jeff M. and Fox, Edward A. and Kan, Min-Yen and Petras, Vivien},
	date = {2018},
	note = {tex.biburl: https://dblp.uni-trier.de/rec/bibtex/conf/jcdl/{HamborgBSLG}18
tex.core: A*
tex.oldkey: Hamborg2018
tex.preprint: https://www.gipp.com/wp-content/papercite-data/pdf/hamborg2018a.pdf
tex.topic: newsanalysis},
	keywords = {!bg, !bg\_author, !bg\_preprint, !cb, !cb\_author, !fh, !fh\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, jabref\_imp2, old\_tex\_field\_preprint},
	biburl = {https://dblp.uni-trier.de/rec/bibtex/conf/jcdl/HamborgBSLG18},
	core = {A*},
	oldkey = {Hamborg2018},
	preprint = {https://www.gipp.com/wp-content/papercite-data/pdf/hamborg2018a.pdf},
	topic = {newsanalysis},
}

@article{HeckS18,
	title = {{DiViDu} - an Open Source Solution for Dual Task Experiments with Integrated Divided Visual Field Paradigm},
	volume = {6},
	url = {https://doi.org/10.5334/jors.199},
	doi = {10.5334/jors.199},
	journaltitle = {Journal of Open Research Software},
	author = {Heck, Nina and Schubotz, Moritz},
	date = {2018},
	note = {tex.ids: {HeckS}18
tex.biburl: https://kops.uni-konstanz.de/handle/123456789/42726
tex.oldkey: Heck2018
tex.publisher: Ubiquity Press, Ltd.},
	keywords = {!ms, !ms\_author, !ms\_cv, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {HeckS18},
	biburl = {https://kops.uni-konstanz.de/handle/123456789/42726},
	oldkey = {Heck2018},
	publisher = {Ubiquity Press, Ltd.},
}

@incollection{GreinerPetterSCG18,
	title = {{MathTools}: An open {API} for convenient {MathML} handling},
	volume = {11006},
	url = {https://www.gipp.com/wp-content/papercite-data/pdf/greinerpetter2018.pdf},
	series = {Lecture notes in computer science},
	pages = {104--110},
	booktitle = {Intelligent Computer Mathematics - 11th International Conference, {CICM} 2018, Hagenberg, Austria, August 13-17, 2018, Proceedings},
	publisher = {Springer},
	author = {Greiner-Petter, André and Schubotz, Moritz and Cohl, Howard S. and Gipp, Bela},
	editor = {Rabe, Florian and Farmer, William M. and Passmore, Grant O. and Youssef, Abdou},
	date = {2018},
	doi = {10.1007/978-3-319-96812-4_9},
	note = {tex.ids: {GreinerPetterSCG}18a
tex.biburl: https://dblp.org/rec/bib/conf/mkm/Greiner-{PetterS}18
tex.oldkey: Greiner-Petter2018
tex.topic: mathir
tex.url\_orig: https://doi.org/10.1007/978-3-319-96812-4\_9
{seriesTitle}: Lecture Notes in Computer Science},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, {DFG}1259-1, jabref\_imp2, old\_tex\_field\_preprint, ⚠️ Invalid {DOI}},
	ids = {GreinerPetterSCG18a},
	biburl = {https://dblp.org/rec/bib/conf/mkm/Greiner-PetterS18},
	oldkey = {Greiner-Petter2018},
	topic = {mathir},
	url_orig = {https://doi.org/10.1007/978-3-319-96812-4_9},
}

@inproceedings{MeuschkeSHS17,
	location = {Singapore},
	title = {Analyzing Mathematical Content to Detect Academic Plagiarism},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-4918-5},
	url = {http://doi.acm.org/10.1145/3132847.3133144},
	doi = {10.1145/3132847.3133144},
	shorttitle = {Proc. {CIKM}},
	abstract = {This paper presents, to our knowledge, the first study on analyzing mathematical expressions to detect academic plagiarism. We make the following contributions. First, we investigate confirmed cases of plagiarism to categorize the similarities of mathematical content commonly found in plagiarized publications. From this investigation, we derive possible feature selection and feature comparison strategies for developing math-based detection approaches and a ground truth for our experiments. Second, we create a test collection by embedding confirmed cases of plagiarism into the {NTCIR}-11 {MathIR} Task dataset, which contains approx. 60 million mathematical expressions in 105,120 documents from {arXiv}.org. Third, we develop a first math-based detection approach by implementing and evaluating different feature comparison approaches using an open source parallel data processing pipeline built using the Apache Flink framework. The best performing approach identifies all but two of our real-world test cases at the top rank and achieves a mean reciprocal rank of 0.86. The results show that mathematical expressions are promising text-independent features to identify academic plagiarism in large collections. To facilitate future research on math-based plagiarism detection, we make our source code and data available. ? 2017 Copyright held by the owner/author(s). Publication rights licensed to {ACM}.},
	pages = {2211--2214},
	booktitle = {Proceedings {ACM} Conference on Information and Knowledge Management ({CIKM})},
	publisher = {{ACM}},
	author = {Meuschke, Norman and Schubotz, Moritz and Hamborg, Felix and Skopal, Tomas and Gipp, Bela},
	date = {2017-11},
	note = {tex.ids: {MeuschkeSHS}17a, {MeuschkeSHS}17b
tex.biburl: https://dblp.org/rec/bib/conf/cikm/{MeuschkeSHSG}17
tex.core: A;Core Rank A;http://portal.core.edu.au/conf-ranks/25/
tex.oldkey: Meuschke2017b
tex.owner: norman
tex.preprint: https://ag-gipp.github.io/bib/preprints/meuschke2017b.pdf
tex.topic: pd},
	keywords = {!bg, !bg\_author, !bg\_preprint, !fh, !fh\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint, pd\_litrev19},
	ids = {MeuschkeSHS17a, MeuschkeSHS17b},
	biburl = {https://dblp.org/rec/bib/conf/cikm/MeuschkeSHSG17},
	core = {A;Core Rank A;http://portal.core.edu.au/conf-ranks/25/},
	oldkey = {Meuschke2017b},
	owner = {norman},
	preprint = {https://ag-gipp.github.io/bib/preprints/meuschke2017b.pdf},
	topic = {pd},
}

@incollection{SchubotzKMH17,
	location = {Cham},
	title = {Evaluating and Improving the Extraction of Mathematical Identifier Definitions},
	volume = {10456 {LNCS}},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-3-319-65812-4 978-3-319-65813-1},
	url = {http://link.springer.com/10.1007/978-3-319-65813-1_7},
	series = {Lecture Notes in Computer Science},
	abstract = {Mathematical formulae in academic texts significantly contribute to the overall semantic content of such texts, especially in the fields of Science, Technology, Engineering and Mathematics. Knowing the definitions of the identifiers in mathematical formulae is essential to understand the semantics of the formulae. Similar to the sense-making process of human readers, mathematical information retrieval systems can analyze the text that surrounds formulae to extract the definitions of identifiers occurring in the formulae. Several approaches for extracting the definitions of mathematical identifiers from documents have been proposed in recent years. So far, these approaches have been evaluated using different collections and gold standard datasets, which prevented comparative performance assessments. To facilitate future research on the task of identifier definition extraction, we make three contributions. First, we provide an automated evaluation framework, which uses the dataset and gold standard of the {NTCIR}-11 Math Retrieval Wikipedia task. Second, we compare existing identifier extraction approaches using the developed evaluation framework. Third, we present a new identifier extraction approach that uses machine learning to combine the well-performing features of previous approaches. The new approach increases the precision of extracting identifier definitions from 17.85\% to 48.60\%, and increases the recall from 22.58\% to 28.06\%. The evaluation framework, the dataset and our source code are openly available at: https://ident.formulasearchengine.com.},
	pages = {82--94},
	booktitle = {Experimental {IR} Meets Multilinguality, Multimodality, and Interaction},
	publisher = {Springer International Publishing},
	author = {Schubotz, Moritz and Krämer, Leonard and Meuschke, Norman and Hamborg, Felix and Gipp, Bela},
	editor = {Jones, Gareth J.F. and Lawless, Séamus and Gonzalo, Julio and Kelly, Liadh and Goeuriot, Lorraine and Mandl, Thomas and Cappellato, Linda and Ferro, Nicola},
	date = {2017-08},
	doi = {10.1007/978-3-319-65813-1_7},
	note = {Series Title: Lecture Notes in Computer Science
tex.ids: {SchubotzKMH}17a
tex.biburl: https://dblp.org/rec/bib/conf/clef/{SchubotzKMHG}17
tex.oldkey: Schubotz2017
tex.preprint: https://ag-gipp.github.io/bib/preprints/schubotz2017.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !fh, !fh\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {SchubotzKMH17a},
	biburl = {https://dblp.org/rec/bib/conf/clef/SchubotzKMHG17},
	oldkey = {Schubotz2017},
	preprint = {https://ag-gipp.github.io/bib/preprints/schubotz2017.pdf},
	topic = {mathir},
}

@inproceedings{SchwarzerBSM17,
	title = {Citolytics: A Link-based Recommender System for Wikipedia},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-4652-8},
	doi = {10.1145/3109859.3109981},
	shorttitle = {Citolytics},
	abstract = {We present Citolytics - a novel link-based recommendation system for Wikipedia articles. In a preliminary study, Citolytics achieved promising results compared to the widely used text-based approach of Apache Lucene's {MoreLikeThis} ({MLT}). In this demo paper, we describe how we plan to integrate Citolytics into the Wikipedia infrastructure by using Elasticsearch and Apache Flink to serve recommendations for Wikipedia articles. Additionally, we propose a large-scale online evaluation design using the Wikipedia Android app. Working with Wikipedia data has several unique advantages. First, the availability of a very large user sample contributes to statistically significant results. Second, the openness of Wikipedia's architecture allows making our source code and evaluation data public, thus benefiting other researchers. If link-based recommendations show promise in our online evaluation, a deployment of the presented system within Wikipedia would have a far-reaching impact on Wikipedia's more than 30 million users.},
	pages = {360--361},
	booktitle = {Proceedings of the 11th {ACM} Conference on Recommender Systems ({RecSys})},
	publisher = {{ACM}},
	author = {Schwarzer, Malte and Breitinger, Corinna and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
	date = {2017-08},
	note = {tex.ids: {SchwarzerBSM}17a
tex.biburl: https://dblp.org/rec/bib/conf/recsys/{SchwarzerBSMG}17
tex.oldkey: Schwarzer2017
tex.preprint: https://ag-gipp.github.io/bib/preprints/schwarzer2017.pdf
tex.topic: rec},
	keywords = {!bg, !bg\_author, !bg\_preprint, !cb, !cb\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {SchwarzerBSM17a},
	biburl = {https://dblp.org/rec/bib/conf/recsys/SchwarzerBSMG17},
	oldkey = {Schwarzer2017},
	preprint = {https://ag-gipp.github.io/bib/preprints/schwarzer2017.pdf},
	topic = {rec},
}

@incollection{SchubotzMHC17,
	title = {{VMEXT}: A Visualization Tool for Mathematical Expression Trees},
	volume = {10383 {LNCS}},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-3-319-62074-9},
	url = {https://doi.org/10.1007/978-3-319-62075-6_24},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{VMEXT}},
	abstract = {Mathematical expressions can be represented as a tree consisting of terminal symbols, such as identifiers or numbers (leaf nodes), and functions or operators (non-leaf nodes). Expression trees are an important mechanism for storing and processing mathematical expressions as well as the most frequently used visualization of the structure of mathematical expressions. Typically, researchers and practitioners manually visualize expression trees using general-purpose tools. This approach is laborious, redundant, and error-prone. Manual visualizations represents a user’s notion of what the markup of an expression should be, but not necessarily what the actual markup is. This paper presents {VMEXT} – a free and open source tool to directly visualize expression trees from parallel  Open image in new window. {VMEXT} simultaneously visualizes the presentation elements and the semantic structure of mathematical expressions to enable users to quickly spot deficiencies in the Content  Open image in new window markup that does not affect the presentation of the expression. Identifying such discrepancies previously required reading the verbose and complex  Open image in new window markup. {VMEXT} also allows one to visualize similar and identical elements of two expressions. Visualizing expression similarity can support developers in designing retrieval approaches and enable improved interaction concepts for users of mathematical information retrieval systems. We demonstrate {VMEXT}’s visualizations in two web-based applications. The first application presents the visualizations alone. The second application shows a possible integration of the visualizations in systems for mathematical knowledge management and mathematical information retrieval. The application converts  Open image in new window input to parallel  Open image in new window, computes basic similarity measures for mathematical expressions, and visualizes the results using {VMEXT}.},
	pages = {340--355},
	booktitle = {Intelligent Computer Mathematics},
	publisher = {Springer},
	author = {Schubotz, Moritz and Meuschke, Norman and Hepp, Thomas and Cohl, Howard S. and Gipp, Bela},
	editor = {Geuvers, Herman and England, Matthew and Hasan, Osman and Rabe, Florian and Teschke, Olaf},
	date = {2017-07},
	note = {tex.ids: {SchubotzMHC}17a, {SchubotzMHC}17b
tex.biburl: http://dblp.uni-trier.de/rec/bib/conf/mkm/{SchubotzMHCG}17
tex.oldkey: vmext17
tex.preprint: https://arxiv.org/pdf/1707.03540.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {SchubotzMHC17a, SchubotzMHC17b},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/mkm/SchubotzMHCG17},
	oldkey = {vmext17},
	preprint = {https://arxiv.org/pdf/1707.03540.pdf},
	topic = {mathir},
}

@inproceedings{MeuschkeSSG17,
	location = {Toronto, Canada},
	title = {Analyzing Semantic Concept Patterns to Detect Academic Plagiarism},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-5388-5},
	doi = {10.1145/3127526.3127535},
	abstract = {Detecting academic plagiarism is a pressing problem, e.g., for educational and research institutions, funding agencies, and academic publishers. Existing plagiarism detection systems reliably identify copied text, or near copies of text, but often fail to detect disguised forms of academic plagiarism, such as paraphrases, translations, and idea plagiarism. We present Semantic Concept Pattern Analysis - an approach that performs an integrated analysis of semantic text relatedness and structural text similarity. Using 25 officially retracted academic plagiarism cases, we demonstrate that our approach can detect plagiarism that established text matching approaches would not identify. We view our approach as a promising addition to improve the detection capabilities for strong paraphrases. We plan to further improve Semantic Concept Pattern Analysis and include the approach as part of an integrated detection process that analyzes heterogeneous similarity features to better identify the many possible forms of plagiarism in academic documents.},
	pages = {46--53},
	booktitle = {Proceedings of the International Workshop on Mining Scientific Publications ({WOSP}) co-located with the {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	publisher = {{IEEE} Computer Society},
	author = {Meuschke, Norman and Siebeck, Nicolas and Schubotz, Moritz and Gipp, Bela},
	date = {2017-06},
	note = {tex.ids: {MeuschkeSSG}17a
tex.biburl: https://dblp.org/rec/bib/conf/jcdl/{MeuschkeSSG}17
tex.oldkey: Meuschke2017
tex.preprint: https://ag-gipp.github.io/bib/preprints/meuschke2017a.pdf},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint, pd\_litrev19},
	ids = {MeuschkeSSG17a},
	biburl = {https://dblp.org/rec/bib/conf/jcdl/MeuschkeSSG17},
	oldkey = {Meuschke2017},
	preprint = {https://ag-gipp.github.io/bib/preprints/meuschke2017a.pdf},
}

@inproceedings{DahmSMG17,
	title = {A Vision for Performing Social and Economic Data Analysis using Wikipedia's Edit History},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-4914-7},
	url = {http://doi.acm.org/10.1145/3041021.3053363},
	doi = {10.1145/3041021.3053363},
	abstract = {In this vision paper, we suggest combining two lines of research to study the collective behavior of Wikipedia contributors. The first line of research analyzes Wikipedia's edit history to quantify the quality of individual contributions and the resulting reputation of the contributor. The second line of research surveys Wikipedia contributors to gain insights, e.g., on their personal and professional background, socioeconomic status, or motives to contribute {toWikipedia}. While both lines of research are valuable on their own, we argue that the combination of both approaches could yield insights that exceed the sum of the individual parts. Linking survey data to contributor reputation and content-based quality metrics could provide a large-scale, public domain data set to perform user modeling, i.e. deducing interest profiles of user groups. User profiles can, among other applications, help to improve recommender systems. The resulting dataset can also enable a better understanding and improved prediction of high quality Wikipedia content and {successfulWikipedia} contributors. Furthermore, the dataset can enable novel research approaches to investigate team composition and collective behavior as well as help to identify domain experts and young talents. We report on the status of implementing our large-scale, content-based analysis of the Wikipedia edit history using the big data processing framework Apache Flink. Additionally, we describe our plans to conduct a survey among Wikipedia contributors to enhance the content-based quality metrics.},
	pages = {1627--1634},
	booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
	publisher = {{ACM}},
	author = {Dahm, Erik and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
	date = {2017-04},
	note = {tex.ids: {DahmSMG}17a
tex.oldkey: Dahm2017
tex.preprint: https://ag-gipp.github.io/bib/preprints/dahm2017.pdf
tex.topic: wiki},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint, wikipedia},
	ids = {DahmSMG17a},
	oldkey = {Dahm2017},
	preprint = {https://ag-gipp.github.io/bib/preprints/dahm2017.pdf},
	topic = {wiki},
}

@inproceedings{CohlSYG17,
	title = {Semantic Preserving Bijective Mappings of Mathematical Formulae Between Document Preparation Systems and Computer Algebra Systems},
	volume = {10383},
	url = {http://hcohl.sdf.org/drmfcas.pdf},
	doi = {10.1007/978-3-319-62075-6_9},
	series = {Lecture Notes in Computer Science},
	pages = {115--131},
	booktitle = {Intelligent Computer Mathematics - 10th International Conference, {CICM}2017, Edinburgh, Uk, July 17-21, 2017, Proceedings},
	publisher = {Springer},
	author = {Cohl, Howard S. and Schubotz, Moritz and Youssef, Abdou and Greiner-Petter, André and Gerhard, Jürgen and Saunders, Bonita V. and {McClain}, Marjorie A. and Bang, Joon and Chen, Kevin},
	editor = {Geuvers, Herman and England, Matthew and Hasan, Osman and Rabe, Florian and Teschke, Olaf},
	date = {2017},
	note = {tex.ids: {CohlSYG}17
tex.biburl: https://dblp.org/rec/bib/conf/mkm/{CohlSYGGSMBC}17
tex.oldkey: Cohl2017
tex.owner: Moritz
tex.url\_orig: https://doi.org/10.1007/978-3-319-62075-6\_9},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {CohlSYG17},
	biburl = {https://dblp.org/rec/bib/conf/mkm/CohlSYGGSMBC17},
	oldkey = {Cohl2017},
	owner = {Moritz},
	url_orig = {https://doi.org/10.1007/978-3-319-62075-6_9},
}

@inproceedings{CorneliS17,
	title = {math.wikipedia.org: A vision for a collaborative semi-formal, language independent math(s) encyclopedia},
	url = {https://www.research.ed.ac.uk/portal/files/32938085/corneli2017math.pdf},
	booktitle = {Conference on Artificial Intelligence and Theorem Proving},
	author = {Corneli, Joe and Schubotz, Moritz},
	date = {2017},
	note = {tex.ids: {CorneliS}17
tex.biburl: https://www.research.ed.ac.uk/portal/en/publications/mathwikipediaorg-a-vision-for-a-collaborative-semiformal-language-independent-maths-encyclopedia(9588c61f-5234-4f9d-a036-c7c3daac9307).bibtex?download=true
tex.oldkey: Corneli2017
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	ids = {CorneliS17},
	biburl = {https://www.research.ed.ac.uk/portal/en/publications/mathwikipediaorg-a-vision-for-a-collaborative-semiformal-language-independent-maths-encyclopedia(9588c61f-5234-4f9d-a036-c7c3daac9307).bibtex?download=true},
	oldkey = {Corneli2017},
	owner = {Moritz},
}

@book{Schubotz17,
	title = {Augmenting Mathematical Formulae for More Effective Querying \& Efficient Presentation},
	isbn = {978-3-7450-6208-3},
	url = {https://www.epubli.de/preview/publication/64471},
	publisher = {Epubli Verlag, Berlin},
	author = {Schubotz, Moritz},
	date = {2017},
	doi = {10.14279/depositonce-6034},
	note = {tex.oldkey: dis
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, \#nosource, jabref\_imp2},
	oldkey = {dis},
	owner = {Moritz},
}

@unpublished{Schubotz16CICM,
	location = {Bialystok, Poland},
	title = {Implicit Content Dictionaries in the {NIST} Digital Repository of Mathematical Formulae},
	url = {http://cicm-conference.org/2016/cicm.php?event=&menu=talks#O3},
	note = {{OpenMath} Workshop of the 9th Conference on Intelligent Computer Mathematics {CICM} 2016},
	author = {Schubotz, Moritz},
	urldate = {2016-10-03},
	date = {2016-07-25},
	keywords = {!ms, !ms\_author, \#nosource, jabref\_imp2},
	jabref-groups = {phd-m},
	oldkey = {schubotz16implCd},
	owner = {Moritz},
}

@report{Schubotz16NTCIRData,
	title = {Identifier Gold Standard for {NTCIR} 11 Math Wikipedia Dataset},
	url = {https://depositonce.tu-berlin.de/handle/11303/6571},
	abstract = {Mathematical formulae are essential in science, but face challenges of ambiguity, due to the use of a small number of identifiers to represent an immense number of concepts. Corresponding to word sense disambiguation in Natural Language Processing, we disambiguate mathematical identifiers. By regarding formulae and natural text as one monolithic information source, we are able to extract the semantics of identifiers in a process we term Mathematical Language Processing ({MLP}). As scientific communities tend to establish standard (identifier) notations, we use the document domain to infer the actual meaning of an identifier. Therefore, we adapt the software development concept of namespaces to mathematical notation. Thus, we learn namespace definitions by clustering the {MLP} results and mapping those clusters to subject classification schemata. In addition, this gives fundamental insights into the usage of mathematical notations in science, technology, engineering and mathematics. Our gold standard based evaluation shows that {MLP} extracts relevant identifier-definitions. Moreover, we discover that identifier namespaces improve the performance of automated identifier-definition extraction, and elevate it to a level that cannot be achieved within the document context alone.},
	author = {Schubotz, Moritz},
	editora = {{Technische Universität Berlin} and Howard, S. Cohl},
	editoratype = {collaborator},
	urldate = {2020-04-11},
	date = {2016-07-18},
	langid = {english},
	doi = {10.14279/depositonce-6064},
	note = {tex.ids: 11303\_6571, Schubotz16NTCIRData
tex.oldkey: {dataIdentifierGold}16
tex.owner: Moritz
tex.publisher: Technische Universität Berlin},
	keywords = {!ms, !ms\_author, \#nosource, jabref\_imp2},
	ids = {11303_6571, Schubotz16NTCIRData},
	oldkey = {dataIdentifierGold16},
	owner = {Moritz},
	publisher = {Technische Universität Berlin},
}

@inproceedings{SchubotzGLC16,
	location = {New York, {NY}, {USA}},
	title = {Semantification of Identifiers in Mathematics for Better Math Information Retrieval},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-4069-4},
	doi = {10.1145/2911451.2911503},
	series = {{SIGIR} '16},
	shorttitle = {Semantification of Identifiers in Mathematics for {MIR}},
	abstract = {Mathematical formulae are essential in science, but face challenges of ambiguity, due to the use of a small number of identifiers to represent an immense number of concepts. Corresponding to word sense disambiguation in Natural Language Processing, we disambiguate mathematical identifiers. By regarding formulae and natural text as one monolithic information source, we are able to extract the semantics of identifiers in a process we term Mathematical Language Processing ({MLP}). As scientific communities tend to establish standard (identifier) notations, we use the document domain to infer the actual meaning of an identifier. Therefore, we adapt the software development concept of namespaces to mathematical notation. Thus, we learn namespace definitions by clustering the {MLP} results and mapping those clusters to subject classification schemata. In addition, this gives fundamental insights into the usage of mathematical notations in science, technology, engineering and mathematics. Our gold standard based evaluation shows that {MLP} extracts relevant identifier-definitions. Moreover, we discover that identifier namespaces improve the performance of automated identifier-definition extraction, and elevate it to a level that cannot be achieved within the document context alone.},
	pages = {135--144},
	booktitle = {Proceedings of the 39th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Schubotz, Moritz and Grigorev, Alexey and Leich, Marcus and Cohl, Howard S. and Meuschke, Norman and Gipp, Bela and Youssef, Abdou S. and Markl, Volker},
	date = {2016-07},
	note = {tex.ids: {SchubotzGLC}16a, {disSigir}16
tex.core: A*
tex.jabref-groups: phd-m
tex.numpages: 10
tex.oldkey: Schubotz16
tex.owner: Moritz
tex.preprint: https://ag-gipp.github.io/bib/preprints/schubotz16.pdf
tex.topic: mathir
place: Pisa, Italy},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, {MIR}, {MLP}, definitions, identifiers, jabref\_imp1\_clean, mathematical information retrieval, mathematical knowledge management, mathematical language processing, mathematics, mathoid, mathosphere, namespace discovery, old\_tex\_field\_preprint, wikipedia},
	ids = {SchubotzGLC16a, disSigir16},
	core = {A*},
	jabref-groups = {phd-m},
	numpages = {10},
	oldkey = {Schubotz16},
	owner = {Moritz},
	preprint = {https://ag-gipp.github.io/bib/preprints/schubotz16.pdf},
	topic = {mathir},
}

@inproceedings{SchubotzMLG16,
	title = {Exploring the One-brain Barrier: a Manual Contribution to the {NTCIR}-12 Math Task},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings12/pdf/ntcir/MathIR/02-NTCIR12-MathIR-SchubotzM.pdf},
	doi = {10.5281/zenodo.3547436},
	shorttitle = {Exploring the one-brain-barrier},
	abstract = {This paper compares the search capabilities of a single human brain supported by the text search built into Wikipedia with state-of-the-art math search systems. To achieve this, we compare results of manual Wikipedia searches with the aggregated and assessed results of all systems participating in the {NTCIR}-12 {MathIR} Wikipedia Task. For 26 of the 30 topics, the average relevance score of our manually retrieved results exceeded the average relevance score of other participants by more than one standard deviation. However, math search engines at large achieved better recall and retrieved highly relevant results that our ‘single-brain system’ missed for 12 topics. By categorizing the topics of {NTCIR}-12 into six types of queries, we observe a particular strength of math search engines to answer queries of the types ‘definition lookup’ and ‘application look-up’. However, we see the low precision of current math search engines as the main challenge that prevents their wide-spread adoption in {STEM} research. By combining our results with highly relevant results of all other participants, we compile a new gold standard dataset and a dataset of duplicate content items. We discuss how the two datasets can be used to improve the query formulation and content augmentation capabilities of match search engines in the future},
	booktitle = {Proceedings of the 12th {NTCIR} Conference on Evaluation of Information Access Technologies},
	author = {Schubotz, Moritz and Meuschke, Norman and Leich, Marcus and Gipp, Bela},
	date = {2016-06},
	note = {tex.ids: {SchubotzMLG}16a, {SchubotzMLG}16b
tex.biburl: https://dblp.org/rec/bib/conf/ntcir/{SchubotzMLG}16
tex.jabref-groups: phd-m
tex.maintitle: Exploring the one-brain-barrier
tex.oldkey: Schubotz2016b
tex.owner: Moritz
tex.preprint: https://ag-gipp.github.io/bib/preprints/schubotz2016b.pdf
tex.topic: mathir},
	keywords = {!bg, !bg\_author, !bg\_preprint, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {SchubotzMLG16a, SchubotzMLG16b},
	biburl = {https://dblp.org/rec/bib/conf/ntcir/SchubotzMLG16},
	jabref-groups = {phd-m},
	maintitle = {Exploring the one-brain-barrier},
	oldkey = {Schubotz2016b},
	owner = {Moritz},
	preprint = {https://ag-gipp.github.io/bib/preprints/schubotz2016b.pdf},
	topic = {mathir},
}

@inproceedings{SchwarzerSMB16,
	location = {Newark, New Jersey, {USA}},
	title = {Evaluating Link-based Recommendations for Wikipedia},
	rights = {Creative Commons Attribution 4.0 International License ({CC}-{BY})},
	isbn = {978-1-4503-4229-2},
	doi = {10.1145/2910896.2910908},
	abstract = {Literature recommender systems support users in filtering the vast and increasing number of documents in digital libraries and on the Web. For academic literature, research has proven the ability of citation-based document similarity measures, such as Co-Citation ({CoCit}), or Co-Citation Proximity Analysis ({CPA}) to improve recommendation quality. In this paper, we report on the first large-scale investigation of the performance of the {CPA} approach in generating literature recommendations for Wikipedia, which is fundamentally different from the academic literature domain. We analyze links instead of citations to generate article recommendations. We evaluate {CPA}, {CoCit}, and the Apache Lucene {MoreLikeThis} ({MLT}) function, which represents a traditional text-based similarity measure. We use two datasets of 779,716 and 2.57 million Wikipedia articles, the Big Data processing framework Apache Flink, and a ten-node computing cluster. To enable our large-scale evaluation, we derive two quasi-gold standards from the links in Wikipedia's "See also" sections and a comprehensive Wikipedia clickstream dataset.

Our results show that the citation-based measures {CPA} and {CoCit} have complementary strengths compared to the text-based {MLT} measure. While {MLT} performs well in identifying narrowly similar articles that share similar words and structure, the citation- based measures are better able to identify topically related information, such as information on the city of a certain university or other technical universities in the region. The {CPA} approach, which consistently outperformed {CoCit}, is better suited for identifying a broader spectrum of related articles, as well as popular articles that typically exhibit a higher quality. Additional benefits of the {CPA} approach are its lower runtime requirements and its language-independence that allows for a cross-language retrieval of articles. We present a manual analysis of exemplary articles to demonstrate and discuss our findings. The raw data and source code of our study, together with a manual on how to use them, are openly available at: https://github.com/wikimedia/citolytics},
	pages = {191--200},
	booktitle = {Proceedings of the 16th Annual International {ACM}/{IEEE} Joint Conference on Digital Libraries ({JCDL})},
	publisher = {{ACM}},
	author = {Schwarzer, Malte and Schubotz, Moritz and Meuschke, Norman and Breitinger, Corinna and Markl, Volker and Gipp, Bela},
	date = {2016-06},
	note = {tex.ids: {SchwarzerSMB}16a
tex.core: A*
tex.oldkey: Schwarzer2016
tex.preprint: https://ag-gipp.github.io/bib/preprints/schwarzer2016.pdf
tex.topic: rec},
	keywords = {!bg, !bg\_author, !bg\_preprint, !cb, !cb\_author, !ms, !ms\_author, !ms\_cv, !ms\_preprint, !nm, !nm\_author, !nm\_preprint, jabref\_imp1\_clean, old\_tex\_field\_preprint},
	ids = {SchwarzerSMB16a},
	core = {A*},
	oldkey = {Schwarzer2016},
	preprint = {https://ag-gipp.github.io/bib/preprints/schwarzer2016.pdf},
	topic = {rec},
}

@inproceedings{SchubotzVC16,
	title = {Getting the Units Right},
	volume = {1785},
	url = {http://ceur-ws.org/Vol-1785/W45.pdf},
	doi = {10.13140/rg.2.1.2508.0561},
	series = {{CEUR} workshop proceedings},
	pages = {146--156},
	booktitle = {Joint Proceedings of the {FM}4M, {MathUI}, and {ThEdu} Workshops, Doctoral Program, and Work in Progress at the Conference on Intelligent Computer Mathematics 2016 co-located with the 9th Conference on Intelligent Computer Mathematics ({CICM} 2016), Bialystok, Poland, July 25-29, 2016.},
	publisher = {{CEUR}-{WS}.org},
	author = {Schubotz, Moritz and Veenhuis, David and Cohl, Howard S.},
	editor = {Kohlhase, Andrea and Libbrecht, Paul and Miller, Bruce R. and Naumowicz, Adam and Neuper, Walther and Quaresma, Pedro and Tompa, Frank Wm. and Suda, Martin},
	date = {2016},
	note = {tex.ids: {SchubotzVC}16
tex.biburl: https://dblp.org/rec/bib/conf/cikm/{SchubotzVC}16
tex.jabref-groups: phd-m
tex.oldkey: {disCicm}16Units
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {SchubotzVC16},
	biburl = {https://dblp.org/rec/bib/conf/cikm/SchubotzVC16},
	jabref-groups = {phd-m},
	oldkey = {disCicm16Units},
	owner = {Moritz},
}

@inproceedings{SchubotzS16,
	title = {A Smooth Transition to Modern Mathoid-Based Math Rendering in Wikipedia with Automatic Visual Regression Testing},
	volume = {1785},
	url = {http://ceur-ws.org/Vol-1785/W48.pdf},
	doi = {10.13140/rg.2.1.3961.1124},
	series = {{CEUR} workshop proceedings},
	pages = {132--145},
	booktitle = {Joint Proceedings of the {FM}4M, {MathUI}, and {ThEdu} Workshops, Doctoral Program, and Work in Progress at the Conference on Intelligent Computer Mathematics 2016 co-located with the 9th Conference on Intelligent Computer Mathematics ({CICM} 2016), Bialystok, Poland, July 25-29, 2016.},
	publisher = {{CEUR}-{WS}.org},
	author = {Schubotz, Moritz and Sexton, Alan P.},
	editor = {Kohlhase, Andrea and Libbrecht, Paul and Miller, Bruce R. and Naumowicz, Adam and Neuper, Walther and Quaresma, Pedro and Tompa, Frank Wm. and Suda, Martin},
	date = {2016},
	note = {tex.ids: {SchubotzS}16
tex.biburl: https://dblp.org/rec/bib/conf/cikm/{SchubotzS}16
tex.homepage: https://github.com/wikimedia/mathoid/
tex.jabref-groups: phd-m
tex.oldkey: {disCicm}16Mathpipe
tex.owner: Moritz
tex.preprint: http://pure-oai.bham.ac.uk/ws/files/31196373/Schubotz$_{\textrm{S}}$exton$_{\textrm{S}}$mooth$_{\textrm{T}}$ransition$_{\textrm{C}}${EUR}$_{\textrm{P}}$roceedings.pdf},
	keywords = {!ms, !ms\_author, !ms\_cv, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {SchubotzS16},
	biburl = {https://dblp.org/rec/bib/conf/cikm/SchubotzS16},
	homepage = {https://github.com/wikimedia/mathoid/},
	jabref-groups = {phd-m},
	oldkey = {disCicm16Mathpipe},
	owner = {Moritz},
	preprint = {http://pure-oai.bham.ac.uk/ws/files/31196373/Schubotz<sub>S</sub>exton<sub>S</sub>mooth<sub>T</sub>ransition<sub>C</sub>EUR<sub>P</sub>roceedings.pdf},
}

@inproceedings{CohlSMS15,
	title = {Growing the Digital Repository of Mathematical Formulae with Generic Sources},
	volume = {9150},
	doi = {10.1007/978-3-319-20615-8_18},
	series = {{LNCS}},
	shorttitle = {Growing the drmf with generic sources},
	pages = {280--287},
	booktitle = {Intelligent Computer Mathematics, Lecture Notes in Artificial Intelligence 9150},
	publisher = {Springer},
	author = {Cohl, Howard S. and Schubotz, Moritz and {McClain}, Marjorie A. and Saunders, Bonita V. and Zou, Cherry Y. and Mohammed, Azeem S. and Danoff, Alex A.},
	editor = {Kerber, Manfred and Carette, Jacques and Kaliszyk, Cezary and Rabe, Florian and Sorge, Volker},
	date = {2015},
	note = {tex.ids: {CohlSMS}15a
tex.biburl: http://dblp.uni-trier.de/rec/bib/conf/mkm/{CohlSMSZMD}15
tex.jabref-groups: phd-m
tex.oldkey: Cohl2015
tex.owner: Moritz
tex.preprint: https://arxiv.org/pdf/1505.01431.pdf},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {CohlSMS15a},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/mkm/CohlSMSZMD15},
	jabref-groups = {phd-m},
	oldkey = {Cohl2015},
	owner = {Moritz},
	preprint = {https://arxiv.org/pdf/1505.01431.pdf},
}

@inproceedings{SchubotzYMC15,
	location = {Santiago, Chile},
	title = {Challenges of Mathematical Information Retrieval in the {NTCIR}-11 Math Wikipedia Task},
	isbn = {978-1-4503-3621-5},
	doi = {10.1145/2766462.2767787},
	series = {{SIGIR} '15},
	shorttitle = {Challenges of  {MIR} in {WMC}},
	pages = {951--954},
	booktitle = {Proceedings of the 38th Annual International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Schubotz, Moritz and Youssef, Abdou and Markl, Volker and Cohl, Howard S.},
	editor = {Baeza-Yates, Ricardo A. and Lalmas, Mounia and Moffat, Alistair and Ribeiro-Neto, Berthier A.},
	date = {2015},
	note = {tex.ids: {SchubotzYMC}15
tex.biburl: http://dblp.uni-trier.de/rec/bib/conf/sigir/{SchubotzYMC}15
tex.core: A*
tex.jabref-groups: phd-m
tex.numpages: 4
tex.oldkey: {disSigir}15
tex.owner: Moritz
tex.preprint: https://www2.seas.gwu.edu/ ayoussef/papers/Challenges\%20of\%20Mathematical\%20Information\%20Retrieval\%20in\%20the\%20NTCIR-11-{SIGIR}2015.pdf},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, {LaTeXML}, {MIR}, {NTCIR}, benchmark, dataset, jabref\_imp2, math information retrieval, math search, {mathML}, mathoid, old\_tex\_field\_preprint, task, wikipedia},
	ids = {SchubotzYMC15},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/sigir/SchubotzYMC15},
	core = {A*},
	jabref-groups = {phd-m},
	numpages = {4},
	oldkey = {disSigir15},
	owner = {Moritz},
	preprint = {https://www2.seas.gwu.edu/ ayoussef/papers/Challenges%20of%20Mathematical%20Information%20Retrieval%20in%20the%20NTCIR-11-SIGIR2015.pdf},
}

@inproceedings{PagelS14,
	title = {Mathematical Language Processing Project},
	volume = {1186},
	url = {http://ceur-ws.org/Vol-1186/paper-23.pdf},
	series = {{CEUR} Workshop Proceedings},
	booktitle = {Joint Proceedings of the {MathUI}, {OpenMath} and {ThEdu} Workshops and Work in Progress track at {CICM} co-located with Conferences on Intelligent Computer Mathematics ({CICM} 2014), Coimbra, Portugal, July 7-11, 2014.},
	publisher = {{CEUR}-{WS}.org},
	author = {Pagel, Robert and Schubotz, Moritz},
	editor = {England, Matthew and Davenport, James H. and Kohlhase, Andrea and Kohlhase, Michael and Libbrecht, Paul and Neuper, Walther and Quaresma, Pedro and Sexton, Alan P. and Sojka, Petr and Urban, Josef and Watt, Stephen M.},
	date = {2014},
	note = {tex.ids: {PagelS}14a
tex.biburl: https://dblp.org/rec/bib/conf/mkm/{PagelS}14
tex.jabref-groups: phd-m
tex.oldkey: Pagel2014
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, cicm, conference, jabref\_imp2, old\_tex\_field\_preprint, peerreview, wip, ⛔ No {DOI} found},
	ids = {PagelS14a},
	biburl = {https://dblp.org/rec/bib/conf/mkm/PagelS14},
	jabref-groups = {phd-m},
	oldkey = {Pagel2014},
	owner = {Moritz},
}

@inproceedings{AizawaKOS14,
	title = {{NTCIR}-11 Math-2 Task Overview},
	url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings11/pdf/NTCIR/OVERVIEW/01-NTCIR11-OV-MATH-AizawaA.pdf},
	abstract = {This paper presents an overview of the {NTCIR}-11 Math-2 Task, which is specifically dedicated to information access to mathematical content. In particular, the paper summarizes the task design, analysis of the submitted runs, and the main approaches deployed by the participating groups. It also contains an introduction to the optional free Wikipediasubtask, a newly introduced mathematical retrieval task using Wikipedia articles.},
	pages = {88--98},
	booktitle = {Proceedings of the 11th {NTCIR} Conference on Evaluation of Information Access Technologies, {NTCIR}-11, National Center of Sciences, Tokyo, Japan, December 9-12, 2014},
	publisher = {National Institute of Informatics ({NII})},
	author = {Aizawa, Akiko and Kohlhase, Michael and Ounis, Iadh and Schubotz, Moritz},
	date = {2014},
	note = {tex.ids: {AizawaKOS}14a
tex.biburl: https://dblp.org/rec/bib/conf/ntcir/{AizawaKOS}14
tex.jabref-groups: {GuidiReview}, phd-m
tex.oldkey: Aizawa2014
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, {NTCIR}, conference, content, information access to mathematical, jabref\_imp2, mathml, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	ids = {AizawaKOS14a},
	biburl = {https://dblp.org/rec/bib/conf/ntcir/AizawaKOS14},
	jabref-groups = {GuidiReview, phd-m},
	oldkey = {Aizawa2014},
	owner = {Moritz},
}

@inproceedings{SchubotzYMC14,
	title = {Evaluation of Similarity-Measure Factors for Formulae Based on the {NTCIR}-11 Math Task},
	url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings11/pdf/NTCIR/Math-2/04-NTCIR11-MATH-SchubotzM.pdf},
	shorttitle = {Evaluation of Similarity-Measure Factors for Formulae},
	abstract = {In this paper we evaluate the similarity-measure factors pro- posed by Zhang and Youssef based on the {NTCIR}-11 gold standard. In contrast to Zhang and Youssef we evaluate them individually. The evaluation indicates that four of five factors are relevant. The fifth factor alone is of lower rele- vance than the other four factors. However, we do not prove that the fifth factor is irrelevant.},
	booktitle = {Proceedings of the 11th {NTCIR} Conference on Evaluation of Information Access Technologies, {NTCIR}-11, National Center of Sciences, Tokyo, Japan, December 9-12, 2014},
	publisher = {National Institute of Informatics ({NII})},
	author = {Schubotz, Moritz and Youssef, Abdou and Markl, Volker and Cohl, Howard S. and Li, Jimmy J.},
	editor = {Kando, Noriko and Joho, Hideo and Kishida, Kazuaki},
	date = {2014},
	note = {tex.ids: {SchubotzYMC}14
tex.biburl: http://dblp.uni-trier.de/rec/bib/conf/ntcir/{SchubotzYMCL}14
tex.jabref-groups: {GuidiReview}, phd-m
tex.maintitle: Evaluation of similarity-measure factors for formulae
tex.oldkey: {disNtcir}11Sim
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint, ⛔ No {DOI} found},
	ids = {SchubotzYMC14},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/ntcir/SchubotzYMCL14},
	jabref-groups = {GuidiReview, phd-m},
	maintitle = {Evaluation of similarity-measure factors for formulae},
	oldkey = {disNtcir11Sim},
	owner = {Moritz},
}

@inproceedings{CohlMSS14,
	title = {Digital Repository of Mathematical Formulae},
	volume = {8543},
	doi = {10.1007/978-3-319-08434-3_30},
	series = {Lecture Notes in Computer Science},
	pages = {419--422},
	booktitle = {Intelligent Computer Mathematics - International Conference, {CICM} 2014, Coimbra, Portugal, July 7-11, 2014. Proceedings},
	publisher = {Springer},
	author = {Cohl, Howard S. and {McClain}, Marjorie A. and Saunders, Bonita V. and Schubotz, Moritz and Williams, Janelle C.},
	editor = {Watt, Stephen M. and Davenport, James H. and Sexton, Alan P. and Sojka, Petr and Urban, Josef},
	date = {2014},
	note = {tex.ids: {CohlMSS}14a
tex.biburl: https://dblp.org/rec/bib/conf/mkm/{CohlMSSW}14
tex.jabref-groups: phd-m
tex.oldkey: Cohl2014
tex.owner: Moritz
tex.preprint: https://arxiv.org/pdf/1404.6519.pdf},
	keywords = {!ms, !ms\_author, !ms\_cv, \#nosource, cicm, conference, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {CohlMSS14a},
	biburl = {https://dblp.org/rec/bib/conf/mkm/CohlMSSW14},
	jabref-groups = {phd-m},
	oldkey = {Cohl2014},
	owner = {Moritz},
	preprint = {https://arxiv.org/pdf/1404.6519.pdf},
}

@incollection{SchubotzW14,
	title = {Mathoid: Robust, Scalable, Fast and Accessible Math Rendering for Wikipedia},
	volume = {8543},
	series = {Lecture Notes in Computer Science},
	pages = {224--235},
	booktitle = {Intelligent Computer Mathematics - International Conference, {CICM} 2014, Coimbra, Portugal, July 7-11, 2014. Proceedings},
	publisher = {Springer},
	author = {Schubotz, Moritz and Wicke, Gabriel},
	editor = {Watt, Stephen M. and Davenport, James H. and Sexton, Alan P. and Sojka, Petr and Urban, Josef},
	date = {2014},
	doi = {10.1007/978-3-319-08434-3_17},
	note = {tex.ids: {SchubotzW}14a
tex.biburl: https://dblp.org/rec/bib/conf/mkm/{SchubotzW}14
tex.homepage: https://github.com/wikimedia/mathoid/
tex.jabref-groups: phd-m
tex.oldkey: Schubotz2014
tex.owner: Moritz
tex.preprint: https://arxiv.org/pdf/1404.6179.pdf
{seriesTitle}: Lecture Notes in Computer Science},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {SchubotzW14a},
	biburl = {https://dblp.org/rec/bib/conf/mkm/SchubotzW14},
	homepage = {https://github.com/wikimedia/mathoid/},
	jabref-groups = {phd-m},
	oldkey = {Schubotz2014},
	owner = {Moritz},
	preprint = {https://arxiv.org/pdf/1404.6179.pdf},
}

@inproceedings{LeichASH13,
	title = {Applying Stratosphere for Big Data Analytics},
	volume = {214},
	doi = {10.5281/zenodo.1210857},
	series = {{LNI}},
	pages = {507--510},
	booktitle = {Datenbanksysteme Für Business, Technologie Und Web ({BTW}), 15. Fachtagung Des {GI}-Fachbereichs "Datenbanken und Informationssysteme" ({DBIS}), 11.-15.3.2013 in Magdeburg, Germany. Proceedings},
	publisher = {{GI}},
	author = {Leich, Marcus and Adamek, Jochen and Schubotz, Moritz and Heise, Arvid and Rheinländer, Astrid and Markl, Volker},
	editor = {Markl, Volker and Saake, Gunter and Sattler, Kai-Uwe and Hackenbroich, Gregor and Mitschang, Bernhard and Härder, Theo and Köppen, Veit},
	date = {2013},
	note = {tex.ids: {LeichASH}13
tex.biburl: http://dblp.uni-trier.de/rec/bib/conf/btw/{LeichASHRM}13
tex.oldkey: Leich2013},
	keywords = {!ms, !ms\_author, !ms\_cv, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {LeichASH13},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/btw/LeichASHRM13},
	oldkey = {Leich2013},
}

@inproceedings{SchubotzLM13,
	title = {Querying Large Collections of Mathematical Publications: {NTCIR}10 Math Task},
	url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings10/pdf/NTCIR/MATH/03-NTCIR10-MATH-SchubotzM.pdf},
	series = {ntcir-math.nii.ac.jp},
	shorttitle = {Querying large collections of mathematical publications},
	abstract = {In this paper, we present our approach for searching mathematical formulae. We focus on a batch query approach that does not rely on specialized indexes, which are usually domain dependent and restrict the expressiveness of the query language. Instead, we use Stratosphere, a distributed data processing platform for Big Data Analytics that accesses data in a non-indexed format. This system is very effective for answering batches of queries that a researcher may wish to evaluate in bulk on large data sets. We demonstrate our approach using the {NTCIR}10 Math task, which provides a set of formula patterns and a test data corpus. We showcase a simple data analysis program for answering the given queries. We interpret the patterns as regular expressions and assume that matches to these expressions are also relevant search results to the end-user. Based on the evaluation of our results by mathematicians from Zentralblatt Math and mathematics students from Jacobs University, we conclude that our assumption holds principally with regard to precision and recall. Our work is just a first step towards a well-defined query language and processing system for scientific publications that allows researchers to specify their information need in terms of mathematical formulae and their contexts. We envision that our system can be utilized to realize such a vision.},
	pages = {667--674},
	booktitle = {Proceedings of the 10th {NTCIR} Conference on Evaluation of Information Access Technologies, {NTCIR}-10, National Center of Sciences, Tokyo, Japan, June 18-21, 2013},
	publisher = {National Institute of Informatics ({NII})},
	author = {Schubotz, Moritz and Leich, Marcus and Markl, Volker},
	editor = {Kando, Noriko and Kato, Tsuneaki},
	date = {2013},
	note = {tex.ids: {SchubotzLM}13a
tex.biburl: http://dblp.uni-trier.de/rec/bib/conf/ntcir/{SchubotzLM}13
tex.jabref-groups: {GuidiReview}, phd-m
tex.maintitle: Querying large collections of mathematical publications
tex.oldkey: Schubotz2013
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, conference, jabref\_imp2, math search, mathml, ntcir, old\_tex\_field\_preprint, peerreview, query language, stratosphere, ⛔ No {DOI} found},
	ids = {SchubotzLM13a},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/ntcir/SchubotzLM13},
	jabref-groups = {GuidiReview, phd-m},
	maintitle = {Querying large collections of mathematical publications},
	oldkey = {Schubotz2013},
	owner = {Moritz},
}

@article{Schubotz12CICM,
	title = {Making Math Searchable in Wikipedia},
	volume = {abs/1304.5475},
	doi = {10.14279/depositonce-5034},
	abstract = {Wikipedia, the world largest encyclopedia contains a lot of knowledge that is expressed as formulae exclusively. Unfortunately, this knowledge is currently not fully accessible by intelligent information retrieval systems. This immense body of knowledge is hidden form value-added services, such as search. In this paper, we present our {MathSearch} implementation for Wikipedia that enables users to perform a combined text and fully unlock the potential benefits.},
	journaltitle = {{CoRR}},
	author = {Schubotz, Moritz},
	date = {2012-07-30},
	eprinttype = {arxiv},
	eprint = {1304.5475},
	note = {tex.ids: Schubotz12
tex.arxivid: 1304.5475
tex.biburl: http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1304-5475
tex.jabref-groups: phd-m
tex.oldkey: Schubotz2012
tex.owner: Moritz
tex.oldkey: corneli17
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, arxiv, cicm, conference, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {Schubotz12},
	arxivid = {1304.5475},
	biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1304-5475},
	jabref-groups = {phd-m},
	oldkey = {Schubotz2012},
	owner = {Moritz},
	oldkey = {corneli17},
	owner = {Moritz},
}

@online{Schubotz12FSE,
	title = {Formulasearchengine},
	url = {http://mlp.formulasearchengine.com},
	author = {Schubotz, Moritz},
	urldate = {2016-04-01},
	date = {2012},
	note = {tex.jabref-groups: phd-m
tex.oldkey: hp
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, \#nosource, jabref\_imp2, ⛔ No {DOI} found},
	jabref-groups = {phd-m},
	oldkey = {hp},
	owner = {Moritz},
}

@software{Schubotz12MathSearch,
	title = {Extension:{MathSearch} - {MediaWiki}},
	url = {http://www.mediawiki.org/wiki/Extension:MathSearch},
	author = {Schubotz, Moritz},
	urldate = {2012-10-05},
	date = {2012},
	note = {tex.jabref-groups: phd-m
tex.oldkey: {MathSearch}
tex.owner: Moritz},
	keywords = {!ms, !ms\_author, \#nosource, jabref\_imp2, ⛔ No {DOI} found},
	jabref-groups = {phd-m},
	oldkey = {MathSearch},
	owner = {Moritz},
}

@article{SchubotzB11,
	title = {Random Backaction in Tunneling of Single Electrons Through Nanostructures},
	volume = {84},
	issn = {1098-0121},
	doi = {10.1103/physrevb.84.075340},
	pages = {1--8},
	number = {7},
	journaltitle = {Physical Review B},
	author = {Schubotz, Moritz and Brandes, Tobias},
	date = {2011-08},
	note = {tex.ids: {SchubotzB}11a
tex.jabref-groups: phd-m
tex.oldkey: Schubotz11
tex.owner: Moritz
tex.preprint: https://arxiv.org/pdf/1105.4422.pdf},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, arxiv, jabref\_imp2, journal, old\_tex\_field\_preprint, peerreview},
	ids = {SchubotzB11a},
	jabref-groups = {phd-m},
	oldkey = {Schubotz11},
	owner = {Moritz},
	preprint = {https://arxiv.org/pdf/1105.4422.pdf},
}

@thesis{Schubotz11,
	location = {Berlin},
	title = {Full Counting Statistics - A quantum master equation approach},
	pagetotal = {189},
	institution = {Institut für theoretische Phyisk an der Fakultät für Mathematik und Naturwissenschaften an der Technische Universität Berlin},
	type = {Diplomarbeit},
	author = {Schubotz, Moritz},
	date = {2011},
	note = {tex.ids: Schubotz11a
tex.jabref-groups: phd-m
tex.oldkey: Schubotz11fse
tex.owner: Moritz
tex.pubstate: unpublished},
	keywords = {!ms, !ms\_author, !ms\_cv, !ms\_preprint, \#nosource, jabref\_imp2, old\_tex\_field\_preprint},
	ids = {Schubotz11a},
	jabref-groups = {phd-m},
	oldkey = {Schubotz11fse},
	owner = {Moritz},
	pubstate = {unpublished},
}
